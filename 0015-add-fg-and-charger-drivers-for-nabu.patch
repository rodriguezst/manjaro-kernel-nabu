From 4aaaff65d47bc730bb2c137386ddea5586b0f132 Mon Sep 17 00:00:00 2001
From: maverick <maverick_jia@sina.com>
Date: Sun, 30 Jul 2023 10:57:52 +0800
Subject: [PATCH 15/43] add fg and charger drivers for nabu

---
 ...gen4-batterydata-nabu-sunwoda-8720mah.dtsi |  153 +
 arch/arm64/boot/dts/qcom/pm8150b.dtsi         |  139 +
 .../dts/qcom/sm8150-xiaomi-nabu-maverick.dts  |   68 +-
 drivers/power/supply/Kconfig                  |    2 +
 drivers/power/supply/Makefile                 |    1 +
 drivers/power/supply/qcom/Kconfig             |   26 +
 drivers/power/supply/qcom/Makefile            |    3 +
 drivers/power/supply/qcom/batterydata-lib.h   |  232 +
 drivers/power/supply/qcom/fg-alg.c            |  784 +++
 drivers/power/supply/qcom/fg-alg.h            |  100 +
 drivers/power/supply/qcom/fg-core.h           |  673 ++
 drivers/power/supply/qcom/fg-memif.c          | 1284 ++++
 drivers/power/supply/qcom/fg-reg.h            |  381 ++
 drivers/power/supply/qcom/fg-util.c           | 1696 +++++
 drivers/power/supply/qcom/of_batterydata.c    |  678 ++
 drivers/power/supply/qcom/of_batterydata.h    |   91 +
 drivers/power/supply/qcom/pm8150b_charger.c   | 1091 +++
 drivers/power/supply/qcom/pmic-voter.c        |  844 +++
 drivers/power/supply/qcom/pmic-voter.h        |   54 +
 drivers/power/supply/qcom/qpnp-fg-gen4.c      | 5902 +++++++++++++++++
 drivers/power/supply/qcom/qpnp-smb5.c         |    0
 drivers/power/supply/qcom/smb5-lib.c          |  553 ++
 drivers/power/supply/qcom/smb5-lib.h          |  201 +
 drivers/power/supply/qcom/smb5-reg.h          |  592 ++
 drivers/power/supply/qcom/step-chg-jeita.h    |   59 +
 drivers/soc/qcom/Kconfig                      |    9 +
 drivers/soc/qcom/Makefile                     |    1 +
 drivers/soc/qcom/qpnp-pbs.c                   |  364 +
 include/linux/qpnp-pbs.h                      |   25 +
 29 files changed, 16004 insertions(+), 2 deletions(-)
 create mode 100644 arch/arm64/boot/dts/qcom/fg-gen4-batterydata-nabu-sunwoda-8720mah.dtsi
 create mode 100644 drivers/power/supply/qcom/Kconfig
 create mode 100644 drivers/power/supply/qcom/Makefile
 create mode 100644 drivers/power/supply/qcom/batterydata-lib.h
 create mode 100644 drivers/power/supply/qcom/fg-alg.c
 create mode 100644 drivers/power/supply/qcom/fg-alg.h
 create mode 100644 drivers/power/supply/qcom/fg-core.h
 create mode 100644 drivers/power/supply/qcom/fg-memif.c
 create mode 100644 drivers/power/supply/qcom/fg-reg.h
 create mode 100644 drivers/power/supply/qcom/fg-util.c
 create mode 100644 drivers/power/supply/qcom/of_batterydata.c
 create mode 100644 drivers/power/supply/qcom/of_batterydata.h
 create mode 100644 drivers/power/supply/qcom/pm8150b_charger.c
 create mode 100644 drivers/power/supply/qcom/pmic-voter.c
 create mode 100644 drivers/power/supply/qcom/pmic-voter.h
 create mode 100644 drivers/power/supply/qcom/qpnp-fg-gen4.c
 create mode 100644 drivers/power/supply/qcom/qpnp-smb5.c
 create mode 100644 drivers/power/supply/qcom/smb5-lib.c
 create mode 100644 drivers/power/supply/qcom/smb5-lib.h
 create mode 100644 drivers/power/supply/qcom/smb5-reg.h
 create mode 100644 drivers/power/supply/qcom/step-chg-jeita.h
 create mode 100644 drivers/soc/qcom/qpnp-pbs.c
 create mode 100644 include/linux/qpnp-pbs.h

diff --git a/arch/arm64/boot/dts/qcom/fg-gen4-batterydata-nabu-sunwoda-8720mah.dtsi b/arch/arm64/boot/dts/qcom/fg-gen4-batterydata-nabu-sunwoda-8720mah.dtsi
new file mode 100644
index 000000000..c152f8ed1
--- /dev/null
+++ b/arch/arm64/boot/dts/qcom/fg-gen4-batterydata-nabu-sunwoda-8720mah.dtsi
@@ -0,0 +1,153 @@
+qcom,5119583_xiaomi_k82_p86120aa1_8720mah_averaged_masterslave_apr8th2021 {
+	qcom,profile-revision = <24>;
+	/* #5119583_XIAOMI_K82_8720mAH_averaged_MasterSlave_Apr8th2021*/
+	qcom,max-voltage-uv = <4480000>;
+	qcom,fastchg-current-ma = <5900>;
+	qcom,jeita-fcc-ranges = <(-100)  0   820000
+				1  50   820000
+				51  100  2500000
+				101 150  5964000
+				151 480  5900000
+				481 590  4260000>;
+	qcom,jeita-fv-ranges = <(-100)   0   4450000
+				1   50   4450000
+				51  100  4450000
+				101 150  4450000
+				151 480  4480000
+				481 600  4100000>;
+//	qcom,step-chg-ranges = <3001000  4150000  6000000
+//				4150001  4230000  6000000
+//				4230001  4350000  6000000
+//				4350001  4400000  6000000
+//				4400001  4430000  6000000
+//				4430001  4480000  4000000>;
+//	qcom,taper-fcc;
+	qcom,jeita-too-hot = <590>;
+	qcom,jeita-too-cold = <(-100)>;
+	qcom,jeita-warm-th= <480>;
+	qcom,jeita-cool-th= <150>;
+	qcom,use-bq-pump;
+	mi,six-pin-battery;
+	qcom,ffc-low-temp-term-current-ma = <(-1278)>;
+	qcom,ffc-high-temp-term-current-ma = <(-1363)>;
+	qcom,fg-cc-cv-threshold-mv = <4450>;
+	qcom,fg-ffc-cc-cv-threshold-mv = <4480>;
+	qcom,nom-batt-capacity-mah = <8720>;
+	qcom,batt-id-kohm = <10>;
+	qcom,battery-beta = <3800>;
+	qcom,therm-room-temp = <100000>;
+	qcom,battery-type = "K82_sunwoda_8720mah";
+	qcom,therm-coefficients = <0x2319 0xcb5 0xdb70 0xc48e 0x856b>;
+	qcom,therm-center-offset = <0x70>;
+	qcom,therm-pull-up = <100>;
+	qcom,rslow-normal-coeffs = <0x33 0xfc 0xe8 0x12>;
+	qcom,rslow-low-coeffs = <0x36 0x05 0xc4 0x12>;
+	qcom,checksum = <0xBEEA>;
+	qcom,gui-version = "PM855GUI - 1.0.0.14";
+	qcom,fg-profile-data = [
+		 09 00 9B DB
+		 1B D5 75 DA
+		 68 D5 00 00
+		 99 B5 42 83
+		 FA 87 1E 93
+		 02 8D EA 87
+		 18 00 33 FC
+		 E8 12 C5 04
+		 50 02 CE 07
+		 32 00 11 EA
+		 BB E4 48 E3
+		 5E 0B B5 E2
+		 1D AC 12 22
+		 C9 FA 3A CC
+		 60 00 40 00
+		 3F 00 38 00
+		 2C 00 2D 00
+		 3A 00 46 00
+		 41 00 46 00
+		 3E 00 60 00
+		 44 00 3B 00
+		 4B 00 47 00
+		 3D 00 8C 00
+		 59 64 4B 00
+		 49 00 4C 08
+		 60 00 4C 00
+		 4F 00 6F 10
+		 5E 10 57 00
+		 A3 28 6B 48
+		 5B 60 54 0C
+		 58 00 D8 08
+		 06 20 B1 14
+		 6F 0B 51 FD
+		 4B 1C AE 03
+		 5B 05 F7 2A
+		 B6 17 51 42
+		 2A 5D 68 02
+		 66 12 54 23
+		 AD 0C DE 12
+		 9D 0D F3 1C
+		 21 FB 58 FD
+		 50 03 FE 16
+		 09 2A 76 44
+		 18 5A 95 11
+		 9E 24 29 DC
+		 21 C3 72 C5
+		 F3 1C 97 AA
+		 FB 04 2D B2
+		 0A 17 12 82
+		 4A 84 43 8A
+		 A4 90 09 80
+		 48 03 13 05
+		 87 02 D7 05
+		 00 00 FB CD
+		 78 E2 FC 07
+		 17 EA 39 CD
+		 1D 18 15 08
+		 80 ED 35 03
+		 76 05 A7 01
+		 CE 07 32 00
+		 9E 01 EE 05
+		 5C 05 1C 03
+		 D4 05 0E 02
+		 BD 03 9D 02
+		 C6 05 48 00
+		 39 00 42 00
+		 44 64 45 00
+		 49 00 40 08
+		 40 00 44 00
+		 44 00 3B 10
+		 3F 10 3F 00
+		 53 28 54 48
+		 57 58 62 0D
+		 43 00 48 00
+		 52 08 54 00
+		 43 00 47 00
+		 49 10 59 10
+		 51 00 5F 20
+		 75 40 49 58
+		 56 0F 5D 00
+		 4C 08 31 10
+		 D8 08 FC 20
+		 54 FC 6D 03
+		 67 0D C7 1C
+		 62 23 C5 45
+		 4B 52 63 18
+		 0F 02 AC 05
+		 A9 03 72 12
+		 3F 0A 6B 20
+		 93 04 89 03
+		 20 05 BE 1C
+		 3C 03 C0 05
+		 85 02 77 18
+		 A0 03 51 04
+		 9A 02 6A 00
+		 35 22 4D 05
+		 7A 02 EB 05
+		 FB 1C AF 03
+		 82 04 0B 02
+		 86 18 17 03
+		 59 05 23 03
+		 8A 00 92 00
+		 C0 00 FA 00
+		 F0 21 00 00
+	];
+};
diff --git a/arch/arm64/boot/dts/qcom/pm8150b.dtsi b/arch/arm64/boot/dts/qcom/pm8150b.dtsi
index 048d79ef7..47190ff31 100644
--- a/arch/arm64/boot/dts/qcom/pm8150b.dtsi
+++ b/arch/arm64/boot/dts/qcom/pm8150b.dtsi
@@ -46,6 +46,11 @@ pmic@2 {
 		#address-cells = <1>;
 		#size-cells = <0>;
 
+		pm8150b_revid: qcom,revid@100 {
+			compatible = "qcom,qpnp-revid";
+			reg = <0x100 0x100>;
+		};
+
 		pon@800 {
 			compatible = "qcom,pm8916-pon";
 			reg = <0x0800>;
@@ -53,6 +58,58 @@ pon@800 {
 			status = "disabled";
 		};
 
+		pm8150b_charger: charger@1100 {
+			compatible = "qcom,pm8150b-charger";
+			status = "disabled";
+			reg = <0x1100>;
+			interrupts =
+				<0x2 0x10 0x0 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x10 0x1 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x10 0x2 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x10 0x3 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x10 0x4 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x10 0x6 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x10 0x7 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x0 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x1 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x2 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x3 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x4 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x5 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x13 0x6 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x13 0x7 IRQ_TYPE_EDGE_RISING>,
+				<0x2 0x14 0x1 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x2 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x3 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x4 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x5 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x6 IRQ_TYPE_EDGE_BOTH>,
+				<0x2 0x14 0x7 IRQ_TYPE_EDGE_BOTH>;
+
+			interrupt-names = "chgr-error",
+					  "chg-state-change",
+					  "step-chg-state-change",
+					  "step-chg-soc-update-fail",
+					  "step-chg-soc-update-req",
+					  "vph-alarm",
+					  "vph-drop-prechg",
+					  "usbin-collapse",
+					  "usbin-vashdn",
+					  "usbin-uv",
+					  "usbin-ov",
+					  "usbin-plugin",
+					  "usbin-revi-change",
+					  "usbin-src-change",
+					  "usbin-icl-change",
+					  "dcin-vashdn",
+					  "dcin-uv",
+					  "dcin-ov",
+					  "dcin-plugin",
+					  "dcin-revi",
+					  "dcin-pon",
+					  "dcin-en";
+		};
+
 		pm8150b_vbus: dcdc@1100 {
 			compatible = "qcom,pm8150b-vbus-reg";
 			status = "disabled";
@@ -151,6 +208,11 @@ pm8150b_adc_tm: adc-tm@3500 {
 			status = "disabled";
 		};
 
+		pm8150b_pbs1: qcom,pbs@7200 {
+			compatible = "qcom,qpnp-pbs";
+			reg = <0x7200 0x100>;
+		};
+
 		pm8150b_gpios: gpio@c000 {
 			compatible = "qcom,pm8150b-gpio", "qcom,spmi-gpio";
 			reg = <0xc000>;
@@ -160,6 +222,83 @@ pm8150b_gpios: gpio@c000 {
 			interrupt-controller;
 			#interrupt-cells = <2>;
 		};
+
+		pm8150b_fg: qpnp,fg {
+			compatible = "qcom,fg-gen4";
+			#address-cells = <1>;
+			#size-cells = <1>;
+			qcom,pmic-revid = <&pm8150b_revid>;
+			qcom,pmic-pbs = <&pm8150b_pbs1>;
+			status = "disabled";
+
+			qcom,fg-batt-soc@4000 {
+				status = "okay";
+				reg = <0x4000 0x100>;
+				interrupts = <0x2 0x40 0x0 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x40 0x1 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x40 0x2
+							IRQ_TYPE_EDGE_RISING>,
+					     <0x2 0x40 0x3
+							IRQ_TYPE_EDGE_RISING>,
+					     <0x2 0x40 0x4 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x40 0x5
+							IRQ_TYPE_EDGE_RISING>,
+					     <0x2 0x40 0x6 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x40 0x7 IRQ_TYPE_EDGE_BOTH>;
+				interrupt-names = "soc-update",
+						  "soc-ready",
+						  "bsoc-delta",
+						  "msoc-delta",
+						  "msoc-low",
+						  "msoc-empty",
+						  "msoc-high",
+						  "msoc-full";
+			};
+
+			qcom,fg-batt-info@4100 {
+				status = "okay";
+				reg = <0x4100 0x100>;
+				interrupts = <0x2 0x41 0x0 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x41 0x1 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x41 0x3
+							IRQ_TYPE_EDGE_RISING>;
+				interrupt-names = "vbatt-low",
+						  "vbatt-pred-delta",
+						  "esr-delta";
+			};
+
+			qcom,fg-rradc@4200 {
+				status = "okay";
+				reg = <0x4200 0x100>;
+				interrupts = <0x2 0x42 0x0 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x42 0x1 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x42 0x2 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x42 0x3 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x42 0x4 IRQ_TYPE_EDGE_BOTH>;
+				interrupt-names = "batt-missing",
+						  "batt-id",
+						  "batt-temp-delta",
+						  "batt-temp-hot",
+						  "batt-temp-cold";
+			};
+
+			qcom,fg-memif@4300 {
+				status = "okay";
+				reg = <0x4300 0x100>;
+				interrupts = <0x2 0x43 0x0 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x43 0x1 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x43 0x2 IRQ_TYPE_EDGE_BOTH>,
+					     <0x2 0x43 0x3
+							IRQ_TYPE_EDGE_RISING>,
+					     <0x2 0x43 0x4
+							IRQ_TYPE_EDGE_FALLING>;
+				interrupt-names = "ima-rdy",
+						  "ima-xcp",
+						  "dma-xcp",
+						  "dma-grant",
+						  "mem-attn";
+			};
+		};
 	};
 
 	pmic@3 {
diff --git a/arch/arm64/boot/dts/qcom/sm8150-xiaomi-nabu-maverick.dts b/arch/arm64/boot/dts/qcom/sm8150-xiaomi-nabu-maverick.dts
index c32517345..9ec9a23ad 100644
--- a/arch/arm64/boot/dts/qcom/sm8150-xiaomi-nabu-maverick.dts
+++ b/arch/arm64/boot/dts/qcom/sm8150-xiaomi-nabu-maverick.dts
@@ -183,9 +183,17 @@ lcd_avee_5p5: lcd-avee-regulator {
 		regulator-enable-ramp-delay = <233>;
 		gpio = <&tlmm 115 0>;
 		enable-active-high;
-//		regulator-always-on;
+		regulator-always-on;
 		regulator-boot-on;
 	};
+
+	bat: battery {
+		compatible = "simple-battery";
+		constant-charge-current-max-microamp = <900000>;
+		constant-charge-voltage-max-microvolt = <4480000>;
+		precharge-current-microamp = <160000>;
+		charge-term-current-microamp = <160000>;
+	};
 };
 
 &pm8150_gpios {
@@ -809,6 +817,11 @@ xiaomi_keyboard {
 		xiaomi-keyboard,vdd-gpio = <&tlmm 82 0x00>;
 		status = "ok";
 	};
+
+	nabu_batterydata: qcom,battery-data {
+		qcom,batt-id-range-pct = <15>;
+		#include "fg-gen4-batterydata-nabu-sunwoda-8720mah.dtsi"
+	};
 };
 
 &wifi {
@@ -833,4 +846,55 @@ &pm8150_sdam_2 {
 	rtc_offset: rtc-offset@bc {
 		reg = <0xbc 0x4>;
 	};
-};
\ No newline at end of file
+};
+
+&pm8150b_fg {
+	status = "okay";
+
+	qcom,battery-data = <&nabu_batterydata>;
+	qcom,rapid-soc-dec-en;
+	qcom,soc-scale-mode-en;
+	qcom,five-pin-battery;
+	qcom,soc-hi-res;
+	qcom,soc_decimal_rate = <
+		0  38
+		10 35
+		20 33
+		30 33
+		40 33
+		50 33
+		60 33
+		70 30
+		80 25
+		90 20
+		95 10 >;
+	qcom,ki-coeff-low-chg = <315>;
+	qcom,ki-coeff-med-chg = <183>;
+	qcom,fg-sys-term-current = <(-500)>;
+	qcom,fg-ffc-sys-term-current = <(-1530)>;
+	qcom,fg-cutoff-voltage = <3400>;
+	qcom,fg-cutoff-current = <200>;
+	qcom,fg-empty-voltage = <3100>;
+	qcom,soc-scale-vbatt-mv = <3600>;
+	qcom,fg-batt-temp-delta = <6>;
+	qcom,fg-force-load-profile;
+	qcom,shutdown-delay-enable;
+	/* ESR fast calibration */
+	qcom,fg-esr-timer-chg-fast = <0 7>;
+	qcom,fg-esr-timer-dischg-fast = <0 96>;
+	qcom,fg-esr-timer-chg-slow = <0 96>;
+	qcom,fg-esr-timer-dischg-slow = <0 96>;
+	qcom,fg-esr-cal-soc-thresh = <26 230>;
+	qcom,fg-esr-cal-temp-thresh = <10 40>;
+	qcom,ki-coeff-chg-med-hi-thresh-ma = <1000>;
+	qcom,ki-coeff-chg-low-med-thresh-ma = <500>;
+	qcom,ffc-ki-coeff-chg-med-hi-thresh-ma = <3900>;
+	qcom,ffc-ki-coeff-chg-low-med-thresh-ma = <3500>;
+
+	nvmem-names = "fg_sdam";
+	nvmem = <&pm8150_sdam_2>;
+};
+
+&pm8150b_charger {
+	status = "okay";
+};
diff --git a/drivers/power/supply/Kconfig b/drivers/power/supply/Kconfig
index 0bbfe6a7c..c14ca6790 100644
--- a/drivers/power/supply/Kconfig
+++ b/drivers/power/supply/Kconfig
@@ -918,4 +918,6 @@ config BATTERY_UG3105
 	  device is off or suspended, the functionality of this driver is
 	  limited to reporting capacity only.
 
+source "drivers/power/supply/qcom/Kconfig"
+
 endif # POWER_SUPPLY
diff --git a/drivers/power/supply/Makefile b/drivers/power/supply/Makefile
index 0ee8653e8..004256271 100644
--- a/drivers/power/supply/Makefile
+++ b/drivers/power/supply/Makefile
@@ -110,3 +110,4 @@ obj-$(CONFIG_BATTERY_ACER_A500)	+= acer_a500_battery.o
 obj-$(CONFIG_BATTERY_SURFACE)	+= surface_battery.o
 obj-$(CONFIG_CHARGER_SURFACE)	+= surface_charger.o
 obj-$(CONFIG_BATTERY_UG3105)	+= ug3105_battery.o
+obj-$(CONFIG_ARCH_QCOM)         += qcom/
diff --git a/drivers/power/supply/qcom/Kconfig b/drivers/power/supply/qcom/Kconfig
new file mode 100644
index 000000000..90db8c390
--- /dev/null
+++ b/drivers/power/supply/qcom/Kconfig
@@ -0,0 +1,26 @@
+menu "Qualcomm Technologies, Inc. Charger and Fuel Gauge support"
+
+config QPNP_FG_GEN4
+        tristate "QPNP GEN4 fuel gauge driver"
+        depends on QPNP_SMB5_NABU
+        help
+          Say Y here to enable the GEN4 Fuel Gauge driver. This adds support
+          for battery fuel gauging and state of charge of battery connected to
+          the device that has QTI PMICs like PM8150B. The state of charge is
+          reported through a BMS power supply property and also sends uevents
+          when the capacity is updated.
+
+config QPNP_SMB5_NABU
+        tristate "SMB5 Battery Charger"
+        depends on MFD_SPMI_PMIC
+        help
+          Say Y to enables support for the SMB5 charging peripheral.
+          The QPNP SMB5 charger driver supports the charger peripheral
+          present in the chip.
+          The power supply framework is used to communicate battery and
+          usb properties to userspace and other driver consumers such
+          as fuel gauge, USB, and USB-PD.
+          VBUS and VCONN regulators are registered for supporting OTG,
+          and powered Type-C cables respectively.
+
+endmenu
diff --git a/drivers/power/supply/qcom/Makefile b/drivers/power/supply/qcom/Makefile
new file mode 100644
index 000000000..8bfa46c93
--- /dev/null
+++ b/drivers/power/supply/qcom/Makefile
@@ -0,0 +1,3 @@
+obj-$(CONFIG_QPNP_FG_GEN4)	+= qpnp-fg-gen4.o fg-util.o fg-memif.o fg-alg.o pmic-voter.o of_batterydata.o
+#obj-$(CONFIG_QPNP_SMB5_NABU)	+= qpnp-smb5-nabu.o smb5-lib-nabu.o pmic-voter.o
+obj-$(CONFIG_QPNP_SMB5_NABU)	+= pm8150b_charger.o smb5-lib.o
diff --git a/drivers/power/supply/qcom/batterydata-lib.h b/drivers/power/supply/qcom/batterydata-lib.h
new file mode 100644
index 000000000..95e7d7937
--- /dev/null
+++ b/drivers/power/supply/qcom/batterydata-lib.h
@@ -0,0 +1,232 @@
+/* Copyright (c) 2012-2015, 2017, 2019 The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __BMS_BATTERYDATA_H
+#define __BMS_BATTERYDATA_H
+
+#include <linux/errno.h>
+
+#define FCC_CC_COLS		5
+#define FCC_TEMP_COLS		8
+
+#define PC_CC_ROWS             31
+#define PC_CC_COLS             13
+
+#define PC_TEMP_ROWS		31
+#define PC_TEMP_COLS		8
+
+#define ACC_IBAT_ROWS		4
+#define ACC_TEMP_COLS		3
+
+#define MAX_SINGLE_LUT_COLS	20
+
+#define MAX_BATT_ID_NUM		4
+#define DEGC_SCALE		10
+
+struct single_row_lut {
+	int x[MAX_SINGLE_LUT_COLS];
+	int y[MAX_SINGLE_LUT_COLS];
+	int cols;
+};
+
+/**
+ * struct sf_lut -
+ * @rows:	number of percent charge entries should be <= PC_CC_ROWS
+ * @cols:	number of charge cycle entries should be <= PC_CC_COLS
+ * @row_entries:	the charge cycles/temperature at which sf data
+ *			is available in the table.
+ *		The charge cycles must be in increasing order from 0 to rows.
+ * @percent:	the percent charge at which sf data is available in the table
+ *		The  percentcharge must be in decreasing order from 0 to cols.
+ * @sf:		the scaling factor data
+ */
+struct sf_lut {
+	int rows;
+	int cols;
+	int row_entries[PC_CC_COLS];
+	int percent[PC_CC_ROWS];
+	int sf[PC_CC_ROWS][PC_CC_COLS];
+};
+
+/**
+ * struct pc_temp_ocv_lut -
+ * @rows:	number of percent charge entries should be <= PC_TEMP_ROWS
+ * @cols:	number of temperature entries should be <= PC_TEMP_COLS
+ * @temp:	the temperatures at which ocv data is available in the table
+ *		The temperatures must be in increasing order from 0 to rows.
+ * @percent:	the percent charge at which ocv data is available in the table
+ *		The  percentcharge must be in decreasing order from 0 to cols.
+ * @ocv:	the open circuit voltage
+ */
+struct pc_temp_ocv_lut {
+	int rows;
+	int cols;
+	int temp[PC_TEMP_COLS];
+	int percent[PC_TEMP_ROWS];
+	int ocv[PC_TEMP_ROWS][PC_TEMP_COLS];
+};
+
+struct ibat_temp_acc_lut {
+	int rows;
+	int cols;
+	int temp[ACC_TEMP_COLS];
+	int ibat[ACC_IBAT_ROWS];
+	int acc[ACC_IBAT_ROWS][ACC_TEMP_COLS];
+};
+
+struct batt_ids {
+	int kohm[MAX_BATT_ID_NUM];
+	int num;
+};
+
+enum battery_type {
+	BATT_UNKNOWN = 0,
+	BATT_PALLADIUM,
+	BATT_DESAY,
+	BATT_OEM,
+	BATT_QRD_4V35_2000MAH,
+	BATT_QRD_4V2_1300MAH,
+};
+
+/**
+ * struct bms_battery_data -
+ * @fcc:		full charge capacity (mAmpHour)
+ * @fcc_temp_lut:	table to get fcc at a given temp
+ * @pc_temp_ocv_lut:	table to get percent charge given batt temp and cycles
+ * @pc_sf_lut:		table to get percent charge scaling factor given cycles
+ *			and percent charge
+ * @rbatt_sf_lut:	table to get battery resistance scaling factor given
+ *			temperature and percent charge
+ * @default_rbatt_mohm:	the default value of battery resistance to use when
+ *			readings from bms are not available.
+ * @delta_rbatt_mohm:	the resistance to be added towards lower soc to
+ *			compensate for battery capacitance.
+ * @rbatt_capacitve_mohm: the resistance to be added to compensate for
+ *				battery capacitance
+ * @flat_ocv_threshold_uv: the voltage where the battery's discharge curve
+ *				starts flattening out.
+ * @max_voltage_uv:	max voltage of the battery
+ * @cutoff_uv:		cutoff voltage of the battery
+ * @iterm_ua:		termination current of the battery when charging
+ *			to 100%
+ * @batt_id_kohm:	the best matched battery id resistor value
+ * @fastchg_current_ma: maximum fast charge current
+ * @fg_cc_cv_threshold_mv: CC to CV threashold voltage
+ */
+
+struct bms_battery_data {
+	unsigned int		fcc;
+	struct single_row_lut	*fcc_temp_lut;
+	struct single_row_lut	*fcc_sf_lut;
+	struct pc_temp_ocv_lut	*pc_temp_ocv_lut;
+	struct ibat_temp_acc_lut *ibat_acc_lut;
+	struct sf_lut		*pc_sf_lut;
+	struct sf_lut		*rbatt_sf_lut;
+	int			default_rbatt_mohm;
+	int			delta_rbatt_mohm;
+	int			rbatt_capacitive_mohm;
+	int			flat_ocv_threshold_uv;
+	int			max_voltage_uv;
+	int			cutoff_uv;
+	int			iterm_ua;
+	int			batt_id_kohm;
+	int			fastchg_current_ma;
+	int			fg_cc_cv_threshold_mv;
+	const char		*battery_type;
+};
+
+/**
+ * struct soh_range -
+ * @batt_age_level:	Battery age level (e.g. 0, 1 etc.,)
+ * @soh_min:		Minimum SOH (state of health) level that this battery
+ *			profile can support.
+ * @soh_max:		Maximum SOH (state of health) level that this battery
+ *			profile can support.
+ */
+struct soh_range {
+	int	batt_age_level;
+	int	soh_min;
+	int	soh_max;
+};
+
+#define is_between(left, right, value) \
+		(((left) >= (right) && (left) >= (value) \
+			&& (value) >= (right)) \
+		|| ((left) <= (right) && (left) <= (value) \
+			&& (value) <= (right)))
+
+#if defined(CONFIG_PM8921_BMS) || \
+	defined(CONFIG_PM8921_BMS_MODULE) || \
+	defined(CONFIG_QPNP_BMS) || \
+	defined(CONFIG_QPNP_VM_BMS)
+extern struct bms_battery_data  palladium_1500_data;
+extern struct bms_battery_data  desay_5200_data;
+extern struct bms_battery_data  oem_batt_data;
+extern struct bms_battery_data QRD_4v35_2000mAh_data;
+extern struct bms_battery_data  qrd_4v2_1300mah_data;
+
+int interpolate_fcc(struct single_row_lut *fcc_temp_lut, int batt_temp);
+int interpolate_scalingfactor(struct sf_lut *sf_lut, int row_entry, int pc);
+int interpolate_scalingfactor_fcc(struct single_row_lut *fcc_sf_lut,
+				int cycles);
+int interpolate_pc(struct pc_temp_ocv_lut *pc_temp_ocv,
+				int batt_temp_degc, int ocv);
+int interpolate_ocv(struct pc_temp_ocv_lut *pc_temp_ocv,
+				int batt_temp_degc, int pc);
+int interpolate_slope(struct pc_temp_ocv_lut *pc_temp_ocv,
+					int batt_temp, int pc);
+int interpolate_acc(struct ibat_temp_acc_lut *ibat_acc_lut,
+					int batt_temp, int ibat);
+int linear_interpolate(int y0, int x0, int y1, int x1, int x);
+#else
+static inline int interpolate_fcc(struct single_row_lut *fcc_temp_lut,
+			int batt_temp)
+{
+	return -EINVAL;
+}
+static inline int interpolate_scalingfactor(struct sf_lut *sf_lut,
+			int row_entry, int pc)
+{
+	return -EINVAL;
+}
+static inline int interpolate_scalingfactor_fcc(
+			struct single_row_lut *fcc_sf_lut, int cycles)
+{
+	return -EINVAL;
+}
+static inline int interpolate_pc(struct pc_temp_ocv_lut *pc_temp_ocv,
+			int batt_temp_degc, int ocv)
+{
+	return -EINVAL;
+}
+static inline int interpolate_ocv(struct pc_temp_ocv_lut *pc_temp_ocv,
+			int batt_temp_degc, int pc)
+{
+	return -EINVAL;
+}
+static inline int interpolate_slope(struct pc_temp_ocv_lut *pc_temp_ocv,
+					int batt_temp, int pc)
+{
+	return -EINVAL;
+}
+static inline int linear_interpolate(int y0, int x0, int y1, int x1, int x)
+{
+	return -EINVAL;
+}
+static inline int interpolate_acc(struct ibat_temp_acc_lut *ibat_acc_lut,
+						int batt_temp, int ibat)
+{
+	return -EINVAL;
+}
+#endif
+
+#endif
diff --git a/drivers/power/supply/qcom/fg-alg.c b/drivers/power/supply/qcom/fg-alg.c
new file mode 100644
index 000000000..9ae045667
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-alg.c
@@ -0,0 +1,784 @@
+/* Copyright (c) 2018-2019, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt)	"ALG: %s: " fmt, __func__
+
+#include <linux/err.h>
+#include <linux/kernel.h>
+#include <linux/mutex.h>
+#include <linux/power_supply.h>
+#include <linux/slab.h>
+#include <linux/sort.h>
+#include "fg-alg.h"
+
+#define FULL_SOC_RAW		255
+#define CAPACITY_DELTA_DECIPCT	500
+#define CENTI_FULL_SOC		10000
+
+#define CENTI_ICORRECT_C0	105
+#define CENTI_ICORRECT_C1	20
+
+#define HOURS_TO_SECONDS	3600
+#define OCV_SLOPE_UV		10869
+#define MILLI_UNIT		1000
+#define MICRO_UNIT		1000000
+#define NANO_UNIT		1000000000
+
+/* Cycle counter APIs */
+
+/**
+ * restore_cycle_count -
+ * @counter: Cycle counter object
+ *
+ * Restores all the counters back from FG/QG during boot
+ *
+ */
+int restore_cycle_count(struct cycle_counter *counter)
+{
+	int rc = 0;
+
+	if (!counter)
+		return -ENODEV;
+
+	mutex_lock(&counter->lock);
+	rc = counter->restore_count(counter->data, counter->count,
+			BUCKET_COUNT);
+	if (rc < 0)
+		pr_err("failed to restore cycle counter rc=%d\n", rc);
+	mutex_unlock(&counter->lock);
+
+	return rc;
+}
+
+/**
+ * clear_cycle_count -
+ * @counter: Cycle counter object
+ *
+ * Clears all the counters stored by FG/QG when a battery is inserted
+ * or the profile is re-loaded.
+ *
+ */
+void clear_cycle_count(struct cycle_counter *counter)
+{
+	int rc = 0, i;
+
+	if (!counter)
+		return;
+
+	mutex_lock(&counter->lock);
+	memset(counter->count, 0, sizeof(counter->count));
+	for (i = 0; i < BUCKET_COUNT; i++) {
+		counter->started[i] = false;
+		counter->last_soc[i] = 0;
+	}
+
+	rc = counter->store_count(counter->data, counter->count, 0,
+			BUCKET_COUNT * 2);
+	if (rc < 0)
+		pr_err("failed to clear cycle counter rc=%d\n", rc);
+
+	mutex_unlock(&counter->lock);
+}
+
+/**
+ * store_cycle_count -
+ * @counter: Cycle counter object
+ * @id: Cycle counter bucket id
+ *
+ * Stores the cycle counter for a bucket in FG/QG.
+ *
+ */
+static int store_cycle_count(struct cycle_counter *counter, int id)
+{
+	int rc = 0;
+	u16 cyc_count;
+
+	if (!counter)
+		return -ENODEV;
+
+	if (id < 0 || (id > BUCKET_COUNT - 1)) {
+		pr_err("Invalid id %d\n", id);
+		return -EINVAL;
+	}
+
+	cyc_count = counter->count[id];
+	cyc_count++;
+
+	rc = counter->store_count(counter->data, &cyc_count, id, 2);
+	if (rc < 0) {
+		pr_err("failed to write cycle_count[%d] rc=%d\n",
+			id, rc);
+		return rc;
+	}
+
+	counter->count[id] = cyc_count;
+	pr_debug("Stored count %d in id %d\n", cyc_count, id);
+
+	return rc;
+}
+
+/**
+ * cycle_count_update -
+ * @counter: Cycle counter object
+ * @batt_soc: Battery State of Charge (SOC)
+ * @charge_status: Charging status from power supply
+ * @charge_done: Indicator for charge termination
+ * @input_present: Indicator for input presence
+ *
+ * Called by FG/QG whenever there is a state change (Charging status, SOC)
+ *
+ */
+void cycle_count_update(struct cycle_counter *counter, int batt_soc,
+			int charge_status, bool charge_done, bool input_present)
+{
+	int rc = 0, id, i, soc_thresh;
+
+	if (!counter)
+		return;
+
+	mutex_lock(&counter->lock);
+
+	/* Find out which id the SOC falls in */
+	id = batt_soc / BUCKET_SOC_PCT;
+
+	if (charge_status == POWER_SUPPLY_STATUS_CHARGING) {
+		if (!counter->started[id] && id != counter->last_bucket) {
+			counter->started[id] = true;
+			counter->last_soc[id] = batt_soc;
+		}
+	} else if (charge_done || !input_present) {
+		for (i = 0; i < BUCKET_COUNT; i++) {
+			soc_thresh = counter->last_soc[i] + BUCKET_SOC_PCT / 2;
+			if (counter->started[i] && batt_soc > soc_thresh) {
+				rc = store_cycle_count(counter, i);
+				if (rc < 0)
+					pr_err("Error in storing cycle_ctr rc: %d\n",
+						rc);
+				counter->last_soc[i] = 0;
+				counter->started[i] = false;
+				counter->last_bucket = i;
+			}
+		}
+	}
+
+	pr_debug("batt_soc: %d id: %d chg_status: %d\n", batt_soc, id,
+		charge_status);
+	mutex_unlock(&counter->lock);
+}
+
+/**
+ * get_bucket_cycle_count -
+ * @counter: Cycle counter object
+ *
+ * Returns the cycle counter for a SOC bucket.
+ *
+ */
+static int get_bucket_cycle_count(struct cycle_counter *counter)
+{
+	int count;
+
+	if (!counter)
+		return 0;
+
+	if ((counter->id <= 0) || (counter->id > BUCKET_COUNT))
+		return -EINVAL;
+
+	mutex_lock(&counter->lock);
+	count = counter->count[counter->id - 1];
+	mutex_unlock(&counter->lock);
+	return count;
+}
+
+/**
+ * get_cycle_count -
+ * @counter: Cycle counter object
+ * @count: Average cycle count returned to the caller
+ *
+ * Get average cycle count for all buckets
+ *
+ */
+int get_cycle_count(struct cycle_counter *counter, int *count)
+{
+	int i, rc, temp = 0;
+
+	for (i = 1; i <= BUCKET_COUNT; i++) {
+		counter->id = i;
+		rc = get_bucket_cycle_count(counter);
+		if (rc < 0) {
+			pr_err("Couldn't get cycle count rc=%d\n", rc);
+			return rc;
+		}
+		temp += rc;
+	}
+
+	/*
+	 * Normalize the counter across each bucket so that we can get
+	 * the overall charge cycle count.
+	 */
+
+	*count = temp / BUCKET_COUNT;
+	return 0;
+}
+
+ /**
+ * set_cycle_count -
+ * @counter: Cycle counter object
+ * @value: The cycle count value to be set
+ *
+ * Get average cycle count for all buckets
+ *
+ */
+int set_cycle_count(struct cycle_counter *counter, u16 count)
+{
+	int rc, id;
+
+	for (id = 0; id < BUCKET_COUNT; id++) {
+		rc = counter->store_count(counter->data, &count, id, 2);
+		if (rc < 0)
+			pr_err("failed to clear cycle counter rc=%d\n", rc);
+	}
+
+	return 0;
+}
+
+ /**
+ * cycle_count_init -
+ * @counter: Cycle counter object
+ *
+ * FG/QG have to call this during driver probe to validate the required
+ * parameters after allocating cycle_counter object.
+ *
+ */
+int cycle_count_init(struct cycle_counter *counter)
+{
+	if (!counter)
+		return -ENODEV;
+
+	if (!counter->data || !counter->restore_count ||
+		!counter->store_count) {
+		pr_err("Invalid parameters for using cycle counter\n");
+		return -EINVAL;
+	}
+
+	mutex_init(&counter->lock);
+	counter->last_bucket = -1;
+	return 0;
+}
+
+/* Capacity learning algorithm APIs */
+
+/**
+ * cap_learning_post_process -
+ * @cl: Capacity learning object
+ *
+ * Does post processing on the learnt capacity based on the user specified
+ * or default parameters for the capacity learning algorithm.
+ *
+ */
+static void cap_learning_post_process(struct cap_learning *cl)
+{
+	int64_t max_inc_val, min_dec_val, old_cap;
+	int rc;
+
+	if (cl->dt.skew_decipct) {
+		pr_debug("applying skew %d on current learnt capacity %lld\n",
+			cl->dt.skew_decipct, cl->final_cap_uah);
+		cl->final_cap_uah = cl->final_cap_uah *
+					(1000 + cl->dt.skew_decipct);
+		cl->final_cap_uah = div64_u64(cl->final_cap_uah, 1000);
+	}
+
+	max_inc_val = cl->learned_cap_uah * (1000 + cl->dt.max_cap_inc);
+	max_inc_val = div64_u64(max_inc_val, 1000);
+
+	min_dec_val = cl->learned_cap_uah * (1000 - cl->dt.max_cap_dec);
+	min_dec_val = div64_u64(min_dec_val, 1000);
+
+	old_cap = cl->learned_cap_uah;
+	if (cl->final_cap_uah > max_inc_val)
+		cl->learned_cap_uah = max_inc_val;
+	else if (cl->final_cap_uah < min_dec_val)
+		cl->learned_cap_uah = min_dec_val;
+	else
+		cl->learned_cap_uah = cl->final_cap_uah;
+
+	if (cl->dt.max_cap_limit) {
+		max_inc_val = (int64_t)cl->nom_cap_uah * (1000 +
+				cl->dt.max_cap_limit);
+		max_inc_val = div64_u64(max_inc_val, 1000);
+		if (cl->final_cap_uah > max_inc_val) {
+			pr_debug("learning capacity %lld goes above max limit %lld\n",
+				cl->final_cap_uah, max_inc_val);
+			cl->learned_cap_uah = max_inc_val;
+		}
+	}
+
+	if (cl->dt.min_cap_limit) {
+		min_dec_val = (int64_t)cl->nom_cap_uah * (1000 -
+				cl->dt.min_cap_limit);
+		min_dec_val = div64_u64(min_dec_val, 1000);
+		if (cl->final_cap_uah < min_dec_val) {
+			pr_debug("learning capacity %lld goes below min limit %lld\n",
+				cl->final_cap_uah, min_dec_val);
+			cl->learned_cap_uah = min_dec_val;
+		}
+	}
+
+	if (cl->store_learned_capacity) {
+		rc = cl->store_learned_capacity(cl->data, cl->learned_cap_uah);
+		if (rc < 0)
+			pr_err("Error in storing learned_cap_uah, rc=%d\n", rc);
+	}
+
+	pr_debug("final cap_uah = %lld, learned capacity %lld -> %lld uah\n",
+		cl->final_cap_uah, old_cap, cl->learned_cap_uah);
+}
+
+/**
+ * cap_wt_learning_process_full_data -
+ * @cl: Capacity learning object
+ * @delta_batt_soc_pct: percentage change in battery State of Charge
+ * @batt_soc_cp: Battery State of Charge in centi-percentage
+ *
+ * Calculates the final learnt capacity when
+ * weighted capacity learning is enabled.
+ *
+ */
+static int cap_wt_learning_process_full_data(struct cap_learning *cl,
+					int delta_batt_soc_pct,
+					int batt_soc_cp)
+{
+	int64_t del_cap_uah, total_cap_uah,
+		res_cap_uah, wt_learnt_cap_uah;
+	int delta_batt_soc_cp, res_batt_soc_cp;
+
+	/* If the delta is < 10%, then skip processing full data */
+	if (delta_batt_soc_pct < cl->dt.min_delta_batt_soc) {
+		pr_debug("batt_soc_delta_pct: %d\n", delta_batt_soc_pct);
+		return -ERANGE;
+	}
+
+	delta_batt_soc_cp = batt_soc_cp - cl->init_batt_soc_cp;
+	res_batt_soc_cp = CENTI_FULL_SOC - batt_soc_cp;
+	/* Learnt Capacity from end Battery SOC to CENTI_FULL_SOC */
+	res_cap_uah = div64_s64(cl->learned_cap_uah *
+				res_batt_soc_cp, CENTI_FULL_SOC);
+	total_cap_uah = cl->init_cap_uah + cl->delta_cap_uah + res_cap_uah;
+	/*
+	 * difference in capacity learnt in this
+	 * charge cycle and previous learnt capacity
+	 */
+	del_cap_uah = total_cap_uah - cl->learned_cap_uah;
+	/* Applying weight based on change in battery SOC MSB */
+	wt_learnt_cap_uah = div64_s64(del_cap_uah * delta_batt_soc_cp,
+					CENTI_FULL_SOC);
+	cl->final_cap_uah = cl->learned_cap_uah + wt_learnt_cap_uah;
+
+	pr_debug("wt_learnt_cap_uah=%lld, del_cap_uah=%lld\n",
+			wt_learnt_cap_uah, del_cap_uah);
+	pr_debug("init_cap_uah=%lld, total_cap_uah=%lld, res_cap_uah=%lld, delta_cap_uah=%lld\n",
+			cl->init_cap_uah, cl->final_cap_uah,
+			res_cap_uah, cl->delta_cap_uah);
+	return 0;
+}
+
+/**
+ * cap_learning_process_full_data -
+ * @cl: Capacity learning object
+ * @batt_soc_cp: Battery State of Charge in centi-percentage
+ *
+ * Processes the coulomb counter during charge termination and calculates the
+ * delta w.r.to the coulomb counter obtained earlier when the learning begun.
+ *
+ */
+static int cap_learning_process_full_data(struct cap_learning *cl,
+					int batt_soc_cp)
+{
+	int rc, cc_soc_sw, cc_soc_delta_pct, delta_batt_soc_pct, batt_soc_pct,
+		cc_soc_fraction;
+	int64_t cc_soc_cap_uah, cc_soc_fraction_uah;
+
+	rc = cl->get_cc_soc(cl->data, &cc_soc_sw);
+	if (rc < 0) {
+		pr_err("Error in getting CC_SOC_SW, rc=%d\n", rc);
+		return rc;
+	}
+
+	batt_soc_pct = DIV_ROUND_CLOSEST(batt_soc_cp, 100);
+	delta_batt_soc_pct = batt_soc_pct - cl->init_batt_soc;
+	cc_soc_delta_pct =
+		div_s64_rem((int64_t)(cc_soc_sw - cl->init_cc_soc_sw) * 100,
+				cl->cc_soc_max, &cc_soc_fraction);
+	cc_soc_fraction_uah = div64_s64(cl->learned_cap_uah *
+				cc_soc_fraction, (int64_t)cl->cc_soc_max * 100);
+	cc_soc_cap_uah = div64_s64(cl->learned_cap_uah * cc_soc_delta_pct, 100);
+	cl->delta_cap_uah = cc_soc_cap_uah + cc_soc_fraction_uah;
+	pr_debug("cc_soc_delta_pct=%d, cc_soc_cap_uah=%lld, cc_soc_fraction_uah=%lld\n",
+			cc_soc_delta_pct, cc_soc_cap_uah, cc_soc_fraction_uah);
+
+	if (cl->dt.cl_wt_enable) {
+		rc = cap_wt_learning_process_full_data(cl, delta_batt_soc_pct,
+							batt_soc_cp);
+		return rc;
+	}
+
+	/* If the delta is < 50%, then skip processing full data */
+	if (cc_soc_delta_pct < 50) {
+		pr_err("cc_soc_delta_pct: %d\n", cc_soc_delta_pct);
+		return -ERANGE;
+	}
+
+	cl->final_cap_uah = cl->init_cap_uah + cl->delta_cap_uah;
+	pr_debug("Current cc_soc=%d cc_soc_delta_pct=%d total_cap_uah=%lld\n",
+		cc_soc_sw, cc_soc_delta_pct, cl->final_cap_uah);
+	return 0;
+}
+
+/**
+ * cap_learning_begin -
+ * @cl: Capacity learning object
+ * @batt_soc_cp: Battery State of Charge in centi-percentage
+ *
+ * Gets the coulomb counter from FG/QG when the conditions are suitable for
+ * beginning capacity learning. Also, primes the coulomb counter based on
+ * battery SOC if required.
+ *
+ */
+#define BATT_SOC_32BIT	GENMASK(31, 0)
+static int cap_learning_begin(struct cap_learning *cl, u32 batt_soc_cp)
+{
+	int rc, cc_soc_sw, batt_soc_pct;
+	u32 batt_soc_prime;
+
+	if (cl->ok_to_begin && !cl->ok_to_begin(cl->data)) {
+		pr_debug("Not OK to begin\n");
+		return -EINVAL;
+	}
+
+	batt_soc_pct = DIV_ROUND_CLOSEST(batt_soc_cp, 100);
+
+	if ((cl->dt.max_start_soc != -EINVAL &&
+			batt_soc_pct > cl->dt.max_start_soc) ||
+			(cl->dt.min_start_soc != -EINVAL &&
+			batt_soc_pct < cl->dt.min_start_soc)) {
+		pr_debug("Battery SOC %d is high/low, not starting\n",
+					batt_soc_pct);
+		return -EINVAL;
+	}
+
+	cl->init_cap_uah = div64_s64(cl->learned_cap_uah * batt_soc_cp,
+					CENTI_FULL_SOC);
+
+	if (cl->prime_cc_soc) {
+		/*
+		 * Prime cc_soc_sw with battery SOC when capacity learning
+		 * begins.
+		 */
+		batt_soc_prime = div64_u64(
+				(uint64_t)batt_soc_cp * BATT_SOC_32BIT,
+							CENTI_FULL_SOC);
+		rc = cl->prime_cc_soc(cl->data, batt_soc_prime);
+		if (rc < 0) {
+			pr_err("Error in writing cc_soc_sw, rc=%d\n", rc);
+			goto out;
+		}
+	}
+
+	rc = cl->get_cc_soc(cl->data, &cc_soc_sw);
+	if (rc < 0) {
+		pr_err("Error in getting CC_SOC_SW, rc=%d\n", rc);
+		goto out;
+	}
+
+	cl->init_cc_soc_sw = cc_soc_sw;
+	cl->init_batt_soc = batt_soc_pct;
+	cl->init_batt_soc_cp = batt_soc_cp;
+	pr_debug("Capacity learning started @ battery SOC %d init_cc_soc_sw:%d\n",
+		batt_soc_cp, cl->init_cc_soc_sw);
+out:
+	return rc;
+}
+
+/**
+ * cap_learning_done -
+ * @cl: Capacity learning object
+ * @batt_soc_cp: Battery State of Charge in centi-percentage
+ *
+ * Top level function for getting coulomb counter and post processing the
+ * data once the capacity learning is complete after charge termination.
+ *
+ */
+static int cap_learning_done(struct cap_learning *cl, int batt_soc_cp)
+{
+	int rc;
+
+	rc = cap_learning_process_full_data(cl, batt_soc_cp);
+	if (rc < 0) {
+		pr_debug("Error in processing cap learning full data, rc=%d\n",
+			rc);
+		goto out;
+	}
+
+	if (cl->prime_cc_soc) {
+		/* Write a FULL value to cc_soc_sw */
+		rc = cl->prime_cc_soc(cl->data, cl->cc_soc_max);
+		if (rc < 0) {
+			pr_err("Error in writing cc_soc_sw, rc=%d\n", rc);
+			goto out;
+		}
+	}
+
+	cap_learning_post_process(cl);
+out:
+	return rc;
+}
+
+/**
+ * cap_wt_learning_update -
+ * @cl: Capacity learning object
+ * @batt_soc_cp: Battery State of Charge in centi-percentage
+ * @input_present: Indicator for input presence
+ *
+ * Called by cap_learning_update when weighted learning is enabled
+ *
+ */
+static void cap_wt_learning_update(struct cap_learning *cl, int batt_soc_cp,
+					bool input_present)
+{
+	int rc;
+
+	if (!input_present) {
+		rc = cap_learning_done(cl, batt_soc_cp);
+		if (rc < 0)
+			pr_debug("Error in completing capacity learning, rc=%d\n",
+				rc);
+		cl->active = false;
+		cl->init_cap_uah = 0;
+	}
+}
+
+/**
+ * cap_learning_update -
+ * @cl: Capacity learning object
+ * @batt_temp - Battery temperature
+ * @batt_soc: Battery State of Charge (SOC)
+ * @charge_status: Charging status from power supply
+ * @charge_done: Indicator for charge termination
+ * @input_present: Indicator for input presence
+ * @qnovo_en: Indicator for Qnovo enable status
+ *
+ * Called by FG/QG driver when there is a state change (Charging status, SOC)
+ *
+ */
+void cap_learning_update(struct cap_learning *cl, int batt_temp,
+			int batt_soc_cp, int charge_status, bool charge_done,
+			bool input_present, bool qnovo_en)
+{
+	int rc;
+	u32 batt_soc_prime;
+	bool prime_cc = false;
+
+	if (!cl)
+		return;
+
+	mutex_lock(&cl->lock);
+
+	if (batt_temp > cl->dt.max_temp || batt_temp < cl->dt.min_temp ||
+		!cl->learned_cap_uah) {
+		cl->active = false;
+		cl->init_cap_uah = 0;
+		goto out;
+	}
+
+	pr_debug("Charge_status: %d active: %d batt_soc: %d\n",
+		charge_status, cl->active, batt_soc_cp);
+
+	if (cl->active && cl->dt.cl_wt_enable)
+		cap_wt_learning_update(cl, batt_soc_cp, input_present);
+
+	/* Initialize the starting point of learning capacity */
+	if (!cl->active) {
+		if (charge_status == POWER_SUPPLY_STATUS_CHARGING) {
+			rc = cap_learning_begin(cl, batt_soc_cp);
+			cl->active = (rc == 0);
+		} else {
+			if (charge_status == POWER_SUPPLY_STATUS_DISCHARGING ||
+				charge_done)
+				prime_cc = true;
+		}
+	} else {
+		if (charge_done) {
+			rc = cap_learning_done(cl, batt_soc_cp);
+			if (rc < 0)
+				pr_err("Error in completing capacity learning, rc=%d\n",
+					rc);
+
+			cl->active = false;
+			cl->init_cap_uah = 0;
+		}
+
+		if (charge_status == POWER_SUPPLY_STATUS_DISCHARGING &&
+				!input_present) {
+			pr_debug("Capacity learning aborted @ battery SOC %d\n",
+				 batt_soc_cp);
+			cl->active = false;
+			cl->init_cap_uah = 0;
+			prime_cc = true;
+		}
+
+		if (charge_status == POWER_SUPPLY_STATUS_NOT_CHARGING &&
+				!cl->dt.cl_wt_enable) {
+			if (qnovo_en && input_present) {
+				/*
+				 * Don't abort the capacity learning when qnovo
+				 * is enabled and input is present where the
+				 * charging status can go to "not charging"
+				 * intermittently.
+				 */
+			} else {
+				pr_debug("Capacity learning aborted @ battery SOC %d\n",
+					batt_soc_cp);
+				cl->active = false;
+				cl->init_cap_uah = 0;
+				prime_cc = true;
+			}
+		}
+	}
+
+	/*
+	 * Prime CC_SOC_SW when the device is not charging or during charge
+	 * termination when the capacity learning is not active.
+	 */
+
+	if (prime_cc && cl->prime_cc_soc) {
+		/* pass 32-bit batt_soc to the priming logic */
+		if (charge_done)
+			batt_soc_prime = cl->cc_soc_max;
+		else
+			batt_soc_prime = div64_u64(
+				(uint64_t)batt_soc_cp * BATT_SOC_32BIT,
+							CENTI_FULL_SOC);
+
+		rc = cl->prime_cc_soc(cl->data, batt_soc_prime);
+		if (rc < 0)
+			pr_err("Error in writing cc_soc_sw, rc=%d\n",
+				rc);
+	}
+
+out:
+	mutex_unlock(&cl->lock);
+}
+
+/**
+ * cap_learning_abort -
+ * @cl: Capacity learning object
+ *
+ * Aborts the capacity learning and initializes variables
+ *
+ */
+void cap_learning_abort(struct cap_learning *cl)
+{
+	if (!cl)
+		return;
+
+	mutex_lock(&cl->lock);
+	pr_debug("Aborting cap_learning\n");
+	cl->active = false;
+	cl->init_cap_uah = 0;
+	mutex_lock(&cl->lock);
+}
+
+/**
+ * cap_learning_post_profile_init -
+ * @cl: Capacity learning object
+ * @nom_cap_uah: Nominal capacity of battery in uAh
+ *
+ * Called by FG/QG once the profile load is complete and nominal capacity
+ * of battery is known. This also gets the last learned capacity back from
+ * FG/QG to feed back to the algorithm.
+ *
+ */
+int cap_learning_post_profile_init(struct cap_learning *cl, int64_t nom_cap_uah)
+{
+	int64_t delta_cap_uah, pct_nom_cap_uah;
+	int rc;
+
+	if (!cl || !cl->data)
+		return -EINVAL;
+
+	mutex_lock(&cl->lock);
+	cl->nom_cap_uah = nom_cap_uah;
+	rc = cl->get_learned_capacity(cl->data, &cl->learned_cap_uah);
+	if (rc < 0) {
+		pr_err("Couldn't get learned capacity, rc=%d\n", rc);
+		goto out;
+	}
+
+	if (cl->learned_cap_uah != cl->nom_cap_uah) {
+		if (cl->learned_cap_uah == 0)
+			cl->learned_cap_uah = cl->nom_cap_uah;
+
+		delta_cap_uah = abs(cl->learned_cap_uah - cl->nom_cap_uah);
+		pct_nom_cap_uah = div64_s64((int64_t)cl->nom_cap_uah *
+				CAPACITY_DELTA_DECIPCT, 1000);
+		/*
+		 * If the learned capacity is out of range by 50% from the
+		 * nominal capacity, then overwrite the learned capacity with
+		 * the nominal capacity.
+		 */
+		if (cl->nom_cap_uah && delta_cap_uah > pct_nom_cap_uah) {
+			pr_debug("learned_cap_uah: %lld is higher than expected, capping it to nominal: %lld\n",
+				cl->learned_cap_uah, cl->nom_cap_uah);
+			cl->learned_cap_uah = cl->nom_cap_uah;
+		}
+
+		rc = cl->store_learned_capacity(cl->data, cl->learned_cap_uah);
+		if (rc < 0)
+			pr_err("Error in storing learned_cap_uah, rc=%d\n", rc);
+	}
+
+out:
+	mutex_unlock(&cl->lock);
+	return rc;
+}
+
+/**
+ * cap_learning_init -
+ * @cl: Capacity learning object
+ *
+ * FG/QG have to call this during driver probe to validate the required
+ * parameters after allocating cap_learning object.
+ *
+ */
+int cap_learning_init(struct cap_learning *cl)
+{
+	if (!cl)
+		return -ENODEV;
+
+	if (!cl->get_learned_capacity || !cl->store_learned_capacity ||
+		!cl->get_cc_soc) {
+		pr_err("Insufficient functions for supporting capacity learning\n");
+		return -EINVAL;
+	}
+
+	if (!cl->cc_soc_max) {
+		pr_err("Insufficient parameters for supporting capacity learning\n");
+		return -EINVAL;
+	}
+
+	mutex_init(&cl->lock);
+	return 0;
+}
+EXPORT_SYMBOL(cap_learning_init);
+
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/power/supply/qcom/fg-alg.h b/drivers/power/supply/qcom/fg-alg.h
new file mode 100644
index 000000000..54f49b631
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-alg.h
@@ -0,0 +1,100 @@
+/* Copyright (c) 2018-2019, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __FG_ALG_H__
+#define __FG_ALG_H__
+
+#include "of_batterydata.h"
+#include "step-chg-jeita.h"
+
+#define BUCKET_COUNT		8
+#define BUCKET_SOC_PCT		(256 / BUCKET_COUNT)
+#define MAX_CC_STEPS		20
+#define MAX_TTF_SAMPLES		10
+
+#define is_between(left, right, value) \
+		(((left) >= (right) && (left) >= (value) \
+			&& (value) >= (right)) \
+		|| ((left) <= (right) && (left) <= (value) \
+			&& (value) <= (right)))
+struct cycle_counter {
+	void		*data;
+	char		str_buf[BUCKET_COUNT * 8];
+	bool		started[BUCKET_COUNT];
+	u16		count[BUCKET_COUNT];
+	u8		last_soc[BUCKET_COUNT];
+	int		id;
+	int		last_bucket;
+	struct mutex	lock;
+	int (*restore_count)(void *data, u16 *buf, int num_bytes);
+	int (*store_count)(void *data, u16 *buf, int id, int num_bytes);
+};
+
+struct cl_params {
+	int	min_start_soc;
+	int	max_start_soc;
+	int	max_temp;
+	int	min_temp;
+	int	max_cap_inc;
+	int	max_cap_dec;
+	int	max_cap_limit;
+	int	min_cap_limit;
+	int	skew_decipct;
+	int	min_delta_batt_soc;
+	int	ibat_flt_thr_ma;
+	bool	cl_wt_enable;
+};
+
+struct cap_learning {
+	void			*data;
+	int			init_cc_soc_sw;
+	int			cc_soc_max;
+	int			init_batt_soc;
+	int			init_batt_soc_cp;
+	int64_t			nom_cap_uah;
+	int64_t			init_cap_uah;
+	int64_t			final_cap_uah;
+	int64_t			learned_cap_uah;
+	int64_t			delta_cap_uah;
+	bool			active;
+	struct mutex		lock;
+	struct cl_params	dt;
+	bool (*ok_to_begin)(void *data);
+	int (*get_learned_capacity)(void *data, int64_t *learned_cap_uah);
+	int (*store_learned_capacity)(void *data, int64_t learned_cap_uah);
+	int (*get_cc_soc)(void *data, int *cc_soc_sw);
+	int (*prime_cc_soc)(void *data, u32 cc_soc_sw);
+};
+
+struct step_chg_data {
+	int ocv;
+	int soc;
+};
+
+int restore_cycle_count(struct cycle_counter *counter);
+void clear_cycle_count(struct cycle_counter *counter);
+void cycle_count_update(struct cycle_counter *counter, int batt_soc,
+		int charge_status, bool charge_done, bool input_present);
+int get_cycle_count(struct cycle_counter *counter, int *count);
+int get_cycle_counts(struct cycle_counter *counter, const char **buf);
+int set_cycle_count(struct cycle_counter *counter, u16 count);
+int cycle_count_init(struct cycle_counter *counter);
+void cap_learning_abort(struct cap_learning *cl);
+void cap_learning_update(struct cap_learning *cl, int batt_temp,
+		int batt_soc, int charge_status, bool charge_done,
+		bool input_present, bool qnovo_en);
+int cap_learning_init(struct cap_learning *cl);
+int cap_learning_post_profile_init(struct cap_learning *cl,
+		int64_t nom_cap_uah);
+
+#endif
diff --git a/drivers/power/supply/qcom/fg-core.h b/drivers/power/supply/qcom/fg-core.h
new file mode 100644
index 000000000..50073772f
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-core.h
@@ -0,0 +1,673 @@
+/* Copyright (c) 2016-2019, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __FG_CORE_H__
+#define __FG_CORE_H__
+
+#include <linux/alarmtimer.h>
+#include <linux/atomic.h>
+#include <linux/bitops.h>
+#include <linux/debugfs.h>
+#include <linux/delay.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/alarmtimer.h>
+#include <linux/power_supply.h>
+#include <linux/regmap.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/string_helpers.h>
+#include <linux/types.h>
+#include <linux/uaccess.h>
+#include "pmic-voter.h"
+
+#define fg_dbg(fg, reason, fmt, ...)			\
+	do {							\
+		if (*fg->debug_mask & (reason))		\
+			pr_info(fmt, ##__VA_ARGS__);	\
+		else						\
+			pr_debug(fmt, ##__VA_ARGS__);	\
+	} while (0)
+
+#define is_between(left, right, value) \
+		(((left) >= (right) && (left) >= (value) \
+			&& (value) >= (right)) \
+		|| ((left) <= (right) && (left) <= (value) \
+			&& (value) <= (right)))
+
+#define PARAM(_id, _addr_word, _addr_byte, _len, _num, _den, _offset,	\
+	      _enc, _dec)						\
+	[FG_SRAM_##_id] = {						\
+		.addr_word	= _addr_word,				\
+		.addr_byte	= _addr_byte,				\
+		.len		= _len,					\
+		.numrtr		= _num,					\
+		.denmtr		= _den,					\
+		.offset		= _offset,				\
+		.encode		= _enc,					\
+		.decode		= _dec,					\
+	}								\
+
+/* Awake votable reasons */
+#define SRAM_READ		"fg_sram_read"
+#define SRAM_WRITE		"fg_sram_write"
+#define PROFILE_LOAD		"fg_profile_load"
+#define TTF_PRIMING		"fg_ttf_priming"
+#define ESR_CALIB		"fg_esr_calib"
+#define FG_ESR_VOTER		"fg_esr_voter"
+
+/* Delta BSOC irq votable reasons */
+#define DELTA_BSOC_IRQ_VOTER	"fg_delta_bsoc_irq"
+
+/* Delta ESR irq votable reasons */
+#define DELTA_ESR_IRQ_VOTER	"fg_delta_esr_irq"
+
+/* Battery missing irq votable reasons */
+#define BATT_MISS_IRQ_VOTER	"fg_batt_miss_irq"
+
+#define ESR_FCC_VOTER		"fg_esr_fcc"
+
+#define FG_PARALLEL_EN_VOTER	"fg_parallel_en"
+#define MEM_ATTN_IRQ_VOTER	"fg_mem_attn_irq"
+
+#define DEBUG_BOARD_VOTER	"fg_debug_board"
+
+#define BUCKET_COUNT			8
+#define BUCKET_SOC_PCT			(256 / BUCKET_COUNT)
+
+#define MAX_CC_STEPS			20
+
+#define FULL_CAPACITY			100
+#define FULL_SOC_RAW			255
+#define FULL_SOC_REPORT_THR		250
+
+#define DEBUG_BATT_SOC			67
+#define BATT_MISS_SOC			50
+#define ESR_SOH_SOC			50
+#define EMPTY_SOC			0
+
+#define VBAT_RESTART_FG_EMPTY_UV		3700000
+#define TEMP_THR_RESTART_FG		150
+#define RESTART_FG_START_WORK_MS		1000
+#define RESTART_FG_WORK_MS		2000
+#define EMPTY_REPORT_SOC		1
+
+#define VBAT_CRITICAL_LOW_THR		2800
+#define EMPTY_DEBOUNCE_TIME_COUNT_MAX		5
+
+enum prof_load_status {
+	PROFILE_MISSING,
+	PROFILE_LOADED,
+	PROFILE_SKIPPED,
+	PROFILE_NOT_LOADED,
+};
+
+/* Debug flag definitions */
+enum fg_debug_flag {
+	FG_IRQ			= BIT(0), /* Show interrupts */
+	FG_STATUS		= BIT(1), /* Show FG status changes */
+	FG_POWER_SUPPLY		= BIT(2), /* Show POWER_SUPPLY */
+	FG_SRAM_WRITE		= BIT(3), /* Show SRAM writes */
+	FG_SRAM_READ		= BIT(4), /* Show SRAM reads */
+	FG_BUS_WRITE		= BIT(5), /* Show REGMAP writes */
+	FG_BUS_READ		= BIT(6), /* Show REGMAP reads */
+	FG_CAP_LEARN		= BIT(7), /* Show capacity learning */
+	FG_TTF			= BIT(8), /* Show time to full */
+	FG_FVSS			= BIT(9), /* Show FVSS */
+};
+
+enum awake_reasons {
+	FG_SW_ESR_WAKE = BIT(0),
+	FG_STATUS_NOTIFY_WAKE = BIT(1),
+};
+
+/* SRAM access */
+enum sram_access_flags {
+	FG_IMA_DEFAULT	= 0,
+	FG_IMA_ATOMIC	= BIT(0),
+	FG_IMA_NO_WLOCK	= BIT(1),
+};
+
+/* JEITA */
+enum jeita_levels {
+	JEITA_COLD = 0,
+	JEITA_COOL,
+	JEITA_WARM,
+	JEITA_HOT,
+	NUM_JEITA_LEVELS,
+};
+
+/* FG irqs */
+enum fg_irq_index {
+	/* FG_BATT_SOC */
+	MSOC_FULL_IRQ = 0,
+	MSOC_HIGH_IRQ,
+	MSOC_EMPTY_IRQ,
+	MSOC_LOW_IRQ,
+	MSOC_DELTA_IRQ,
+	BSOC_DELTA_IRQ,
+	SOC_READY_IRQ,
+	SOC_UPDATE_IRQ,
+	/* FG_BATT_INFO */
+	BATT_TEMP_DELTA_IRQ,
+	BATT_MISSING_IRQ,
+	ESR_DELTA_IRQ,
+	VBATT_LOW_IRQ,
+	VBATT_PRED_DELTA_IRQ,
+	/* FG_MEM_IF */
+	DMA_GRANT_IRQ,
+	MEM_XCP_IRQ,
+	IMA_RDY_IRQ,
+	FG_GEN3_IRQ_MAX,
+	/* GEN4 FG_MEM_IF */
+	MEM_ATTN_IRQ,
+	DMA_XCP_IRQ,
+	/* GEN4 FG_ADC_RR */
+	BATT_TEMP_COLD_IRQ,
+	BATT_TEMP_HOT_IRQ,
+	BATT_ID_IRQ,
+	FG_GEN4_IRQ_MAX,
+};
+
+/*
+ * List of FG_SRAM parameters. Please add a parameter only if it is an entry
+ * that will be used either to configure an entity (e.g. termination current)
+ * which might need some encoding (or) it is an entry that will be read from
+ * SRAM and decoded (e.g. CC_SOC_SW) for SW to use at various places. For
+ * generic read/writes to SRAM registers, please use fg_sram_read/write APIs
+ * directly without adding an entry here.
+ */
+enum fg_sram_param_id {
+	FG_SRAM_BATT_SOC = 0,
+	FG_SRAM_FULL_SOC,
+	FG_SRAM_MONOTONIC_SOC,
+	FG_SRAM_VOLTAGE_PRED,
+	FG_SRAM_OCV,
+	FG_SRAM_VBAT_FLT,
+	FG_SRAM_VBAT_TAU,
+	FG_SRAM_VBAT_FINAL,
+	FG_SRAM_IBAT_FINAL,
+	FG_SRAM_IBAT_FLT,
+	FG_SRAM_ESR,
+	FG_SRAM_ESR_MDL,
+	FG_SRAM_ESR_ACT,
+	FG_SRAM_RSLOW,
+	FG_SRAM_ALG_FLAGS,
+	FG_SRAM_CC_SOC,
+	FG_SRAM_CC_SOC_SW,
+	FG_SRAM_ACT_BATT_CAP,
+	FG_SRAM_TIMEBASE,
+	/* Entries below here are configurable during initialization */
+	FG_SRAM_CUTOFF_VOLT,
+	FG_SRAM_EMPTY_VOLT,
+	FG_SRAM_VBATT_LOW,
+	FG_SRAM_FLOAT_VOLT,
+	FG_SRAM_VBATT_FULL,
+	FG_SRAM_ESR_TIMER_DISCHG_MAX,
+	FG_SRAM_ESR_TIMER_DISCHG_INIT,
+	FG_SRAM_ESR_TIMER_CHG_MAX,
+	FG_SRAM_ESR_TIMER_CHG_INIT,
+	FG_SRAM_ESR_PULSE_THRESH,
+	FG_SRAM_SYS_TERM_CURR,
+	FG_SRAM_CHG_TERM_CURR,
+	FG_SRAM_CHG_TERM_BASE_CURR,
+	FG_SRAM_CUTOFF_CURR,
+	FG_SRAM_DELTA_MSOC_THR,
+	FG_SRAM_DELTA_BSOC_THR,
+	FG_SRAM_RECHARGE_SOC_THR,
+	FG_SRAM_SYNC_SLEEP_THR,
+	FG_SRAM_RECHARGE_VBATT_THR,
+	FG_SRAM_KI_COEFF_LOW_DISCHG,
+	FG_SRAM_KI_COEFF_MED_DISCHG,
+	FG_SRAM_KI_COEFF_HI_DISCHG,
+	FG_SRAM_KI_COEFF_LO_MED_DCHG_THR,
+	FG_SRAM_KI_COEFF_MED_HI_DCHG_THR,
+	FG_SRAM_KI_COEFF_LOW_CHG,
+	FG_SRAM_KI_COEFF_MED_CHG,
+	FG_SRAM_KI_COEFF_HI_CHG,
+	FG_SRAM_KI_COEFF_LO_MED_CHG_THR,
+	FG_SRAM_KI_COEFF_MED_HI_CHG_THR,
+	FG_SRAM_KI_COEFF_FULL_SOC,
+	FG_SRAM_KI_COEFF_CUTOFF,
+	FG_SRAM_ESR_TIGHT_FILTER,
+	FG_SRAM_ESR_BROAD_FILTER,
+	FG_SRAM_SLOPE_LIMIT,
+	FG_SRAM_BATT_TEMP_COLD,
+	FG_SRAM_BATT_TEMP_HOT,
+	FG_SRAM_ESR_CAL_SOC_MIN,
+	FG_SRAM_ESR_CAL_SOC_MAX,
+	FG_SRAM_ESR_CAL_TEMP_MIN,
+	FG_SRAM_ESR_CAL_TEMP_MAX,
+	FG_SRAM_DELTA_ESR_THR,
+	FG_SRAM_MAX,
+};
+
+struct fg_sram_param {
+	u16 addr_word;
+	int addr_byte;
+	u8  len;
+	int value;
+	int numrtr;
+	int denmtr;
+	int offset;
+	void (*encode)(struct fg_sram_param *sp, enum fg_sram_param_id id,
+		int val, u8 *buf);
+	int (*decode)(struct fg_sram_param *sp, enum fg_sram_param_id id,
+		int val);
+};
+
+struct fg_dma_address {
+	/* Starting word address of the partition */
+	u16 partition_start;
+	/* Last word address of the partition */
+	u16 partition_end;
+	/*
+	 * Byte offset in the FG_DMA peripheral that maps to the partition_start
+	 * in SRAM
+	 */
+	u16 spmi_addr_base;
+};
+
+enum fg_alg_flag_id {
+	ALG_FLAG_SOC_LT_OTG_MIN = 0,
+	ALG_FLAG_SOC_LT_RECHARGE,
+	ALG_FLAG_IBATT_LT_ITERM,
+	ALG_FLAG_IBATT_GT_HPM,
+	ALG_FLAG_IBATT_GT_UPM,
+	ALG_FLAG_VBATT_LT_RECHARGE,
+	ALG_FLAG_VBATT_GT_VFLOAT,
+	ALG_FLAG_MAX,
+};
+
+enum fg_version {
+	GEN3_FG = 1,
+	GEN4_FG,
+};
+
+struct fg_alg_flag {
+	char	*name;
+	u8	bit;
+	bool	invalid;
+};
+
+enum wa_flags {
+	PMI8998_V1_REV_WA = BIT(0),
+	PM660_TSMC_OSC_WA = BIT(1),
+	PM8150B_V1_DMA_WA = BIT(2),
+	PM8150B_V1_RSLOW_COMP_WA = BIT(3),
+	PM8150B_V2_RSLOW_SCALE_FN_WA = BIT(4),
+};
+
+enum slope_limit_status {
+	LOW_TEMP_DISCHARGE = 0,
+	LOW_TEMP_CHARGE,
+	HIGH_TEMP_DISCHARGE,
+	HIGH_TEMP_CHARGE,
+	SLOPE_LIMIT_NUM_COEFFS,
+};
+
+enum esr_filter_status {
+	ROOM_TEMP = 1,
+	LOW_TEMP,
+	RELAX_TEMP,
+};
+
+enum esr_timer_config {
+	TIMER_RETRY = 0,
+	TIMER_MAX,
+	NUM_ESR_TIMERS,
+};
+
+enum fg_ttf_mode {
+	FG_TTF_MODE_NORMAL = 0,
+	FG_TTF_MODE_QNOVO,
+};
+
+/* parameters from battery profile */
+struct fg_batt_props {
+	const char	*batt_type_str;
+	char		*batt_profile;
+	int		float_volt_uv;
+	int		vbatt_full_mv;
+	int		ffc_vbatt_full_mv;
+	int		fastchg_curr_ma;
+	int		nom_cap_uah;
+	int		*therm_coeffs;
+	int		therm_ctr_offset;
+	int		therm_pull_up_kohms;
+	int		*rslow_normal_coeffs;
+	int		*rslow_low_coeffs;
+	int		ffc_term_curr_ma;
+	int		ffc_low_temp_term_curr_ma;
+	int		ffc_high_temp_term_curr_ma;
+};
+
+struct fg_cyc_ctr_data {
+	bool		en;
+	bool		started[BUCKET_COUNT];
+	u16		count[BUCKET_COUNT];
+	u8		last_soc[BUCKET_COUNT];
+	char		counter[BUCKET_COUNT * 8];
+	struct mutex	lock;
+};
+
+struct fg_cap_learning {
+	bool		active;
+	int		init_cc_soc_sw;
+	int64_t		nom_cap_uah;
+	int64_t		init_cc_uah;
+	int64_t		final_cc_uah;
+	int64_t		learned_cc_uah;
+	struct mutex	lock;
+};
+
+struct fg_irq_info {
+	const char		*name;
+	const irq_handler_t	handler;
+	bool			wakeable;
+	int			irq;
+};
+
+struct fg_circ_buf {
+	int	arr[10];
+	int	size;
+	int	head;
+};
+
+struct fg_cc_step_data {
+	int arr[MAX_CC_STEPS];
+	int sel;
+};
+
+struct fg_pt {
+	s32 x;
+	s32 y;
+};
+
+struct fg_ttf {
+	struct fg_circ_buf	ibatt;
+	struct fg_circ_buf	vbatt;
+	struct fg_cc_step_data	cc_step;
+	struct mutex		lock;
+	int			mode;
+	int			last_ttf;
+	s64			last_ms;
+};
+
+static const struct fg_pt fg_ln_table[] = {
+	{ 1000,		0 },
+	{ 2000,		693 },
+	{ 4000,		1386 },
+	{ 6000,		1792 },
+	{ 8000,		2079 },
+	{ 16000,	2773 },
+	{ 32000,	3466 },
+	{ 64000,	4159 },
+	{ 128000,	4852 },
+};
+
+/* each tuple is - <temperature in degC, Timebase> */
+static const struct fg_pt fg_tsmc_osc_table[] = {
+	{ -20,		395064 },
+	{ -10,		398114 },
+	{   0,		401669 },
+	{  10,		404641 },
+	{  20,		408856 },
+	{  25,		412449 },
+	{  30,		416532 },
+	{  40,		420289 },
+	{  50,		425020 },
+	{  60,		430160 },
+	{  70,		434175 },
+	{  80,		439475 },
+	{  90,		444992 },
+};
+
+#define BATT_MA_AVG_SAMPLES		8
+struct batt_params {
+	bool		update_now;
+	int		batt_raw_soc;
+	int		batt_soc;
+	int		samples_num;
+	int		samples_index;
+	int		batt_ma_avg_samples[BATT_MA_AVG_SAMPLES];
+	int		batt_ma_avg;
+	int		batt_ma_prev;
+	int		batt_ma;
+	int		batt_mv;
+	int		batt_temp;
+	struct timespec64	last_soc_change_time;
+};
+
+struct fg_memif {
+	struct fg_dma_address	*addr_map;
+	int			num_partitions;
+	u16			address_max;
+	u8			num_bytes_per_word;
+};
+
+struct cold_thermal {
+	int index;
+	int temp_l;
+	int temp_h;
+	int curr_th;
+};
+
+struct fg_dev {
+	struct thermal_zone_device	*tz_dev;
+	struct device		*dev;
+	struct pmic_revid_data	*pmic_rev_id;
+	struct regmap		*regmap;
+	struct dentry		*dfs_root;
+	struct power_supply	*fg_psy;
+	struct power_supply	*batt_psy;
+	struct power_supply	*usb_psy;
+	struct power_supply	*dc_psy;
+	struct power_supply	*parallel_psy;
+	struct power_supply	*pc_port_psy;
+	struct fg_irq_info	*irqs;
+	struct votable		*awake_votable;
+	struct votable		*delta_bsoc_irq_en_votable;
+	struct votable		*batt_miss_irq_en_votable;
+	struct fg_sram_param	*sp;
+	struct fg_memif		sram;
+	struct fg_alg_flag	*alg_flags;
+	int			*debug_mask;
+	struct fg_batt_props	bp;
+	struct notifier_block	nb;
+	struct alarm            esr_sw_timer;
+	struct notifier_block	twm_nb;
+	struct mutex		bus_lock;
+	struct mutex		sram_rw_lock;
+	struct mutex		charge_full_lock;
+	struct mutex		qnovo_esr_ctrl_lock;
+	spinlock_t		suspend_lock;
+	spinlock_t		awake_lock;
+	u32			batt_soc_base;
+	u32			batt_info_base;
+	u32			mem_if_base;
+	u32			rradc_base;
+	u32			wa_flags;
+	int			cycle_count;
+	u32			esr_wakeup_ms;
+	u32			awake_status;
+	int			batt_id_ohms;
+	int			charge_status;
+	int			prev_charge_status;
+	int			charge_done;
+	int			online_status;
+	int			last_soc;
+	int			last_batt_temp;
+	int			health;
+	int			maint_soc;
+	int			delta_soc;
+	int			last_msoc;
+	int			last_recharge_volt_mv;
+	int			delta_temp_irq_count;
+	enum esr_filter_status	esr_flt_sts;
+	int			vbatt_full_volt_uv;
+	int			vbat_critical_low_count;
+	bool			profile_available;
+	enum prof_load_status	profile_load_status;
+	bool			battery_missing;
+	bool			fg_restarting;
+	bool			charge_full;
+	bool			recharge_soc_adjusted;
+	bool			soc_reporting_ready;
+	bool			use_ima_single_mode;
+	bool			usb_present;
+	bool			twm_state;
+	bool			report_full;
+	bool			use_dma;
+	bool			qnovo_enable;
+	bool			empty_restart_fg;
+	bool			profile_already_find;
+	bool			input_present;
+	bool			batt_temp_low;
+	/* cold thermal related */
+	struct cold_thermal *cold_thermal_seq;
+	int			cold_thermal_len;
+	int			curr_cold_thermal_level;
+	enum fg_version		version;
+	bool			suspended;
+	struct batt_params	param;
+	struct delayed_work	soc_monitor_work;
+	struct completion	soc_update;
+	struct completion	soc_ready;
+	struct delayed_work	profile_load_work;
+	struct work_struct	status_change_work;
+	struct work_struct	esr_sw_work;
+	struct delayed_work	sram_dump_work;
+	int			fake_authentic;
+	int			fake_chip_ok;
+	int			maxim_cycle_count;
+	int			batt_fake_temp;
+	struct work_struct	esr_filter_work;
+	struct alarm		esr_filter_alarm;
+	ktime_t			last_delta_temp_time;
+	struct delayed_work	empty_restart_fg_work;
+	struct delayed_work	soc_work;
+};
+
+/* Debugfs data structures are below */
+
+/* Log buffer */
+struct fg_log_buffer {
+	size_t		rpos;
+	size_t		wpos;
+	size_t		len;
+	char		data[0];
+};
+
+/* transaction parameters */
+struct fg_trans {
+	struct fg_dev		*fg;
+	struct mutex		fg_dfs_lock; /* Prevent thread concurrency */
+	struct fg_log_buffer	*log;
+	u32			cnt;
+	u16			addr;
+	u32			offset;
+	u8			*data;
+};
+
+struct fg_dbgfs {
+	struct debugfs_blob_wrapper	help_msg;
+	struct fg_dev			*fg;
+	struct dentry			*root;
+	u32				cnt;
+	u32				addr;
+};
+
+extern int fg_decode_voltage_24b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode_voltage_15b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode_current_16b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode_current_24b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode_cc_soc(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int value);
+extern int fg_decode_value_16b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode_default(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern int fg_decode(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val);
+extern void fg_encode_voltage(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val_mv, u8 *buf);
+extern void fg_encode_current(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val_ma, u8 *buf);
+extern void fg_encode_default(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val, u8 *buf);
+extern void fg_encode(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int val, u8 *buf);
+extern int fg_get_sram_prop(struct fg_dev *fg, enum fg_sram_param_id id,
+	int *val);
+extern int fg_get_msoc_raw(struct fg_dev *fg, int *val);
+extern int fg_get_msoc(struct fg_dev *fg, int *val);
+extern const char *fg_get_battery_type(struct fg_dev *fg);
+extern int fg_get_battery_resistance(struct fg_dev *fg, int *val);
+extern int fg_get_battery_voltage(struct fg_dev *fg, int *val);
+extern int fg_get_battery_current(struct fg_dev *fg, int *val);
+extern int fg_set_esr_timer(struct fg_dev *fg, int cycles_init, int cycles_max,
+				bool charging, int flags);
+extern int fg_set_constant_chg_voltage(struct fg_dev *fg, int volt_uv);
+extern int fg_register_interrupts(struct fg_dev *fg, int size);
+extern void fg_unregister_interrupts(struct fg_dev *fg, void *data, int size);
+extern int fg_sram_write(struct fg_dev *fg, u16 address, u8 offset,
+			u8 *val, int len, int flags);
+extern int fg_sram_read(struct fg_dev *fg, u16 address, u8 offset,
+			u8 *val, int len, int flags);
+extern int fg_sram_masked_write(struct fg_dev *fg, u16 address, u8 offset,
+			u8 mask, u8 val, int flags);
+extern int fg_interleaved_mem_read(struct fg_dev *fg, u16 address,
+			u8 offset, u8 *val, int len);
+extern int fg_interleaved_mem_write(struct fg_dev *fg, u16 address,
+			u8 offset, u8 *val, int len, bool atomic_access);
+extern int fg_direct_mem_read(struct fg_dev *fg, u16 address,
+			u8 offset, u8 *val, int len);
+extern int fg_direct_mem_write(struct fg_dev *fg, u16 address,
+			u8 offset, u8 *val, int len, bool atomic_access);
+extern int fg_read(struct fg_dev *fg, int addr, u8 *val, int len);
+extern int fg_write(struct fg_dev *fg, int addr, u8 *val, int len);
+extern int fg_masked_write(struct fg_dev *fg, int addr, u8 mask, u8 val);
+extern int fg_dump_regs(struct fg_dev *fg);
+extern int fg_restart(struct fg_dev *fg, int wait_time_ms);
+extern int fg_memif_init(struct fg_dev *fg);
+extern int fg_clear_ima_errors_if_any(struct fg_dev *fg, bool check_hw_sts);
+extern int fg_clear_dma_errors_if_any(struct fg_dev *fg);
+extern int fg_debugfs_create(struct fg_dev *fg);
+extern void fill_string(char *str, size_t str_len, u8 *buf, int buf_len);
+extern void dump_sram(struct fg_dev *fg, u8 *buf, int addr, int len);
+extern s64 fg_float_decode(u16 val);
+extern bool usb_psy_initialized(struct fg_dev *fg);
+extern bool dc_psy_initialized(struct fg_dev *fg);
+extern bool batt_psy_initialized(struct fg_dev *fg);
+extern bool pc_port_psy_initialized(struct fg_dev *fg);
+extern void fg_notify_charger(struct fg_dev *fg);
+extern bool is_input_present(struct fg_dev *fg);
+extern bool is_parallel_charger_available(struct fg_dev *fg);
+extern void fg_circ_buf_add(struct fg_circ_buf *buf, int val);
+extern void fg_circ_buf_clr(struct fg_circ_buf *buf);
+extern int fg_circ_buf_avg(struct fg_circ_buf *buf, int *avg);
+extern int fg_circ_buf_median(struct fg_circ_buf *buf, int *median);
+extern int fg_lerp(const struct fg_pt *pts, size_t tablesize, s32 input,
+			s32 *output);
+void fg_stay_awake(struct fg_dev *fg, int awake_reason);
+void fg_relax(struct fg_dev *fg, int awake_reason);
+#endif
diff --git a/drivers/power/supply/qcom/fg-memif.c b/drivers/power/supply/qcom/fg-memif.c
new file mode 100644
index 000000000..42de6f5bf
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-memif.c
@@ -0,0 +1,1284 @@
+/* Copyright (c) 2016-2018, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt)	"FG: %s: " fmt, __func__
+
+#include "fg-core.h"
+#include "fg-reg.h"
+
+/* Generic definitions */
+#define RETRY_COUNT		3
+#define DEBUG_PRINT_BUFFER_SIZE	64
+
+enum {
+	FG_READ = 0,
+	FG_WRITE,
+};
+
+static int fg_set_address(struct fg_dev *fg, u16 address)
+{
+	u8 buffer[2];
+	int rc;
+
+	buffer[0] = address & 0xFF;
+	buffer[1] = address >> 8;
+
+	/* MSB has to be written zero for GEN3 FG */
+	if (fg->version == GEN3_FG)
+		buffer[1] = 0;
+
+	rc = fg_write(fg, MEM_IF_ADDR_LSB(fg), buffer, 2);
+	if (rc < 0) {
+		pr_err("failed to write to 0x%04X, rc=%d\n",
+			MEM_IF_ADDR_LSB(fg), rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+static int fg_config_access_mode(struct fg_dev *fg, bool access, bool burst)
+{
+	int rc;
+	u8 intf_ctl = 0;
+
+	fg_dbg(fg, FG_SRAM_READ | FG_SRAM_WRITE, "access: %d burst: %d\n",
+		access, burst);
+
+	WARN_ON(burst && fg->use_ima_single_mode);
+	intf_ctl = ((access == FG_WRITE) ? IMA_WR_EN_BIT : 0) |
+			(burst ? MEM_ACS_BURST_BIT : 0);
+
+	rc = fg_masked_write(fg, MEM_IF_IMA_CTL(fg), IMA_CTL_MASK,
+			intf_ctl);
+	if (rc < 0) {
+		pr_err("failed to write to 0x%04x, rc=%d\n",
+			MEM_IF_IMA_CTL(fg), rc);
+		return -EIO;
+	}
+
+	return rc;
+}
+
+static int fg_run_iacs_clear_sequence(struct fg_dev *fg)
+{
+	u8 val, hw_sts, exp_sts;
+	int rc, tries = 250;
+
+	/*
+	 * Values to write for running IACS clear sequence comes from
+	 * hardware documentation.
+	 */
+	rc = fg_masked_write(fg, MEM_IF_IMA_CFG(fg),
+			IACS_CLR_BIT | STATIC_CLK_EN_BIT,
+			IACS_CLR_BIT | STATIC_CLK_EN_BIT);
+	if (rc < 0) {
+		pr_err("failed to write 0x%04x, rc=%d\n", MEM_IF_IMA_CFG(fg),
+			rc);
+		return rc;
+	}
+
+	rc = fg_config_access_mode(fg, FG_READ, false);
+	if (rc < 0) {
+		pr_err("failed to write to 0x%04x, rc=%d\n",
+			MEM_IF_IMA_CTL(fg), rc);
+		return rc;
+	}
+
+	rc = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg),
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT,
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT);
+	if (rc < 0) {
+		pr_err("failed to set ima_req_access bit rc=%d\n", rc);
+		return rc;
+	}
+
+	/* Delay for the clock to reach FG */
+	usleep_range(35, 40);
+
+	while (1) {
+		if (fg->version == GEN4_FG) {
+			val = 0x4;
+			rc = fg_write(fg, MEM_IF_ADDR_MSB(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to write 0x%04x, rc=%d\n",
+					MEM_IF_ADDR_MSB(fg), rc);
+				return rc;
+			}
+
+			val = 0;
+			rc = fg_write(fg, MEM_IF_WR_DATA1(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to write 0x%04x, rc=%d\n",
+					MEM_IF_WR_DATA1(fg), rc);
+				return rc;
+			}
+
+			rc = fg_read(fg, MEM_IF_RD_DATA1(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to read 0x%04x, rc=%d\n",
+					MEM_IF_RD_DATA1(fg), rc);
+				return rc;
+			}
+		} else { /* GEN3 FG */
+			val = 0;
+			rc = fg_write(fg, MEM_IF_ADDR_MSB(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to write 0x%04x, rc=%d\n",
+					MEM_IF_ADDR_MSB(fg), rc);
+				return rc;
+			}
+
+			val = 0;
+			rc = fg_write(fg, MEM_IF_WR_DATA3(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to write 0x%04x, rc=%d\n",
+					MEM_IF_WR_DATA3(fg), rc);
+				return rc;
+			}
+
+			rc = fg_read(fg, MEM_IF_RD_DATA3(fg), &val, 1);
+			if (rc < 0) {
+				pr_err("failed to read 0x%04x, rc=%d\n",
+					MEM_IF_RD_DATA3(fg), rc);
+				return rc;
+			}
+		}
+
+		/* Delay for IMA hardware to clear */
+		usleep_range(35, 40);
+
+		rc = fg_read(fg, MEM_IF_IMA_HW_STS(fg), &hw_sts, 1);
+		if (rc < 0) {
+			pr_err("failed to read ima_hw_sts rc=%d\n", rc);
+			return rc;
+		}
+
+		if (hw_sts != 0)
+			continue;
+
+		rc = fg_read(fg, MEM_IF_IMA_EXP_STS(fg), &exp_sts, 1);
+		if (rc < 0) {
+			pr_err("failed to read ima_exp_sts rc=%d\n", rc);
+			return rc;
+		}
+
+		if (exp_sts == 0 || !(--tries))
+			break;
+	}
+
+	if (!tries)
+		pr_err("Failed to clear the error? hw_sts: %x exp_sts: %d\n",
+			hw_sts, exp_sts);
+
+	rc = fg_masked_write(fg, MEM_IF_IMA_CFG(fg), IACS_CLR_BIT, 0);
+	if (rc < 0) {
+		pr_err("failed to write 0x%04x, rc=%d\n", MEM_IF_IMA_CFG(fg),
+			rc);
+		return rc;
+	}
+
+	udelay(5);
+
+	rc = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg),
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT, 0);
+	if (rc < 0) {
+		pr_err("failed to write to 0x%04x, rc=%d\n",
+			MEM_IF_MEM_INTF_CFG(fg), rc);
+		return rc;
+	}
+
+	/* Delay before next transaction is attempted */
+	usleep_range(35, 40);
+	fg_dbg(fg, FG_SRAM_READ | FG_SRAM_WRITE, "IACS clear sequence complete\n");
+	return rc;
+}
+
+int fg_clear_dma_errors_if_any(struct fg_dev *fg)
+{
+	int rc;
+	u8 dma_sts;
+	bool error_present;
+
+	rc = fg_read(fg, MEM_IF_DMA_STS(fg), &dma_sts, 1);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			MEM_IF_DMA_STS(fg), rc);
+		return rc;
+	}
+	fg_dbg(fg, FG_STATUS, "dma_sts: %x\n", dma_sts);
+
+	error_present = dma_sts & (DMA_WRITE_ERROR_BIT | DMA_READ_ERROR_BIT);
+	rc = fg_masked_write(fg, MEM_IF_DMA_CTL(fg), DMA_CLEAR_LOG_BIT,
+			error_present ? DMA_CLEAR_LOG_BIT : 0);
+	if (rc < 0) {
+		pr_err("failed to write addr=0x%04x, rc=%d\n",
+			MEM_IF_DMA_CTL(fg), rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+int fg_clear_ima_errors_if_any(struct fg_dev *fg, bool check_hw_sts)
+{
+	int rc = 0;
+	u8 err_sts, exp_sts = 0, hw_sts = 0;
+	bool run_err_clr_seq = false;
+
+	rc = fg_read(fg, MEM_IF_IMA_EXP_STS(fg), &exp_sts, 1);
+	if (rc < 0) {
+		pr_err("failed to read ima_exp_sts rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_read(fg, MEM_IF_IMA_HW_STS(fg), &hw_sts, 1);
+	if (rc < 0) {
+		pr_err("failed to read ima_hw_sts rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_read(fg, MEM_IF_IMA_ERR_STS(fg), &err_sts, 1);
+	if (rc < 0) {
+		pr_err("failed to read ima_err_sts rc=%d\n", rc);
+		return rc;
+	}
+
+	fg_dbg(fg, FG_SRAM_READ | FG_SRAM_WRITE, "ima_err_sts=%x ima_exp_sts=%x ima_hw_sts=%x\n",
+		err_sts, exp_sts, hw_sts);
+
+	if (check_hw_sts) {
+		/*
+		 * Lower nibble should be equal to upper nibble before SRAM
+		 * transactions begins from SW side. If they are unequal, then
+		 * the error clear sequence should be run irrespective of IMA
+		 * exception errors.
+		 */
+		if ((hw_sts & 0x0F) != hw_sts >> 4) {
+			pr_err("IMA HW not in correct state, hw_sts=%x\n",
+				hw_sts);
+			run_err_clr_seq = true;
+		}
+	}
+
+	if (exp_sts & (IACS_ERR_BIT | XCT_TYPE_ERR_BIT | DATA_RD_ERR_BIT |
+		DATA_WR_ERR_BIT | ADDR_BURST_WRAP_BIT | ADDR_STABLE_ERR_BIT)) {
+		pr_err("IMA exception bit set, exp_sts=%x\n", exp_sts);
+		run_err_clr_seq = true;
+	}
+
+	if (run_err_clr_seq) {
+		/* clear the error */
+		rc = fg_run_iacs_clear_sequence(fg);
+		if (rc < 0) {
+			pr_err("failed to run iacs clear sequence rc=%d\n", rc);
+			return rc;
+		}
+
+		/* Retry again as there was an error in the transaction */
+		return -EAGAIN;
+	}
+
+	return rc;
+}
+
+static int fg_check_iacs_ready(struct fg_dev *fg)
+{
+	int rc = 0, tries = 250;
+	u8 ima_opr_sts = 0;
+
+	/*
+	 * Additional delay to make sure IACS ready bit is set after
+	 * Read/Write operation.
+	 */
+
+	usleep_range(30, 35);
+	while (1) {
+		rc = fg_read(fg, MEM_IF_IMA_OPR_STS(fg), &ima_opr_sts, 1);
+		if (rc < 0) {
+			pr_err("failed to read 0x%04x, rc=%d\n",
+				MEM_IF_IMA_OPR_STS(fg), rc);
+			return rc;
+		}
+
+		if (ima_opr_sts & IACS_RDY_BIT)
+			break;
+
+		if (!(--tries))
+			break;
+
+		/* delay for iacs_ready to be asserted */
+		usleep_range(5000, 7000);
+	}
+
+	if (!tries) {
+		pr_err("IACS_RDY not set, opr_sts: %d\n", ima_opr_sts);
+		/* check for error condition */
+		rc = fg_clear_ima_errors_if_any(fg, false);
+		if (rc < 0) {
+			if (rc != -EAGAIN)
+				pr_err("Failed to check for ima errors rc=%d\n",
+					rc);
+			return rc;
+		}
+
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+static int __fg_interleaved_mem_write(struct fg_dev *fg, u16 address,
+				int offset, u8 *val, int len)
+{
+	int rc = 0, i;
+	u8 *ptr = val, byte_enable = 0, num_bytes = 0, dummy_byte = 0;
+
+	fg_dbg(fg, FG_SRAM_WRITE, "length %d addr=%02X offset=%d\n", len,
+		address, offset);
+
+	while (len > 0) {
+		num_bytes = (offset + len) > fg->sram.num_bytes_per_word ?
+				(fg->sram.num_bytes_per_word - offset) : len;
+
+		/* write to byte_enable */
+		for (i = offset; i < (offset + num_bytes); i++)
+			byte_enable |= BIT(i);
+
+		rc = fg_write(fg, MEM_IF_IMA_BYTE_EN(fg), &byte_enable, 1);
+		if (rc < 0) {
+			pr_err("Unable to write to byte_en_reg rc=%d\n",
+				rc);
+			return rc;
+		}
+
+		/* write data */
+		rc = fg_write(fg, MEM_IF_WR_DATA0(fg) + offset, ptr,
+				num_bytes);
+		if (rc < 0) {
+			pr_err("failed to write to 0x%04x, rc=%d\n",
+				MEM_IF_WR_DATA0(fg) + offset, rc);
+			return rc;
+		}
+
+		/*
+		 * The last-byte WR_DATA3/1 starts the write transaction.
+		 * Write a dummy value to WR_DATA3/1 if it does not have
+		 * valid data. This dummy data is not written to the
+		 * SRAM as byte_en for WR_DATA3/1 is not set.
+		 */
+		if (fg->version == GEN3_FG && !(byte_enable & BIT(3))) {
+			rc = fg_write(fg, MEM_IF_WR_DATA3(fg), &dummy_byte,
+					1);
+			if (rc < 0) {
+				pr_err("failed to write dummy-data to WR_DATA3 rc=%d\n",
+					rc);
+				return rc;
+			}
+		} else if (fg->version == GEN4_FG && !(byte_enable & BIT(1))) {
+			rc = fg_write(fg, MEM_IF_WR_DATA1(fg), &dummy_byte,
+					1);
+			if (rc < 0) {
+				pr_err("failed to write dummy-data to WR_DATA1 rc=%d\n",
+					rc);
+				return rc;
+			}
+		}
+
+		/* check for error condition */
+		rc = fg_clear_ima_errors_if_any(fg, false);
+		if (rc < 0) {
+			if (rc == -EAGAIN)
+				pr_err("IMA error cleared, address [%d %d] len %d\n",
+					address, offset, len);
+			else
+				pr_err("Failed to check for ima errors rc=%d\n",
+					rc);
+			return rc;
+		}
+
+		ptr += num_bytes;
+		len -= num_bytes;
+		offset = byte_enable = 0;
+
+		if (fg->use_ima_single_mode && len) {
+			address++;
+			rc = fg_set_address(fg, address);
+			if (rc < 0) {
+				pr_err("failed to set address rc = %d\n", rc);
+				return rc;
+			}
+		}
+
+		rc = fg_check_iacs_ready(fg);
+		if (rc < 0) {
+			pr_debug("IACS_RDY failed rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	return rc;
+}
+
+static int __fg_interleaved_mem_read(struct fg_dev *fg, u16 address,
+				int offset, u8 *val, int len)
+{
+	int rc = 0, total_len;
+	u8 *rd_data = val, num_bytes;
+	char str[DEBUG_PRINT_BUFFER_SIZE];
+
+	fg_dbg(fg, FG_SRAM_READ, "length %d addr=%02X\n", len, address);
+
+	total_len = len;
+	while (len > 0) {
+		num_bytes = (offset + len) > fg->sram.num_bytes_per_word ?
+				(fg->sram.num_bytes_per_word - offset) : len;
+		rc = fg_read(fg, MEM_IF_RD_DATA0(fg) + offset, rd_data,
+				num_bytes);
+		if (rc < 0) {
+			pr_err("failed to read 0x%04x, rc=%d\n",
+				MEM_IF_RD_DATA0(fg) + offset, rc);
+			return rc;
+		}
+
+		rd_data += num_bytes;
+		len -= num_bytes;
+		offset = 0;
+
+		/* check for error condition */
+		rc = fg_clear_ima_errors_if_any(fg, false);
+		if (rc < 0) {
+			if (rc == -EAGAIN)
+				pr_err("IMA error cleared, address [%d %d] len %d\n",
+					address, offset, len);
+			else
+				pr_err("Failed to check for ima errors rc=%d\n",
+					rc);
+			return rc;
+		}
+
+		if (fg->use_ima_single_mode) {
+			if (len) {
+				address++;
+				rc = fg_set_address(fg, address);
+				if (rc < 0) {
+					pr_err("failed to set address rc = %d\n",
+						rc);
+					return rc;
+				}
+			}
+		} else {
+			if (len && len < fg->sram.num_bytes_per_word) {
+				/*
+				 * Move to single mode. Changing address is not
+				 * required here as it must be in burst mode.
+				 * Address will get incremented internally by FG
+				 * HW once the MSB of RD_DATA is read.
+				 */
+				rc = fg_config_access_mode(fg, FG_READ,
+								false);
+				if (rc < 0) {
+					pr_err("failed to move to single mode rc=%d\n",
+						rc);
+					return -EIO;
+				}
+			}
+		}
+
+		rc = fg_check_iacs_ready(fg);
+		if (rc < 0) {
+			pr_debug("IACS_RDY failed rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	if (*fg->debug_mask & FG_SRAM_READ) {
+		fill_string(str, DEBUG_PRINT_BUFFER_SIZE, val, total_len);
+		pr_info("data read: %s\n", str);
+	}
+
+	return rc;
+}
+
+static int fg_get_mem_access_status(struct fg_dev *fg, bool *status)
+{
+	int rc;
+	u8 mem_if_sts;
+
+	rc = fg_read(fg, MEM_IF_MEM_INTF_CFG(fg), &mem_if_sts, 1);
+	if (rc < 0) {
+		pr_err("failed to read rif_mem status rc=%d\n", rc);
+		return rc;
+	}
+
+	*status = mem_if_sts & MEM_ACCESS_REQ_BIT;
+	return 0;
+}
+
+static bool is_mem_access_available(struct fg_dev *fg, int access)
+{
+	bool rif_mem_sts = true;
+	int rc, time_count = 0;
+
+	while (1) {
+		rc = fg_get_mem_access_status(fg, &rif_mem_sts);
+		if (rc < 0)
+			return rc;
+
+		/* This is an inverting logic */
+		if (!rif_mem_sts)
+			break;
+
+		fg_dbg(fg, FG_SRAM_READ | FG_SRAM_WRITE, "MEM_ACCESS_REQ is not clear yet for IMA_%s\n",
+			access ? "write" : "read");
+
+		/*
+		 * Try this no more than 4 times. If MEM_ACCESS_REQ is not
+		 * clear, then return an error instead of waiting for it again.
+		 */
+		if  (time_count > 4) {
+			pr_err("Tried 4 times(~16ms) polling MEM_ACCESS_REQ\n");
+			return false;
+		}
+
+		/* Wait for 4ms before reading MEM_ACCESS_REQ again */
+		usleep_range(4000, 4100);
+		time_count++;
+	}
+	return true;
+}
+
+static int fg_interleaved_mem_config(struct fg_dev *fg, u8 *val,
+		u16 address, int offset, int len, bool access)
+{
+	int rc = 0;
+	bool burst_mode = false;
+
+	if (!is_mem_access_available(fg, access))
+		return -EBUSY;
+
+	/* configure for IMA access */
+	rc = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg),
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT,
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT);
+	if (rc < 0) {
+		pr_err("failed to set ima_req_access bit rc=%d\n", rc);
+		return rc;
+	}
+
+	/* configure for the read/write, single/burst mode */
+	burst_mode = fg->use_ima_single_mode ? false :
+			(offset + len) > fg->sram.num_bytes_per_word;
+	rc = fg_config_access_mode(fg, access, burst_mode);
+	if (rc < 0) {
+		pr_err("failed to set memory access rc = %d\n", rc);
+		return rc;
+	}
+
+	rc = fg_check_iacs_ready(fg);
+	if (rc < 0) {
+		pr_err_ratelimited("IACS_RDY failed rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_set_address(fg, address);
+	if (rc < 0) {
+		pr_err("failed to set address rc = %d\n", rc);
+		return rc;
+	}
+
+	if (access == FG_READ) {
+		rc = fg_check_iacs_ready(fg);
+		if (rc < 0) {
+			pr_debug("IACS_RDY failed rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	return rc;
+}
+
+static int fg_get_beat_count(struct fg_dev *fg, u8 *count)
+{
+	int rc;
+
+	rc = fg_read(fg, MEM_IF_FG_BEAT_COUNT(fg), count, 1);
+	*count &= BEAT_COUNT_MASK;
+	return rc;
+}
+
+int fg_interleaved_mem_read(struct fg_dev *fg, u16 address, u8 offset,
+				u8 *val, int len)
+{
+	int rc = 0, ret;
+	u8 start_beat_count, end_beat_count, count = 0;
+	bool retry = false;
+
+	if (fg->version == GEN4_FG) {
+		if (offset > 1) {
+			pr_err("offset too large %d\n", offset);
+			return -EINVAL;
+		}
+	} else {
+		if (offset > 3) {
+			pr_err("offset too large %d\n", offset);
+			return -EINVAL;
+		}
+	}
+retry:
+	if (count >= RETRY_COUNT) {
+		pr_err("Tried %d times\n", RETRY_COUNT);
+		retry = false;
+		goto out;
+	}
+
+	rc = fg_interleaved_mem_config(fg, val, address, offset, len,
+					FG_READ);
+	if (rc < 0) {
+		pr_err("failed to configure SRAM for IMA rc = %d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	/* read the start beat count */
+	rc = fg_get_beat_count(fg, &start_beat_count);
+	if (rc < 0) {
+		pr_err("failed to read beat count rc=%d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	/* read data */
+	rc = __fg_interleaved_mem_read(fg, address, offset, val, len);
+	if (rc < 0) {
+		count++;
+		if (rc == -EAGAIN) {
+			pr_err("IMA read failed retry_count = %d\n", count);
+			goto retry;
+		}
+		pr_err("failed to read SRAM address rc = %d\n", rc);
+		retry = true;
+		goto out;
+	}
+
+	/* read the end beat count */
+	rc = fg_get_beat_count(fg, &end_beat_count);
+	if (rc < 0) {
+		pr_err("failed to read beat count rc=%d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	fg_dbg(fg, FG_SRAM_READ, "Start beat_count = %x End beat_count = %x\n",
+		start_beat_count, end_beat_count);
+
+	if (start_beat_count != end_beat_count) {
+		fg_dbg(fg, FG_SRAM_READ, "Beat count(%d/%d) do not match - retry transaction\n",
+			start_beat_count, end_beat_count);
+		count++;
+		retry = true;
+	}
+out:
+	/* Release IMA access */
+	ret = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg),
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT, 0);
+	if (rc < 0 && ret < 0) {
+		pr_err("failed to reset IMA access bit ret = %d\n", ret);
+		return ret;
+	}
+
+	if (retry) {
+		retry = false;
+		goto retry;
+	}
+
+	return rc;
+}
+
+int fg_interleaved_mem_write(struct fg_dev *fg, u16 address, u8 offset,
+				u8 *val, int len, bool atomic_access)
+{
+	int rc = 0, ret;
+	u8 start_beat_count, end_beat_count, count = 0;
+	bool retry = false;
+
+	if (fg->version == GEN4_FG) {
+		if (offset > 1) {
+			pr_err("offset too large %d\n", offset);
+			return -EINVAL;
+		}
+	} else {
+		if (offset > 3) {
+			pr_err("offset too large %d\n", offset);
+			return -EINVAL;
+		}
+	}
+retry:
+	if (count >= RETRY_COUNT) {
+		pr_err("Tried %d times\n", RETRY_COUNT);
+		retry = false;
+		goto out;
+	}
+
+	rc = fg_interleaved_mem_config(fg, val, address, offset, len,
+					FG_WRITE);
+	if (rc < 0) {
+		pr_err("failed to configure SRAM for IMA rc = %d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	/* read the start beat count */
+	rc = fg_get_beat_count(fg, &start_beat_count);
+	if (rc < 0) {
+		pr_err("failed to read beat count rc=%d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	/* write data */
+	rc = __fg_interleaved_mem_write(fg, address, offset, val, len);
+	if (rc < 0) {
+		count++;
+		if (rc == -EAGAIN) {
+			pr_err("IMA write failed retry_count = %d\n", count);
+			goto retry;
+		}
+		pr_err("failed to write SRAM address rc = %d\n", rc);
+		retry = true;
+		goto out;
+	}
+
+	/* read the end beat count */
+	rc = fg_get_beat_count(fg, &end_beat_count);
+	if (rc < 0) {
+		pr_err("failed to read beat count rc=%d\n", rc);
+		count++;
+		retry = true;
+		goto out;
+	}
+
+	if (atomic_access && start_beat_count != end_beat_count)
+		pr_err("Start beat_count = %x End beat_count = %x\n",
+			start_beat_count, end_beat_count);
+out:
+	/* Release IMA access */
+	ret = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg),
+				MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT, 0);
+	if (rc < 0 && ret < 0) {
+		pr_err("failed to reset IMA access bit ret = %d\n", ret);
+		return ret;
+	}
+
+	if (retry) {
+		retry = false;
+		goto retry;
+	}
+
+	/* Return the error we got before releasing memory access */
+	return rc;
+}
+
+static int fg_poll_alg_active(struct fg_dev *fg)
+{
+	u32 retries = 35, poll_time_us = 10000;
+	int rc;
+	u8 val;
+
+	/*
+	 * ALG active should be asserted low within ~164 ms mostly however
+	 * during ESR pulsing, a worst case delay of ~320 ms is needed.
+	 */
+	while (retries--) {
+		rc = fg_read(fg, BATT_INFO_PEEK_RD(fg), &val, 1);
+		if (rc < 0) {
+			pr_err("failed to read PEEK_MUX rc=%d\n", rc);
+			return rc;
+		}
+
+		if (!(val & ALG_ACTIVE_BIT))
+			break;
+
+		usleep_range(poll_time_us, poll_time_us + 1);
+	}
+
+	if (val & ALG_ACTIVE_BIT)
+		return -ETIMEDOUT;
+
+	/* Wait for 1 ms after ALG active is asserted low */
+	usleep_range(1000, 1001);
+	return rc;
+}
+
+static int fg_direct_mem_release(struct fg_dev *fg)
+{
+	int rc;
+	u8 val = 0, mask;
+
+	mask = MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT;
+	rc = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg), mask, val);
+	if (rc < 0) {
+		pr_err("failed to configure mem_if_mem_intf_cfg rc=%d\n", rc);
+		return rc;
+	}
+
+	mask = MEM_ARB_REQ_BIT;
+	rc = fg_masked_write(fg, MEM_IF_MEM_ARB_CFG(fg), mask, val);
+	if (rc < 0) {
+		pr_err("failed to configure mem_if_mem_arb_cfg rc:%d\n", rc);
+		return rc;
+	}
+
+	pr_debug("released access\n");
+	return rc;
+}
+
+#define MEM_GNT_WAIT_TIME_US	10000
+#define MEM_GNT_RETRIES		50
+static int fg_direct_mem_request(struct fg_dev *fg)
+{
+	int rc, ret, i = 0;
+	u8 val, mask, poll_bit;
+
+	if (fg->wa_flags & PM8150B_V1_DMA_WA) {
+		rc = fg_poll_alg_active(fg);
+		if (rc < 0) {
+			pr_err("Failed to assert ALG active rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	val = mask = MEM_ARB_REQ_BIT;
+	rc = fg_masked_write(fg, MEM_IF_MEM_ARB_CFG(fg), mask, val);
+	if (rc < 0) {
+		pr_err("failed to configure mem_if_mem_arb_cfg rc:%d\n", rc);
+		return rc;
+	}
+
+	mask = MEM_ACCESS_REQ_BIT | IACS_SLCT_BIT;
+	val = MEM_ACCESS_REQ_BIT;
+	rc = fg_masked_write(fg, MEM_IF_MEM_INTF_CFG(fg), mask, val);
+	if (rc < 0) {
+		pr_err("failed to configure mem_if_mem_intf_cfg rc=%d\n", rc);
+		goto release;
+	}
+
+	pr_debug("requesting access\n");
+
+	/*
+	 * HW takes 5 cycles (200 KHz clock) to grant access after requesting
+	 * for DMA. Wait for 40 us before polling for MEM_GNT first time.
+	 */
+	usleep_range(40, 41);
+
+	poll_bit = MEM_GNT_BIT;
+	if (fg->version == GEN4_FG)
+		poll_bit = GEN4_MEM_GNT_BIT;
+
+	while (i < MEM_GNT_RETRIES) {
+		rc = fg_read(fg, MEM_IF_INT_RT_STS(fg), &val, 1);
+		if (rc < 0) {
+			pr_err("Error in reading MEM_IF_INT_RT_STS, rc=%d\n",
+				rc);
+			goto release;
+		}
+
+		if (val & poll_bit) {
+			/* Delay needed for PM8150B V1 after DMA is granted */
+			if (fg->wa_flags & PM8150B_V1_DMA_WA)
+				usleep_range(1000, 1001);
+			return 0;
+		}
+
+		usleep_range(MEM_GNT_WAIT_TIME_US, MEM_GNT_WAIT_TIME_US + 1);
+		i++;
+	}
+
+	rc = -ETIMEDOUT;
+	pr_err("wait for mem_grant timed out, val=0x%x\n", val);
+	fg_dump_regs(fg);
+
+release:
+	ret = fg_direct_mem_release(fg);
+	if (ret < 0)
+		return ret;
+
+	return rc;
+}
+
+static int fg_get_dma_address(struct fg_dev *fg, u16 sram_addr, u8 offset,
+				u16 *addr)
+{
+	int i;
+	u16 start_sram_addr, end_sram_addr;
+
+	for (i = 0; i < fg->sram.num_partitions; i++) {
+		start_sram_addr = fg->sram.addr_map[i].partition_start;
+		end_sram_addr = fg->sram.addr_map[i].partition_end;
+		if (sram_addr >= start_sram_addr &&
+			sram_addr <= end_sram_addr) {
+			*addr = fg->sram.addr_map[i].spmi_addr_base + offset +
+					(sram_addr - start_sram_addr) *
+						fg->sram.num_bytes_per_word;
+			return 0;
+		}
+	}
+
+	pr_err("Couldn't find address for %d from address map\n", sram_addr);
+	return -ENXIO;
+}
+
+static int fg_get_partition_count(struct fg_dev *fg, u16 sram_addr, int len,
+				int *count)
+{
+	int i, start_partn = 0, end_partn = 0;
+	u16 end_addr = 0;
+
+	end_addr = sram_addr + len / fg->sram.num_bytes_per_word;
+	if (!(len % fg->sram.num_bytes_per_word))
+		end_addr -= 1;
+
+	if (sram_addr == end_addr) {
+		*count = 1;
+		return 0;
+	}
+
+	for (i = 0; i < fg->sram.num_partitions; i++) {
+		if (sram_addr >= fg->sram.addr_map[i].partition_start
+			&& sram_addr <= fg->sram.addr_map[i].partition_end)
+			start_partn = i + 1;
+
+		if (end_addr >= fg->sram.addr_map[i].partition_start
+			&& end_addr <= fg->sram.addr_map[i].partition_end)
+			end_partn = i + 1;
+	}
+
+	if (!start_partn || !end_partn) {
+		pr_err("Couldn't find number of partitions for address %d\n",
+			sram_addr);
+		return -ENXIO;
+	}
+
+	*count = (end_partn - start_partn) + 1;
+
+	return 0;
+}
+
+static int fg_get_partition_avail_bytes(struct fg_dev *fg, u16 sram_addr,
+					int len, int *rem_len)
+{
+	int i, part_len = 0, temp;
+	u16 end_addr;
+
+	for (i = 0; i < fg->sram.num_partitions; i++) {
+		if (sram_addr >= fg->sram.addr_map[i].partition_start
+			&& sram_addr <= fg->sram.addr_map[i].partition_end) {
+			part_len = (fg->sram.addr_map[i].partition_end -
+					fg->sram.addr_map[i].partition_start +
+					1);
+			part_len *= fg->sram.num_bytes_per_word;
+			end_addr = fg->sram.addr_map[i].partition_end;
+			break;
+		}
+	}
+
+	if (part_len <= 0) {
+		pr_err("Bad address? total_len=%d\n", part_len);
+		return -ENXIO;
+	}
+
+	temp = (end_addr - sram_addr + 1) * fg->sram.num_bytes_per_word;
+	if (temp > part_len || !temp) {
+		pr_err("Bad length=%d\n", temp);
+		return -ENXIO;
+	}
+
+	*rem_len = temp;
+	pr_debug("address %d len %d rem_len %d\n", sram_addr, len, *rem_len);
+	return 0;
+}
+
+static int __fg_direct_mem_rw(struct fg_dev *fg, u16 sram_addr, u8 offset,
+				u8 *val, int len, bool access)
+{
+	int rc, ret, num_partitions, num_bytes = 0;
+	u16 addr;
+	u8 *ptr = val;
+	char *temp_str;
+
+	if (offset > 3) {
+		pr_err("offset too large %d\n", offset);
+		return -EINVAL;
+	}
+
+	rc = fg_get_partition_count(fg, sram_addr, len, &num_partitions);
+	if (rc < 0)
+		return rc;
+
+	pr_debug("number of partitions: %d\n", num_partitions);
+
+	rc = fg_direct_mem_request(fg);
+	if (rc < 0) {
+		pr_err("Error in requesting direct_mem access rc=%d\n", rc);
+		return rc;
+	}
+
+	while (num_partitions-- && len) {
+		rc = fg_get_dma_address(fg, sram_addr, offset, &addr);
+		if (rc < 0) {
+			pr_err("Incorrect address %d/offset %d\n", sram_addr,
+				offset);
+			break;
+		}
+
+		rc = fg_get_partition_avail_bytes(fg, sram_addr + offset, len,
+						&num_bytes);
+		if (rc < 0)
+			break;
+
+		if (num_bytes > len)
+			num_bytes = len;
+
+		pr_debug("reading from address: [%d %d] dma_address = %x\n",
+			sram_addr, offset, addr);
+
+		if (access == FG_READ) {
+			rc = fg_read(fg, addr, ptr, num_bytes);
+			temp_str = "read";
+		} else {
+			rc = fg_write(fg, addr, ptr, num_bytes);
+			temp_str = "write";
+		}
+
+		if (rc < 0) {
+			pr_err("Error in %sing address %d rc=%d\n", temp_str,
+				sram_addr, rc);
+			break;
+		}
+
+		ptr += num_bytes;
+		len -= num_bytes;
+		sram_addr += (num_bytes / fg->sram.num_bytes_per_word);
+		offset = 0;
+	}
+
+	ret = fg_direct_mem_release(fg);
+	if (ret < 0) {
+		pr_err("Error in releasing direct_mem access rc=%d\n", rc);
+		return ret;
+	}
+
+	return rc;
+}
+
+int fg_direct_mem_read(struct fg_dev *fg, u16 sram_addr, u8 offset,
+				u8 *val, int len)
+{
+	return __fg_direct_mem_rw(fg, sram_addr, offset, val, len, FG_READ);
+}
+
+int fg_direct_mem_write(struct fg_dev *fg, u16 sram_addr, u8 offset,
+				u8 *val, int len, bool atomic_access)
+{
+	return __fg_direct_mem_rw(fg, sram_addr, offset, val, len, FG_WRITE);
+}
+
+static int fg_ima_init(struct fg_dev *fg)
+{
+	int rc;
+
+	if (fg->version == GEN3_FG) {
+		fg->sram.num_bytes_per_word = 4;
+		fg->sram.address_max = 255;
+	} else if (fg->version == GEN4_FG) {
+		fg->sram.num_bytes_per_word = 2;
+		fg->sram.address_max = 480;
+	} else {
+		pr_err("Unknown FG version %d\n", fg->version);
+		return -ENXIO;
+	}
+
+	/*
+	 * Change the FG_MEM_INT interrupt to track IACS_READY
+	 * condition instead of end-of-transaction. This makes sure
+	 * that the next transaction starts only after the hw is ready.
+	 */
+	rc = fg_masked_write(fg, MEM_IF_IMA_CFG(fg), IACS_INTR_SRC_SLCT_BIT,
+				IACS_INTR_SRC_SLCT_BIT);
+	if (rc < 0) {
+		pr_err("failed to configure interrupt source %d\n", rc);
+		return rc;
+	}
+
+	/* Clear DMA errors if any before clearing IMA errors */
+	rc = fg_clear_dma_errors_if_any(fg);
+	if (rc < 0) {
+		pr_err("Error in checking DMA errors rc:%d\n", rc);
+		return rc;
+	}
+
+	/* Clear IMA errors if any before SRAM transactions can begin */
+	rc = fg_clear_ima_errors_if_any(fg, true);
+	if (rc < 0 && rc != -EAGAIN) {
+		pr_err("Error in checking IMA errors rc:%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+/*
+ * This SRAM partition to DMA address partition mapping remains identical for
+ * PMICs that use GEN3 FG.
+ */
+static struct fg_dma_address fg_gen3_addr_map[3] = {
+	/* system partition */
+	{
+		.partition_start = 0,
+		.partition_end = 23,
+		.spmi_addr_base = FG_DMA0_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* battery profile partition */
+	{
+		.partition_start = 24,
+		.partition_end = 79,
+		.spmi_addr_base = FG_DMA1_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* scratch pad partition */
+	{
+		.partition_start = 80,
+		.partition_end =  125,
+		.spmi_addr_base = FG_DMA2_BASE + SRAM_ADDR_OFFSET,
+	},
+};
+
+static struct fg_dma_address fg_gen4_addr_map[6] = {
+	/* system partition */
+	{
+		.partition_start = 0,
+		.partition_end = 63,
+		.spmi_addr_base = GEN4_FG_DMA0_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* battery profile partition */
+	{
+		.partition_start = 64,
+		.partition_end = 169,
+		.spmi_addr_base = GEN4_FG_DMA1_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* battery profile partition continued */
+	{
+		.partition_start = 170,
+		.partition_end = 274,
+		.spmi_addr_base = GEN4_FG_DMA2_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* dp/SW partition */
+	{
+		.partition_start = 275,
+		.partition_end = 299,
+		.spmi_addr_base = GEN4_FG_DMA3_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* wk/scratch pad partition */
+	{
+		.partition_start = 300,
+		.partition_end =  405,
+		.spmi_addr_base = GEN4_FG_DMA4_BASE + SRAM_ADDR_OFFSET,
+	},
+	/* wk/scratch pad partition continued */
+	{
+		.partition_start = 406,
+		.partition_end =  486,
+		.spmi_addr_base = GEN4_FG_DMA5_BASE + SRAM_ADDR_OFFSET,
+	},
+};
+
+static int fg_dma_init(struct fg_dev *fg)
+{
+	int rc;
+	u8 val;
+
+	if (fg->version == GEN3_FG) {
+		fg->sram.addr_map = fg_gen3_addr_map;
+		fg->sram.num_partitions = 3;
+		fg->sram.num_bytes_per_word = 4;
+		fg->sram.address_max = 255;
+	} else if (fg->version == GEN4_FG) {
+		fg->sram.addr_map = fg_gen4_addr_map;
+		fg->sram.num_partitions = 6;
+		fg->sram.num_bytes_per_word = 2;
+		fg->sram.address_max = 485;
+	} else {
+		pr_err("Unknown FG version %d\n", fg->version);
+		return -ENXIO;
+	}
+
+	/* Clear DMA errors if any before clearing IMA errors */
+	rc = fg_clear_dma_errors_if_any(fg);
+	if (rc < 0) {
+		pr_err("Error in checking DMA errors rc:%d\n", rc);
+		return rc;
+	}
+
+	/* Configure the DMA peripheral addressing to partition */
+	rc = fg_masked_write(fg, MEM_IF_DMA_CTL(fg), ADDR_KIND_BIT,
+				ADDR_KIND_BIT);
+	if (rc < 0) {
+		pr_err("failed to configure DMA_CTL rc:%d\n", rc);
+		return rc;
+	}
+
+	/* Release the DMA initially so that request can happen */
+	rc = fg_direct_mem_release(fg);
+	if (rc < 0) {
+		pr_err("Error in releasing direct_mem access rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/* Set low latency always and clear log bit */
+	rc = fg_masked_write(fg, MEM_IF_MEM_ARB_CFG(fg),
+		MEM_ARB_LO_LATENCY_EN_BIT | MEM_CLR_LOG_BIT,
+		MEM_ARB_LO_LATENCY_EN_BIT);
+	if (rc < 0) {
+		pr_err("failed to configure mem_if_mem_arb_cfg rc:%d\n", rc);
+		return rc;
+	}
+
+	/*
+	 * Configure PEEK_MUX for ALG active signal always for PM8150B.
+	 * For v1.0, it is used for DMA workaround. For v2.0 onwards, it is
+	 * used for ADC lockup workaround.
+	 */
+	val = ALG_ACTIVE_PEEK_CFG;
+	rc = fg_write(fg, BATT_INFO_PEEK_MUX4(fg), &val, 1);
+	if (rc < 0) {
+		pr_err("failed to configure batt_info_peek_mux4 rc:%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+int fg_memif_init(struct fg_dev *fg)
+{
+	if (fg->battery_missing)
+		return 0;
+
+	if (fg->use_dma)
+		return fg_dma_init(fg);
+
+	return fg_ima_init(fg);
+}
diff --git a/drivers/power/supply/qcom/fg-reg.h b/drivers/power/supply/qcom/fg-reg.h
new file mode 100644
index 000000000..a27251968
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-reg.h
@@ -0,0 +1,381 @@
+/* Copyright (c) 2016-2019, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __FG_REG_H__
+#define __FG_REG_H__
+
+/* FG_ADC_RR register definitions used only for READ */
+#define ADC_RR_FAKE_BATT_LOW_LSB(chip)		(chip->rradc_base + 0x58)
+#define ADC_RR_FAKE_BATT_HIGH_LSB(chip)		(chip->rradc_base + 0x5A)
+
+/* GEN4 FG definitions for FG_ADC_RR */
+#define ADC_RR_INT_RT_STS(chip)			(chip->rradc_base + 0x10)
+#define ADC_RR_BT_MISS_BIT			BIT(0)
+
+#define ADC_RR_BATT_ID_HI_BIAS_STS(chip)	(chip->rradc_base + 0x65)
+#define BIAS_STS_READY				BIT(0)
+
+#define ADC_RR_BATT_ID_HI_BIAS_LSB(chip)	(chip->rradc_base + 0x66)
+#define ADC_RR_BATT_ID_HI_BIAS_MSB(chip)	(chip->rradc_base + 0x67)
+
+#define ADC_RR_BATT_ID_MED_BIAS_STS(chip)	(chip->rradc_base + 0x6D)
+#define ADC_RR_BATT_ID_MED_BIAS_LSB(chip)	(chip->rradc_base + 0x6E)
+#define ADC_RR_BATT_ID_MED_BIAS_MSB(chip)	(chip->rradc_base + 0x6F)
+
+#define ADC_RR_BATT_ID_LO_BIAS_STS(chip)	(chip->rradc_base + 0x75)
+#define ADC_RR_BATT_ID_LO_BIAS_LSB(chip)	(chip->rradc_base + 0x76)
+#define ADC_RR_BATT_ID_LO_BIAS_MSB(chip)	(chip->rradc_base + 0x77)
+
+#define ADC_RR_BATT_THERM_BASE_CFG1(chip)	(chip->rradc_base + 0x81)
+#define BATT_THERM_PULL_UP_30K			1
+#define BATT_THERM_PULL_UP_100K			2
+#define BATT_THERM_PULL_UP_400K			3
+#define BATT_THERM_PULL_UP_MASK			GENMASK(1, 0)
+
+#define ADC_RR_BATT_THERM_FREQ(chip)		(chip->rradc_base + 0x82)
+
+#define ADC_RR_BATT_TEMP_LSB(chip)		(chip->rradc_base + 0x88)
+#define ADC_RR_BATT_TEMP_MSB(chip)		(chip->rradc_base + 0x89)
+#define GEN4_BATT_TEMP_MSB_MASK			GENMASK(1, 0)
+
+/* FG_BATT_SOC register definitions */
+#define BATT_SOC_FG_ALG_STS(chip)		(chip->batt_soc_base + 0x06)
+#define BATT_SOC_FG_ALG_AUX_STS0(chip)		(chip->batt_soc_base + 0x07)
+#define BATT_SOC_SLEEP_SHUTDOWN_STS(chip)	(chip->batt_soc_base + 0x08)
+#define BATT_SOC_FG_MONOTONIC_SOC(chip)		(chip->batt_soc_base + 0x09)
+#define BATT_SOC_FG_MONOTONIC_SOC_CP(chip)	(chip->batt_soc_base + 0x0A)
+#define BATT_SOC_RST_CTRL0(chip)		(chip->batt_soc_base + 0xBA)
+
+#define BATT_SOC_INT_RT_STS(chip)		(chip->batt_soc_base + 0x10)
+#define SOC_READY_BIT				BIT(1)
+#define MSOC_EMPTY_BIT				BIT(5)
+
+#define BATT_SOC_EN_CTL(chip)			(chip->batt_soc_base + 0x46)
+#define FG_ALGORITHM_EN_BIT			BIT(7)
+
+#define BATT_SOC_RESTART(chip)			(chip->batt_soc_base + 0x48)
+#define RESTART_GO_BIT				BIT(0)
+
+#define BATT_SOC_STS_CLR(chip)			(chip->batt_soc_base + 0x4A)
+#define BATT_SOC_LOW_PWR_CFG(chip)		(chip->batt_soc_base + 0x52)
+#define BATT_SOC_LOW_PWR_STS(chip)		(chip->batt_soc_base + 0x56)
+/* BATT_SOC_RST_CTRL0 */
+#define BCL_RST_BIT				BIT(2)
+#define MEM_RST_BIT				BIT(1)
+#define ALG_RST_BIT				BIT(0)
+
+/* FG_BATT_INFO register definitions */
+#define BATT_INFO_BATT_TEMP_STS(chip)		(chip->batt_info_base + 0x06)
+#define JEITA_TOO_HOT_STS_BIT			BIT(7)
+#define JEITA_HOT_STS_BIT			BIT(6)
+#define JEITA_COLD_STS_BIT			BIT(5)
+#define JEITA_TOO_COLD_STS_BIT			BIT(4)
+#define BATT_TEMP_DELTA_BIT			BIT(1)
+#define BATT_TEMP_AVAIL_BIT			BIT(0)
+
+#define BATT_INFO_SYS_BATT(chip)		(chip->batt_info_base + 0x07)
+#define BATT_REM_LATCH_STS_BIT			BIT(4)
+#define BATT_MISSING_HW_BIT			BIT(2)
+#define BATT_MISSING_ALG_BIT			BIT(1)
+#define BATT_MISSING_CMP_BIT			BIT(0)
+
+#define BATT_INFO_FG_STS(chip)			(chip->batt_info_base + 0x09)
+#define FG_WD_RESET_BIT				BIT(7)
+#define FG_CRG_TRM_BIT				BIT(0)
+
+#define BATT_INFO_INT_RT_STS(chip)		(chip->batt_info_base + 0x10)
+#define BT_TMPR_DELTA_BIT			BIT(6)
+#define WDOG_EXP_BIT				BIT(5)
+#define BT_ATTN_BIT				BIT(4)
+#define BT_MISS_BIT				BIT(3)
+#define ESR_DELTA_BIT				BIT(2)
+#define VBT_LOW_BIT				BIT(1)
+#define VBT_PRD_DELTA_BIT			BIT(0)
+
+/* GEN4 bit definitions */
+#define GEN4_BT_ATTN_BIT			BIT(5)
+#define GEN4_WDOG_EXP_BIT			BIT(4)
+#define GEN4_ESR_DELTA_BIT			BIT(3)
+#define GEN4_ESR_PULSE_PRE_BIT			BIT(2)
+#define GEN4_VBT_PRD_DELTA_BIT			BIT(1)
+#define GEN4_VBT_LOW_BIT			BIT(0)
+
+#define BATT_INFO_BATT_REM_LATCH(chip)		(chip->batt_info_base + 0x4F)
+#define BATT_REM_LATCH_CLR_BIT			BIT(7)
+
+#define BATT_INFO_BATT_TEMP_LSB(chip)		(chip->batt_info_base + 0x50)
+#define BATT_TEMP_LSB_MASK			GENMASK(7, 0)
+
+#define BATT_INFO_BATT_TEMP_MSB(chip)		(chip->batt_info_base + 0x51)
+#define BATT_TEMP_MSB_MASK			GENMASK(2, 0)
+
+#define BATT_INFO_BATT_TEMP_CFG(chip)		(chip->batt_info_base + 0x56)
+#define JEITA_TEMP_HYST_MASK			GENMASK(5, 4)
+#define JEITA_TEMP_HYST_SHIFT			4
+#define JEITA_TEMP_NO_HYST			0x0
+#define JEITA_TEMP_HYST_1C			0x1
+#define JEITA_TEMP_HYST_2C			0x2
+#define JEITA_TEMP_HYST_3C			0x3
+
+#define BATT_INFO_BATT_TMPR_INTR(chip)		(chip->batt_info_base + 0x59)
+#define CHANGE_THOLD_MASK			GENMASK(1, 0)
+#define BTEMP_DELTA_2K				0x0
+#define BTEMP_DELTA_4K				0x1
+#define BTEMP_DELTA_6K				0x2
+#define BTEMP_DELTA_10K				0x3
+
+#define BATT_INFO_THERM_C1(chip)		(chip->batt_info_base + 0x5C)
+#define BATT_INFO_THERM_COEFF_MASK		GENMASK(7, 0)
+
+#define BATT_INFO_THERM_C2(chip)		(chip->batt_info_base + 0x5D)
+#define BATT_INFO_THERM_C3(chip)		(chip->batt_info_base + 0x5E)
+
+#define BATT_INFO_THERM_HALF_RANGE(chip)	(chip->batt_info_base + 0x5F)
+#define BATT_INFO_THERM_TEMP_MASK		GENMASK(7, 0)
+
+#define BATT_INFO_JEITA_CTLS(chip)		(chip->batt_info_base + 0x61)
+#define JEITA_STS_CLEAR_BIT			BIT(0)
+
+#define BATT_INFO_JEITA_TOO_COLD(chip)		(chip->batt_info_base + 0x62)
+#define JEITA_THOLD_MASK			GENMASK(7, 0)
+
+#define BATT_INFO_JEITA_COLD(chip)		(chip->batt_info_base + 0x63)
+#define BATT_INFO_JEITA_HOT(chip)		(chip->batt_info_base + 0x64)
+#define BATT_INFO_JEITA_TOO_HOT(chip)		(chip->batt_info_base + 0x65)
+
+/* starting from v2.0 */
+#define BATT_INFO_ESR_GENERAL_CFG(chip)		(chip->batt_info_base + 0x68)
+#define ESR_DEEP_TAPER_EN_BIT			BIT(0)
+
+#define BATT_INFO_ESR_PULL_DN_CFG(chip)		(chip->batt_info_base + 0x69)
+#define ESR_PULL_DOWN_IVAL_MASK			GENMASK(3, 2)
+#define ESR_PULL_DOWN_IVAL_SHIFT		2
+#define ESR_MEAS_CUR_60MA			0x0
+#define ESR_MEAS_CUR_120MA			0x1
+#define ESR_MEAS_CUR_180MA			0x2
+#define ESR_MEAS_CUR_240MA			0x3
+#define ESR_PULL_DOWN_MODE_MASK			GENMASK(1, 0)
+#define ESR_NO_PULL_DOWN			0x0
+#define ESR_STATIC_PULL_DOWN			0x1
+#define ESR_CRG_DSC_PULL_DOWN			0x2
+#define ESR_DSC_PULL_DOWN			0x3
+
+#define BATT_INFO_ESR_FAST_CRG_CFG(chip)	(chip->batt_info_base + 0x6A)
+#define ESR_FAST_CRG_IVAL_MASK			GENMASK(3, 1)
+#define ESR_FCC_300MA				0x0
+#define ESR_FCC_600MA				0x1
+#define ESR_FCC_1A				0x2
+#define ESR_FCC_2A				0x3
+#define ESR_FCC_3A				0x4
+#define ESR_FCC_4A				0x5
+#define ESR_FCC_5A				0x6
+#define ESR_FCC_6A				0x7
+#define ESR_FAST_CRG_CTL_EN_BIT			BIT(0)
+
+/* GEN4 bit definitions */
+#define GEN4_ESR_FAST_CRG_IVAL_MASK		GENMASK(7, 4)
+#define GEN4_ESR_FAST_CRG_IVAL_SHIFT		4
+#define GEN4_ESR_FCC_300MA			0x0
+#define GEN4_ESR_FCC_600MA			0x1
+#define GEN4_ESR_FCC_1A				0x2
+#define GEN4_ESR_FCC_1P5_A			0x3
+#define GEN4_ESR_FCC_2A				0x4
+#define GEN4_ESR_FCC_2P5_A			0x5
+#define GEN4_ESR_FCC_3A				0x6
+#define GEN4_ESR_FCC_3P5_A			0x7
+#define GEN4_ESR_FCC_4A				0x8
+#define GEN4_ESR_FCC_4P5_A			0x9
+#define GEN4_ESR_FCC_5A				0xA
+#define GEN4_ESR_FCC_5P5_A			0xB
+#define GEN4_ESR_FCC_6A				0xC
+#define GEN4_ESR_FCC_6P5_A			0xD
+#define GEN4_ESR_FCC_7A				0xE
+#define GEN4_ESR_FCC_7P5_A			0xF
+
+#define BATT_INFO_BATT_MISS_CFG(chip)		(chip->batt_info_base + 0x6B)
+#define BM_THERM_TH_MASK			GENMASK(5, 4)
+#define RES_TH_0P75_MOHM			0x0
+#define RES_TH_1P00_MOHM			0x1
+#define RES_TH_1P50_MOHM			0x2
+#define RES_TH_3P00_MOHM			0x3
+#define BM_BATT_ID_TH_MASK			GENMASK(3, 2)
+#define BM_FROM_THERM_BIT			BIT(1)
+#define BM_FROM_BATT_ID_BIT			BIT(0)
+
+#define BATT_INFO_WATCHDOG_COUNT(chip)		(chip->batt_info_base + 0x70)
+#define WATCHDOG_COUNTER			GENMASK(7, 0)
+
+#define BATT_INFO_WATCHDOG_CFG(chip)		(chip->batt_info_base + 0x71)
+#define RESET_CAPABLE_BIT			BIT(2)
+#define PET_CTRL_BIT				BIT(1)
+#define ENABLE_CTRL_BIT				BIT(0)
+
+#define BATT_INFO_IBATT_SENSING_CFG(chip)	(chip->batt_info_base + 0x73)
+#define ADC_BITSTREAM_INV_BIT			BIT(4)
+#define SOURCE_SELECT_MASK			GENMASK(1, 0)
+#define SRC_SEL_BATFET				0x0
+#define SRC_SEL_BATFET_SMB			0x2
+#define SRC_SEL_RESERVED			0x3
+
+#define BATT_INFO_QNOVO_CFG(chip)		(chip->batt_info_base + 0x74)
+#define LD_REG_FORCE_CTL_BIT			BIT(2)
+#define LD_REG_CTRL_FORCE_HIGH			LD_REG_FORCE_CTL_BIT
+#define LD_REG_CTRL_FORCE_LOW			0
+#define LD_REG_CTRL_BIT				BIT(1)
+#define LD_REG_CTRL_REGISTER			LD_REG_CTRL_BIT
+#define LD_REG_CTRL_LOGIC			0
+#define BIT_STREAM_CFG_BIT			BIT(0)
+
+#define BATT_INFO_QNOVO_SCALER(chip)		(chip->batt_info_base + 0x75)
+#define QNOVO_SCALER_MASK			GENMASK(7, 0)
+
+/* starting from v2.0 */
+#define BATT_INFO_CRG_SERVICES(chip)		(chip->batt_info_base + 0x90)
+#define FG_CRC_TRM_EN_BIT			BIT(0)
+
+/* Following LSB/MSB address are for v2.0 and above; v1.1 have them swapped */
+#define BATT_INFO_VBATT_LSB(chip)		(chip->batt_info_base + 0xA0)
+#define BATT_INFO_VBATT_MSB(chip)		(chip->batt_info_base + 0xA1)
+#define VBATT_MASK				GENMASK(7, 0)
+
+#define BATT_INFO_IBATT_LSB(chip)		(chip->batt_info_base + 0xA2)
+#define BATT_INFO_IBATT_MSB(chip)		(chip->batt_info_base + 0xA3)
+#define IBATT_MASK				GENMASK(7, 0)
+
+#define BATT_INFO_ESR_LSB(chip)			(chip->batt_info_base + 0xA4)
+#define BATT_INFO_ESR_MSB(chip)			(chip->batt_info_base + 0xA5)
+#define ESR_LSB_MASK				GENMASK(7, 0)
+#define ESR_MSB_MASK				GENMASK(5, 0)
+
+#define BATT_INFO_VBATT_LSB_CP(chip)		(chip->batt_info_base + 0xA6)
+#define BATT_INFO_VBATT_MSB_CP(chip)		(chip->batt_info_base + 0xA7)
+#define BATT_INFO_IBATT_LSB_CP(chip)		(chip->batt_info_base + 0xA8)
+#define BATT_INFO_IBATT_MSB_CP(chip)		(chip->batt_info_base + 0xA9)
+#define BATT_INFO_ESR_LSB_CP(chip)		(chip->batt_info_base + 0xAA)
+#define BATT_INFO_ESR_MSB_CP(chip)		(chip->batt_info_base + 0xAB)
+
+#define BATT_INFO_VADC_LSB(chip)		(chip->batt_info_base + 0xAC)
+#define VADC_LSB_MASK				GENMASK(7, 0)
+
+#define BATT_INFO_VADC_MSB(chip)		(chip->batt_info_base + 0xAD)
+#define VADC_MSB_MASK				GENMASK(6, 0)
+
+#define BATT_INFO_IADC_LSB(chip)		(chip->batt_info_base + 0xAE)
+#define IADC_LSB_MASK				GENMASK(7, 0)
+
+#define BATT_INFO_IADC_MSB(chip)		(chip->batt_info_base + 0xAF)
+#define IADC_MSB_MASK				GENMASK(6, 0)
+
+#define BATT_INFO_FG_CNV_CHAR_CFG(chip)		(chip->batt_info_base + 0xB7)
+#define SMB_MEASURE_EN_BIT			BIT(2)
+
+#define BATT_INFO_TM_MISC(chip)			(chip->batt_info_base + 0xE5)
+#define FORCE_SEQ_RESP_TOGGLE_BIT		BIT(6)
+#define ALG_DIRECT_VALID_DATA_BIT		BIT(5)
+#define ALG_DIRECT_MODE_EN_BIT			BIT(4)
+#define BATT_VADC_CONV_BIT			BIT(3)
+#define BATT_IADC_CONV_BIT			BIT(2)
+#define ADC_ENABLE_REG_CTRL_BIT			BIT(1)
+#define WDOG_FORCE_EXP_BIT			BIT(0)
+
+#define BATT_INFO_TM_MISC1(chip)		(chip->batt_info_base + 0xE6)
+/* for v2.0 and above */
+#define ESR_REQ_CTL_BIT				BIT(1)
+#define ESR_REQ_CTL_EN_BIT			BIT(0)
+
+#define BATT_INFO_PEEK_MUX4(chip)		(chip->batt_info_base + 0xEE)
+#define ALG_ACTIVE_PEEK_CFG			0xAC
+
+#define BATT_INFO_PEEK_RD(chip)			(chip->batt_info_base + 0xEF)
+#define ALG_ACTIVE_BIT				BIT(3)
+
+/* FG_MEM_IF register and bit definitions */
+#define MEM_IF_INT_RT_STS(chip)			((chip->mem_if_base) + 0x10)
+#define MEM_XCP_BIT				BIT(1)
+#define MEM_GNT_BIT				BIT(2)
+#define GEN4_DMA_XCP_BIT			BIT(2)
+#define GEN4_MEM_GNT_BIT			BIT(3)
+#define GEN4_MEM_ATTN_BIT			BIT(4)
+
+#define MEM_IF_MEM_ARB_CFG(chip)		((chip->mem_if_base) + 0x40)
+#define MEM_CLR_LOG_BIT				BIT(2)
+#define MEM_ARB_LO_LATENCY_EN_BIT		BIT(1)
+#define MEM_ARB_REQ_BIT				BIT(0)
+
+#define MEM_IF_MEM_INTF_CFG(chip)		((chip->mem_if_base) + 0x50)
+#define MEM_ACCESS_REQ_BIT			BIT(7)
+#define IACS_SLCT_BIT				BIT(5)
+
+#define MEM_IF_IMA_CTL(chip)			((chip->mem_if_base) + 0x51)
+#define MEM_ACS_BURST_BIT			BIT(7)
+#define IMA_WR_EN_BIT				BIT(6)
+#define IMA_CTL_MASK				GENMASK(7, 6)
+
+#define MEM_IF_IMA_CFG(chip)			((chip->mem_if_base) + 0x52)
+#define IACS_CLR_BIT				BIT(2)
+#define IACS_INTR_SRC_SLCT_BIT			BIT(3)
+#define STATIC_CLK_EN_BIT			BIT(4)
+
+#define MEM_IF_IMA_OPR_STS(chip)		((chip->mem_if_base) + 0x54)
+#define IACS_RDY_BIT				BIT(1)
+
+#define MEM_IF_IMA_EXP_STS(chip)		((chip->mem_if_base) + 0x55)
+#define IACS_ERR_BIT				BIT(0)
+#define XCT_TYPE_ERR_BIT			BIT(1)
+#define DATA_RD_ERR_BIT				BIT(3)
+#define DATA_WR_ERR_BIT				BIT(4)
+#define ADDR_BURST_WRAP_BIT			BIT(5)
+#define ADDR_STABLE_ERR_BIT			BIT(7)
+
+#define MEM_IF_IMA_HW_STS(chip)			((chip->mem_if_base) + 0x56)
+
+#define MEM_IF_FG_BEAT_COUNT(chip)		((chip->mem_if_base) + 0x57)
+#define BEAT_COUNT_MASK				GENMASK(3, 0)
+
+#define MEM_IF_IMA_ERR_STS(chip)		((chip->mem_if_base) + 0x5F)
+#define ADDR_STBL_ERR_BIT			BIT(7)
+#define WR_ACS_ERR_BIT				BIT(6)
+#define RD_ACS_ERR_BIT				BIT(5)
+
+#define MEM_IF_IMA_BYTE_EN(chip)		((chip->mem_if_base) + 0x60)
+#define MEM_IF_ADDR_LSB(chip)			((chip->mem_if_base) + 0x61)
+#define MEM_IF_ADDR_MSB(chip)			((chip->mem_if_base) + 0x62)
+#define MEM_IF_WR_DATA0(chip)			((chip->mem_if_base) + 0x63)
+#define MEM_IF_WR_DATA1(chip)			((chip->mem_if_base) + 0x64)
+#define MEM_IF_WR_DATA3(chip)			((chip->mem_if_base) + 0x66)
+#define MEM_IF_RD_DATA0(chip)			((chip->mem_if_base) + 0x67)
+#define MEM_IF_RD_DATA1(chip)			((chip->mem_if_base) + 0x68)
+#define MEM_IF_RD_DATA3(chip)			((chip->mem_if_base) + 0x6A)
+
+#define MEM_IF_DMA_STS(chip)			((chip->mem_if_base) + 0x70)
+#define DMA_WRITE_ERROR_BIT			BIT(1)
+#define DMA_READ_ERROR_BIT			BIT(2)
+
+#define MEM_IF_DMA_CTL(chip)			((chip->mem_if_base) + 0x71)
+#define ADDR_KIND_BIT				BIT(1)
+#define DMA_CLEAR_LOG_BIT			BIT(0)
+
+/* FG_DMAx */
+#define FG_DMA0_BASE				0x4800
+#define FG_DMA1_BASE				0x4900
+#define FG_DMA2_BASE				0x4A00
+#define FG_DMA3_BASE				0x4B00
+#define SRAM_ADDR_OFFSET			0x20
+
+/* GEN4 FG_DMAx */
+#define GEN4_FG_DMA0_BASE			0x4400
+#define GEN4_FG_DMA1_BASE			0x4500
+#define GEN4_FG_DMA2_BASE			0x4600
+#define GEN4_FG_DMA3_BASE			0x4700
+#define GEN4_FG_DMA4_BASE			0x4800
+#define GEN4_FG_DMA5_BASE			0x4900
+#endif
diff --git a/drivers/power/supply/qcom/fg-util.c b/drivers/power/supply/qcom/fg-util.c
new file mode 100644
index 000000000..44f22baea
--- /dev/null
+++ b/drivers/power/supply/qcom/fg-util.c
@@ -0,0 +1,1696 @@
+/* Copyright (c) 2016-2019, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include <linux/sort.h>
+#include "fg-core.h"
+#include "fg-reg.h"
+
+/* 3 byte address + 1 space character */
+#define ADDR_LEN			4
+/* Format is 'XX ' */
+#define CHARS_PER_ITEM			3
+/* 4 data items per line */
+#define ITEMS_PER_LINE			4
+#define MAX_LINE_LENGTH			(ADDR_LEN + (ITEMS_PER_LINE *	\
+					CHARS_PER_ITEM) + 1)		\
+
+#define MAX_READ_TRIES		5
+
+#define VOLTAGE_24BIT_MSB_MASK	GENMASK(27, 16)
+#define VOLTAGE_24BIT_LSB_MASK	GENMASK(11, 0)
+int fg_decode_voltage_24b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int value)
+{
+	int msb, lsb, val;
+
+	msb = value & VOLTAGE_24BIT_MSB_MASK;
+	lsb = value & VOLTAGE_24BIT_LSB_MASK;
+	val = (msb >> 4) | lsb;
+	sp[id].value = div_s64((s64)val * sp[id].denmtr, sp[id].numrtr);
+	pr_debug("id: %d raw value: %x decoded value: %x\n", id, value,
+			sp[id].value);
+	return sp[id].value;
+}
+
+#define VOLTAGE_15BIT_MASK	GENMASK(14, 0)
+int fg_decode_voltage_15b(struct fg_sram_param *sp,
+				enum fg_sram_param_id id, int value)
+{
+	value &= VOLTAGE_15BIT_MASK;
+	sp[id].value = div_u64((u64)value * sp[id].denmtr, sp[id].numrtr);
+	pr_debug("id: %d raw value: %x decoded value: %x\n", id, value,
+		sp[id].value);
+	return sp[id].value;
+}
+
+#define CURRENT_24BIT_MSB_MASK	GENMASK(27, 16)
+#define CURRENT_24BIT_LSB_MASK	GENMASK(11, 0)
+int fg_decode_current_24b(struct fg_sram_param *sp,
+	enum fg_sram_param_id id, int value)
+{
+	int msb, lsb, val;
+
+	msb = value & CURRENT_24BIT_MSB_MASK;
+	lsb = value & CURRENT_24BIT_LSB_MASK;
+	val = (msb >> 4) | lsb;
+	val = sign_extend32(val, 23);
+	sp[id].value = div_s64((s64)val * sp[id].denmtr, sp[id].numrtr);
+	pr_debug("id: %d raw value: %x decoded value: %x\n", id, value,
+			sp[id].value);
+	return sp[id].value;
+}
+
+int fg_decode_current_16b(struct fg_sram_param *sp,
+				enum fg_sram_param_id id, int value)
+{
+	value = sign_extend32(value, 15);
+	sp[id].value = div_s64((s64)value * sp[id].denmtr, sp[id].numrtr);
+	pr_debug("id: %d raw value: %x decoded value: %d\n", id, value,
+		sp[id].value);
+	return sp[id].value;
+}
+
+int fg_decode_cc_soc(struct fg_sram_param *sp,
+				enum fg_sram_param_id id, int value)
+{
+	sp[id].value = div_s64((s64)value * sp[id].denmtr, sp[id].numrtr);
+	sp[id].value = sign_extend32(sp[id].value, 31);
+	pr_debug("id: %d raw value: %x decoded value: %x\n", id, value,
+		sp[id].value);
+	return sp[id].value;
+}
+
+int fg_decode_value_16b(struct fg_sram_param *sp,
+				enum fg_sram_param_id id, int value)
+{
+	sp[id].value = div_u64((u64)(u16)value * sp[id].denmtr, sp[id].numrtr);
+	pr_debug("id: %d raw value: %x decoded value: %x\n", id, value,
+		sp[id].value);
+	return sp[id].value;
+}
+
+int fg_decode_default(struct fg_sram_param *sp, enum fg_sram_param_id id,
+				int value)
+{
+	sp[id].value = value;
+	return sp[id].value;
+}
+
+int fg_decode(struct fg_sram_param *sp, enum fg_sram_param_id id,
+			int value)
+{
+	if (!sp[id].decode) {
+		pr_err("No decoding function for parameter %d\n", id);
+		return -EINVAL;
+	}
+
+	return sp[id].decode(sp, id, value);
+}
+
+void fg_encode_voltage(struct fg_sram_param *sp,
+				enum fg_sram_param_id  id, int val_mv, u8 *buf)
+{
+	int i, mask = 0xff;
+	int64_t temp;
+
+	val_mv += sp[id].offset;
+	temp = (int64_t)div_u64((u64)val_mv * sp[id].numrtr, sp[id].denmtr);
+	pr_debug("temp: %llx id: %d, val_mv: %d, buf: [ ", temp, id, val_mv);
+	for (i = 0; i < sp[id].len; i++) {
+		buf[i] = temp & mask;
+		temp >>= 8;
+		pr_debug("%x ", buf[i]);
+	}
+	pr_debug("]\n");
+}
+
+void fg_encode_current(struct fg_sram_param *sp,
+				enum fg_sram_param_id  id, int val_ma, u8 *buf)
+{
+	int i, mask = 0xff;
+	int64_t temp;
+	s64 current_ma;
+
+	current_ma = val_ma;
+	temp = (int64_t)div_s64(current_ma * sp[id].numrtr, sp[id].denmtr);
+	pr_debug("temp: %llx id: %d, val: %d, buf: [ ", temp, id, val_ma);
+	for (i = 0; i < sp[id].len; i++) {
+		buf[i] = temp & mask;
+		temp >>= 8;
+		pr_debug("%x ", buf[i]);
+	}
+	pr_debug("]\n");
+}
+
+void fg_encode_default(struct fg_sram_param *sp,
+				enum fg_sram_param_id  id, int val, u8 *buf)
+{
+	int i, mask = 0xff;
+	int64_t temp;
+
+	temp = (int64_t)div_s64((s64)val * sp[id].numrtr, sp[id].denmtr);
+	pr_debug("temp: %llx id: %d, val: %d, buf: [ ", temp, id, val);
+	for (i = 0; i < sp[id].len; i++) {
+		buf[i] = temp & mask;
+		temp >>= 8;
+		pr_debug("%x ", buf[i]);
+	}
+	pr_debug("]\n");
+}
+
+void fg_encode(struct fg_sram_param *sp, enum fg_sram_param_id id,
+			int val, u8 *buf)
+{
+	if (!sp[id].encode) {
+		pr_err("No encoding function for parameter %d\n", id);
+		return;
+	}
+
+	sp[id].encode(sp, id, val, buf);
+}
+
+/*
+ * Please make sure *_sram_params table has the entry for the parameter
+ * obtained through this function. In addition to address, offset,
+ * length from where this SRAM parameter is read, a decode function
+ * need to be specified.
+ */
+int fg_get_sram_prop(struct fg_dev *fg, enum fg_sram_param_id id,
+				int *val)
+{
+	int temp, rc, i;
+	u8 buf[4];
+
+	if (id < 0 || id > FG_SRAM_MAX || fg->sp[id].len > sizeof(buf))
+		return -EINVAL;
+
+	if (fg->battery_missing)
+		return 0;
+
+	rc = fg_sram_read(fg, fg->sp[id].addr_word, fg->sp[id].addr_byte,
+		buf, fg->sp[id].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error reading address %d[%d] rc=%d\n",
+			fg->sp[id].addr_word, fg->sp[id].addr_byte, rc);
+		return rc;
+	}
+
+	for (i = 0, temp = 0; i < fg->sp[id].len; i++)
+		temp |= buf[i] << (8 * i);
+
+	*val = fg_decode(fg->sp, id, temp);
+	return 0;
+}
+
+void fg_circ_buf_add(struct fg_circ_buf *buf, int val)
+{
+	buf->arr[buf->head] = val;
+	buf->head = (buf->head + 1) % ARRAY_SIZE(buf->arr);
+	buf->size = min(++buf->size, (int)ARRAY_SIZE(buf->arr));
+}
+
+void fg_circ_buf_clr(struct fg_circ_buf *buf)
+{
+	buf->size = 0;
+	buf->head = 0;
+	memset(buf->arr, 0, sizeof(buf->arr));
+}
+
+int fg_circ_buf_avg(struct fg_circ_buf *buf, int *avg)
+{
+	s64 result = 0;
+	int i;
+
+	if (buf->size == 0)
+		return -ENODATA;
+
+	for (i = 0; i < buf->size; i++)
+		result += buf->arr[i];
+
+	*avg = div_s64(result, buf->size);
+	return 0;
+}
+
+static int cmp_int(const void *a, const void *b)
+{
+	return *(int *)a - *(int *)b;
+}
+
+int fg_circ_buf_median(struct fg_circ_buf *buf, int *median)
+{
+	int *temp;
+
+	if (buf->size == 0)
+		return -ENODATA;
+
+	if (buf->size == 1) {
+		*median = buf->arr[0];
+		return 0;
+	}
+
+	temp = kmalloc_array(buf->size, sizeof(*temp), GFP_KERNEL);
+	if (!temp)
+		return -ENOMEM;
+
+	memcpy(temp, buf->arr, buf->size * sizeof(*temp));
+	sort(temp, buf->size, sizeof(*temp), cmp_int, NULL);
+
+	if (buf->size % 2)
+		*median = temp[buf->size / 2];
+	else
+		*median = (temp[buf->size / 2 - 1] + temp[buf->size / 2]) / 2;
+
+	kfree(temp);
+	return 0;
+}
+
+int fg_lerp(const struct fg_pt *pts, size_t tablesize, s32 input, s32 *output)
+{
+	int i;
+	s64 temp;
+
+	if (pts == NULL) {
+		pr_err("Table is NULL\n");
+		return -EINVAL;
+	}
+
+	if (tablesize < 1) {
+		pr_err("Table has no entries\n");
+		return -ENOENT;
+	}
+
+	if (tablesize == 1) {
+		*output = pts[0].y;
+		return 0;
+	}
+
+	if (pts[0].x > pts[1].x) {
+		pr_err("Table is not in acending order\n");
+		return -EINVAL;
+	}
+
+	if (input <= pts[0].x) {
+		*output = pts[0].y;
+		return 0;
+	}
+
+	if (input >= pts[tablesize - 1].x) {
+		*output = pts[tablesize - 1].y;
+		return 0;
+	}
+
+	for (i = 1; i < tablesize; i++) {
+		if (input >= pts[i].x)
+			continue;
+
+		temp = (s64)(pts[i].y - pts[i - 1].y) *
+						(s64)(input - pts[i - 1].x);
+		temp = div_s64(temp, pts[i].x - pts[i - 1].x);
+		*output = temp + pts[i - 1].y;
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+bool usb_psy_initialized(struct fg_dev *fg)
+{
+	if (fg->usb_psy)
+		return true;
+
+	fg->usb_psy = power_supply_get_by_name("usb");
+	if (!fg->usb_psy)
+		return false;
+
+	return true;
+}
+
+static bool is_usb_present(struct fg_dev *fg)
+{
+	union power_supply_propval pval = {0, };
+	int rc;
+
+	if (!usb_psy_initialized(fg))
+		return false;
+
+	rc = power_supply_get_property(fg->usb_psy,
+			POWER_SUPPLY_PROP_PRESENT, &pval);
+	if (rc < 0)
+		return false;
+
+	return pval.intval != 0;
+}
+
+bool dc_psy_initialized(struct fg_dev *fg)
+{
+	if (fg->dc_psy)
+		return true;
+
+	fg->dc_psy = power_supply_get_by_name("dc");
+	if (!fg->dc_psy)
+		return false;
+
+	return true;
+}
+
+static bool is_dc_present(struct fg_dev *fg)
+{
+	union power_supply_propval pval = {0, };
+	int rc;
+
+	if (!dc_psy_initialized(fg))
+		return false;
+
+	rc = power_supply_get_property(fg->dc_psy,
+			POWER_SUPPLY_PROP_PRESENT, &pval);
+	if (rc < 0)
+		return false;
+
+	return pval.intval != 0;
+}
+
+bool is_input_present(struct fg_dev *fg)
+{
+	return is_usb_present(fg) || is_dc_present(fg);
+}
+
+void fg_notify_charger(struct fg_dev *fg)
+{
+	union power_supply_propval prop = {0, };
+	int rc;
+
+	if (!fg->batt_psy)
+		return;
+
+	if (!fg->profile_available)
+		return;
+
+	if (fg->bp.float_volt_uv > 0) {
+		prop.intval = fg->bp.float_volt_uv;
+		rc = power_supply_set_property(fg->batt_psy,
+				POWER_SUPPLY_PROP_VOLTAGE_MAX, &prop);
+		if (rc < 0) {
+			pr_err("Error in setting voltage_max property on batt_psy, rc=%d\n",
+				rc);
+			return;
+		}
+	}
+
+	fg_dbg(fg, FG_STATUS, "Notified charger on float voltage and FCC\n");
+
+	/*if (fg->bp.fastchg_curr_ma > 0) {
+		prop.intval = fg->bp.fastchg_curr_ma * 1000;
+		rc = power_supply_set_property(fg->batt_psy,
+				POWER_SUPPLY_PROP_CONSTANT_CHARGE_CURRENT_MAX,
+				&prop);
+		if (rc < 0) {
+			pr_err("Error in setting constant_charge_current_max property on batt_psy, rc=%d\n",
+				rc);
+			return;
+		}
+	}*/
+}
+
+bool batt_psy_initialized(struct fg_dev *fg)
+{
+	if (fg->batt_psy)
+		return true;
+
+	fg->batt_psy = power_supply_get_by_name("pm8150b-charger");
+	if (!fg->batt_psy)
+		return false;
+
+	/* batt_psy is initialized, set the fcc and fv */
+	fg_notify_charger(fg);
+
+	return true;
+}
+
+bool pc_port_psy_initialized(struct fg_dev *fg)
+{
+	if (fg->pc_port_psy)
+		return true;
+
+	fg->pc_port_psy = power_supply_get_by_name("pc_port");
+	if (!fg->pc_port_psy)
+		return false;
+
+	return true;
+}
+
+bool is_parallel_charger_available(struct fg_dev *fg)
+{
+	if (!fg->parallel_psy)
+		fg->parallel_psy = power_supply_get_by_name("parallel");
+
+	if (!fg->parallel_psy)
+		return false;
+
+	return true;
+}
+
+#define EXPONENT_SHIFT		11
+#define EXPONENT_OFFSET		-9
+#define MANTISSA_SIGN_BIT	10
+#define MICRO_UNIT		1000000
+s64 fg_float_decode(u16 val)
+{
+	s8 exponent;
+	s32 mantissa;
+
+	/* mantissa bits are shifted out during sign extension */
+	exponent = ((s16)val >> EXPONENT_SHIFT) + EXPONENT_OFFSET;
+	/* exponent bits are shifted out during sign extension */
+	mantissa = sign_extend32(val, MANTISSA_SIGN_BIT) * MICRO_UNIT;
+
+	if (exponent < 0)
+		return (s64)mantissa >> -exponent;
+
+	return (s64)mantissa << exponent;
+}
+
+void fill_string(char *str, size_t str_len, u8 *buf, int buf_len)
+{
+	int pos = 0;
+	int i;
+
+	for (i = 0; i < buf_len; i++) {
+		pos += scnprintf(str + pos, str_len - pos, "%02x", buf[i]);
+		if (i < buf_len - 1)
+			pos += scnprintf(str + pos, str_len - pos, " ");
+	}
+}
+
+void dump_sram(struct fg_dev *fg, u8 *buf, int addr, int len)
+{
+	int i;
+	char str[16];
+
+	/*
+	 * Length passed should be in multiple of 4 as each GEN3 FG SRAM word
+	 * holds 4 bytes and GEN4 FG SRAM word holds 2 bytes. To keep this
+	 * simple, even if a length which is not a multiple of 4 bytes or less
+	 * than 4 bytes is passed, SRAM registers dumped will be always in
+	 * multiple of 4 bytes.
+	 */
+	for (i = 0; i < len; i += 4) {
+		str[0] = '\0';
+		fill_string(str, sizeof(str), buf + i, 4);
+
+		/*
+		 * We still print 4 bytes per line. However, the address
+		 * should be incremented by 2 for GEN4 FG as each word holds
+		 * 2 bytes.
+		 */
+		if (fg->version == GEN3_FG)
+			pr_info("%03d %s\n", addr + (i / 4), str);
+		else
+			pr_info("%03d %s\n", addr + (i / 2), str);
+	}
+}
+
+static inline bool fg_sram_address_valid(struct fg_dev *fg, u16 address,
+					int len)
+{
+	if (address > fg->sram.address_max || !fg->sram.num_bytes_per_word)
+		return false;
+
+	if ((address + DIV_ROUND_UP(len, fg->sram.num_bytes_per_word))
+			> fg->sram.address_max + 1)
+		return false;
+
+	return true;
+}
+
+#define SOC_UPDATE_WAIT_MS	1500
+int fg_sram_write(struct fg_dev *fg, u16 address, u8 offset,
+			u8 *val, int len, int flags)
+{
+	int rc = 0, tries = 0;
+	bool atomic_access = false;
+
+	if (!fg)
+		return -ENXIO;
+
+	if (fg->battery_missing)
+		return 0;
+
+	if (!fg_sram_address_valid(fg, address, len))
+		return -EFAULT;
+
+	if (!(flags & FG_IMA_NO_WLOCK))
+		vote(fg->awake_votable, SRAM_WRITE, true, 0);
+
+	if (flags & FG_IMA_ATOMIC)
+		atomic_access = true;
+
+	/* With DMA granted, SRAM transaction is already atomic */
+	if (fg->use_dma)
+		atomic_access = false;
+
+	mutex_lock(&fg->sram_rw_lock);
+
+	if (atomic_access && fg->irqs[SOC_UPDATE_IRQ].irq) {
+		/*
+		 * This interrupt need to be enabled only when it is
+		 * required. It will be kept disabled other times.
+		 */
+		reinit_completion(&fg->soc_update);
+		enable_irq(fg->irqs[SOC_UPDATE_IRQ].irq);
+	}
+
+	/*
+	 * Atomic access mean waiting upon SOC_UPDATE interrupt from
+	 * FG_ALG and do the transaction after that. This is to make
+	 * sure that there will be no SOC update happening when an
+	 * IMA write is happening. SOC_UPDATE interrupt fires every
+	 * FG cycle (~1.47 seconds).
+	 */
+	if (atomic_access) {
+		for (tries = 0; tries < 2; tries++) {
+			/* Wait for SOC_UPDATE completion */
+			rc = wait_for_completion_interruptible_timeout(
+				&fg->soc_update,
+				msecs_to_jiffies(SOC_UPDATE_WAIT_MS));
+			if (rc > 0) {
+				rc = 0;
+				break;
+			} else if (!rc) {
+				rc = -ETIMEDOUT;
+			}
+		}
+
+		if (rc < 0) {
+			pr_err("wait for soc_update timed out rc=%d\n", rc);
+			goto out;
+		}
+	}
+
+	if (fg->use_dma)
+		rc = fg_direct_mem_write(fg, address, offset, val, len,
+				false);
+	else
+		rc = fg_interleaved_mem_write(fg, address, offset, val, len,
+				atomic_access);
+
+	if (rc < 0)
+		pr_err("Error in writing SRAM address 0x%x[%d], rc=%d\n",
+			address, offset, rc);
+
+out:
+	if (atomic_access && fg->irqs[SOC_UPDATE_IRQ].irq)
+		disable_irq_nosync(fg->irqs[SOC_UPDATE_IRQ].irq);
+
+	mutex_unlock(&fg->sram_rw_lock);
+	if (!(flags & FG_IMA_NO_WLOCK))
+		vote(fg->awake_votable, SRAM_WRITE, false, 0);
+	return rc;
+}
+
+int fg_sram_read(struct fg_dev *fg, u16 address, u8 offset,
+			u8 *val, int len, int flags)
+{
+	int rc = 0;
+
+	if (!fg)
+		return -ENXIO;
+
+	if (fg->battery_missing)
+		return 0;
+
+	if (!fg_sram_address_valid(fg, address, len))
+		return -EFAULT;
+
+	if (!(flags & FG_IMA_NO_WLOCK))
+		vote(fg->awake_votable, SRAM_READ, true, 0);
+
+	mutex_lock(&fg->sram_rw_lock);
+
+	if (fg->use_dma)
+		rc = fg_direct_mem_read(fg, address, offset, val, len);
+	else
+		rc = fg_interleaved_mem_read(fg, address, offset, val, len);
+
+	if (rc < 0)
+		pr_err("Error in reading SRAM address 0x%x[%d], rc=%d\n",
+			address, offset, rc);
+
+	mutex_unlock(&fg->sram_rw_lock);
+	if (!(flags & FG_IMA_NO_WLOCK))
+		vote(fg->awake_votable, SRAM_READ, false, 0);
+	return rc;
+}
+
+int fg_sram_masked_write(struct fg_dev *fg, u16 address, u8 offset,
+			u8 mask, u8 val, int flags)
+{
+	int rc = 0, length = 4;
+	u8 buf[4];
+
+	if (fg->version == GEN4_FG)
+		length = 2;
+
+	rc = fg_sram_read(fg, address, 0, buf, length, flags);
+	if (rc < 0) {
+		pr_err("sram read failed: address=%03X, rc=%d\n", address, rc);
+		return rc;
+	}
+
+	buf[offset] &= ~mask;
+	buf[offset] |= val & mask;
+
+	rc = fg_sram_write(fg, address, 0, buf, length, flags);
+	if (rc < 0) {
+		pr_err("sram write failed: address=%03X, rc=%d\n", address, rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+int fg_read(struct fg_dev *fg, int addr, u8 *val, int len)
+{
+	int rc, i;
+
+	if (!fg || !fg->regmap)
+		return -ENXIO;
+
+	rc = regmap_bulk_read(fg->regmap, addr, val, len);
+
+	if (rc < 0) {
+		dev_err(fg->dev, "regmap_read failed for address %04x rc=%d\n",
+			addr, rc);
+		return rc;
+	}
+
+	if (*fg->debug_mask & FG_BUS_READ) {
+		pr_info("length %d addr=%04x\n", len, addr);
+		for (i = 0; i < len; i++)
+			pr_info("val[%d]: %02x\n", i, val[i]);
+	}
+
+	return 0;
+}
+
+static inline bool is_sec_access(struct fg_dev *fg, int addr)
+{
+	if (fg->version != GEN3_FG)
+		return false;
+
+	return ((addr & 0x00FF) > 0xB8);
+}
+
+int fg_write(struct fg_dev *fg, int addr, u8 *val, int len)
+{
+	int rc, i;
+
+	if (!fg || !fg->regmap)
+		return -ENXIO;
+
+	mutex_lock(&fg->bus_lock);
+	if (is_sec_access(fg, addr)) {
+		rc = regmap_write(fg->regmap, (addr & 0xFF00) | 0xD0, 0xA5);
+		if (rc < 0) {
+			dev_err(fg->dev, "regmap_write failed for address %x rc=%d\n",
+				addr, rc);
+			goto out;
+		}
+	}
+
+	if (len > 1)
+		rc = regmap_bulk_write(fg->regmap, addr, val, len);
+	else
+		rc = regmap_write(fg->regmap, addr, *val);
+
+	if (rc < 0) {
+		dev_err(fg->dev, "regmap_write failed for address %04x rc=%d\n",
+			addr, rc);
+		goto out;
+	}
+
+	if (*fg->debug_mask & FG_BUS_WRITE) {
+		pr_info("length %d addr=%04x\n", len, addr);
+		for (i = 0; i < len; i++)
+			pr_info("val[%d]: %02x\n", i, val[i]);
+	}
+out:
+	mutex_unlock(&fg->bus_lock);
+	return rc;
+}
+
+int fg_masked_write(struct fg_dev *fg, int addr, u8 mask, u8 val)
+{
+	int rc;
+
+	if (!fg || !fg->regmap)
+		return -ENXIO;
+
+	mutex_lock(&fg->bus_lock);
+	if (is_sec_access(fg, addr)) {
+		rc = regmap_write(fg->regmap, (addr & 0xFF00) | 0xD0, 0xA5);
+		if (rc < 0) {
+			dev_err(fg->dev, "regmap_write failed for address %x rc=%d\n",
+				addr, rc);
+			goto out;
+		}
+	}
+
+	rc = regmap_update_bits(fg->regmap, addr, mask, val);
+	if (rc < 0) {
+		dev_err(fg->dev, "regmap_update_bits failed for address %04x rc=%d\n",
+			addr, rc);
+		goto out;
+	}
+
+	fg_dbg(fg, FG_BUS_WRITE, "addr=%04x mask: %02x val: %02x\n", addr,
+		mask, val);
+out:
+	mutex_unlock(&fg->bus_lock);
+	return rc;
+}
+
+int fg_dump_regs(struct fg_dev *fg)
+{
+	int i, rc;
+	u8 buf[256];
+
+	if (!fg)
+		return -EINVAL;
+
+	rc = fg_read(fg, fg->batt_soc_base, buf, sizeof(buf));
+	if (rc < 0)
+		return rc;
+
+	pr_info("batt_soc_base registers:\n");
+	for (i = 0; i < sizeof(buf); i++)
+		pr_info("%04x:%02x\n", fg->batt_soc_base + i, buf[i]);
+
+	rc = fg_read(fg, fg->mem_if_base, buf, sizeof(buf));
+	if (rc < 0)
+		return rc;
+
+	pr_info("mem_if_base registers:\n");
+	for (i = 0; i < sizeof(buf); i++)
+		pr_info("%04x:%02x\n", fg->mem_if_base + i, buf[i]);
+
+	return 0;
+}
+
+int fg_restart(struct fg_dev *fg, int wait_time_ms)
+{
+	union power_supply_propval pval = {0, };
+	int rc;
+	bool tried_again = false;
+
+	if (!fg->fg_psy)
+		return -ENODEV;
+
+	rc = power_supply_get_property(fg->fg_psy, POWER_SUPPLY_PROP_CAPACITY,
+					&pval);
+	if (rc < 0) {
+		pr_err("Error in getting capacity, rc=%d\n", rc);
+		return rc;
+	}
+
+	fg->last_soc = pval.intval;
+	fg->fg_restarting = true;
+	reinit_completion(&fg->soc_ready);
+	rc = fg_masked_write(fg, BATT_SOC_RESTART(fg), RESTART_GO_BIT,
+			RESTART_GO_BIT);
+	if (rc < 0) {
+		pr_err("Error in writing to %04x, rc=%d\n",
+			BATT_SOC_RESTART(fg), rc);
+		goto out;
+	}
+
+wait:
+	rc = wait_for_completion_interruptible_timeout(&fg->soc_ready,
+		msecs_to_jiffies(wait_time_ms));
+
+	/* If we were interrupted wait again one more time. */
+	if (rc == -ERESTARTSYS && !tried_again) {
+		tried_again = true;
+		goto wait;
+	} else if (rc <= 0) {
+		pr_err("wait for soc_ready timed out rc=%d\n", rc);
+	}
+
+	rc = fg_masked_write(fg, BATT_SOC_RESTART(fg), RESTART_GO_BIT, 0);
+	if (rc < 0) {
+		pr_err("Error in writing to %04x, rc=%d\n",
+			BATT_SOC_RESTART(fg), rc);
+		goto out;
+	}
+out:
+	if (fg->empty_restart_fg)
+		fg->empty_restart_fg = false;
+	fg->fg_restarting = false;
+	return rc;
+}
+
+/* All fg_get_* , fg_set_* functions here */
+
+int fg_get_msoc_raw(struct fg_dev *fg, int *val)
+{
+	u8 cap[2];
+	int rc, tries = 0;
+
+	while (tries < MAX_READ_TRIES) {
+		rc = fg_read(fg, BATT_SOC_FG_MONOTONIC_SOC(fg), cap, 2);
+		if (rc < 0) {
+			pr_err("failed to read addr=0x%04x, rc=%d\n",
+				BATT_SOC_FG_MONOTONIC_SOC(fg), rc);
+			return rc;
+		}
+
+		if (cap[0] == cap[1])
+			break;
+
+		tries++;
+	}
+
+	if (tries == MAX_READ_TRIES) {
+		pr_err("MSOC: shadow registers do not match\n");
+		return -EINVAL;
+	}
+
+	fg_dbg(fg, FG_POWER_SUPPLY, "raw: 0x%02x\n", cap[0]);
+	*val = cap[0];
+	return 0;
+}
+
+int fg_get_msoc(struct fg_dev *fg, int *msoc)
+{
+	int rc;
+
+	rc = fg_get_msoc_raw(fg, msoc);
+	if (rc < 0)
+		return rc;
+
+	/*
+	 * To have better endpoints for 0 and 100, it is good to tune the
+	 * calculation discarding values 0 and 255 while rounding off. Rest
+	 * of the values 1-254 will be scaled to 1-99. DIV_ROUND_UP will not
+	 * be suitable here as it rounds up any value higher than 252 to 100.
+	 */
+	if ((*msoc >= FULL_SOC_REPORT_THR - 2)
+				&& (*msoc < FULL_SOC_RAW) && fg->report_full) {
+		*msoc = DIV_ROUND_CLOSEST(*msoc * FULL_CAPACITY, FULL_SOC_RAW) + 1;
+		if (*msoc >= FULL_CAPACITY)
+			*msoc = FULL_CAPACITY;
+	} else if (*msoc == FULL_SOC_RAW)
+		*msoc = 100;
+	else if (*msoc == 0)
+		*msoc = 0;
+	else if (*msoc >= FULL_SOC_REPORT_THR - 4 && *msoc <= FULL_SOC_REPORT_THR - 3 && fg->report_full)
+		*msoc = DIV_ROUND_CLOSEST(*msoc * FULL_CAPACITY, FULL_SOC_RAW);
+	else
+		*msoc = DIV_ROUND_CLOSEST((*msoc - 1) * (FULL_CAPACITY - 2),
+				FULL_SOC_RAW - 2) + 1;
+	return 0;
+}
+
+#define DEFAULT_BATT_TYPE	"Unknown Battery"
+#define MISSING_BATT_TYPE	"Missing Battery"
+#define LOADING_BATT_TYPE	"Loading Battery"
+#define SKIP_BATT_TYPE		"Skipped loading battery"
+const char *fg_get_battery_type(struct fg_dev *fg)
+{
+	switch (fg->profile_load_status) {
+	case PROFILE_MISSING:
+		return DEFAULT_BATT_TYPE;
+	case PROFILE_SKIPPED:
+		return SKIP_BATT_TYPE;
+	case PROFILE_LOADED:
+		if (fg->bp.batt_type_str)
+			return fg->bp.batt_type_str;
+		break;
+	case PROFILE_NOT_LOADED:
+		return MISSING_BATT_TYPE;
+	default:
+		break;
+	};
+
+	if (fg->battery_missing)
+		return MISSING_BATT_TYPE;
+
+	if (fg->profile_available)
+		return LOADING_BATT_TYPE;
+
+	return DEFAULT_BATT_TYPE;
+}
+
+int fg_get_battery_resistance(struct fg_dev *fg, int *val)
+{
+	int rc, esr_uohms, rslow_uohms;
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_ESR, &esr_uohms);
+	if (rc < 0) {
+		pr_err("failed to get ESR, rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_RSLOW, &rslow_uohms);
+	if (rc < 0) {
+		pr_err("failed to get Rslow, rc=%d\n", rc);
+		return rc;
+	}
+
+	*val = esr_uohms + rslow_uohms;
+	return 0;
+}
+
+#define BATT_CURRENT_NUMR	488281
+#define BATT_CURRENT_DENR	1000
+int fg_get_battery_current(struct fg_dev *fg, int *val)
+{
+	int rc = 0, tries = 0;
+	int64_t temp = 0;
+	u8 buf[2], buf_cp[2];
+
+	while (tries++ < MAX_READ_TRIES) {
+		rc = fg_read(fg, BATT_INFO_IBATT_LSB(fg), buf, 2);
+		if (rc < 0) {
+			pr_err("failed to read addr=0x%04x, rc=%d\n",
+				BATT_INFO_IBATT_LSB(fg), rc);
+			return rc;
+		}
+
+		rc = fg_read(fg, BATT_INFO_IBATT_LSB_CP(fg), buf_cp, 2);
+		if (rc < 0) {
+			pr_err("failed to read addr=0x%04x, rc=%d\n",
+				BATT_INFO_IBATT_LSB_CP(fg), rc);
+			return rc;
+		}
+
+		if (buf[0] == buf_cp[0] && buf[1] == buf_cp[1])
+			break;
+	}
+
+	if (tries == MAX_READ_TRIES) {
+		pr_err("IBATT: shadow registers do not match\n");
+		return -EINVAL;
+	}
+
+	if (fg->wa_flags & PMI8998_V1_REV_WA)
+		temp = buf[0] << 8 | buf[1];
+	else
+		temp = buf[1] << 8 | buf[0];
+
+	pr_debug("buf: %x %x temp: %llx\n", buf[0], buf[1], temp);
+	/* Sign bit is bit 15 */
+	temp = sign_extend32(temp, 15);
+	*val = div_s64((s64)temp * BATT_CURRENT_NUMR, BATT_CURRENT_DENR);
+	return 0;
+}
+
+#define BATT_VOLTAGE_NUMR	122070
+#define BATT_VOLTAGE_DENR	1000
+int fg_get_battery_voltage(struct fg_dev *fg, int *val)
+{
+	int rc = 0, tries = 0;
+	u16 temp = 0;
+	u8 buf[2], buf_cp[2];
+
+	while (tries++ < MAX_READ_TRIES) {
+		rc = fg_read(fg, BATT_INFO_VBATT_LSB(fg), buf, 2);
+		if (rc < 0) {
+			pr_err("failed to read addr=0x%04x, rc=%d\n",
+				BATT_INFO_VBATT_LSB(fg), rc);
+			return rc;
+		}
+
+		rc = fg_read(fg, BATT_INFO_VBATT_LSB_CP(fg), buf_cp, 2);
+		if (rc < 0) {
+			pr_err("failed to read addr=0x%04x, rc=%d\n",
+				BATT_INFO_VBATT_LSB_CP(fg), rc);
+			return rc;
+		}
+
+		if (buf[0] == buf_cp[0] && buf[1] == buf_cp[1])
+			break;
+	}
+
+	if (tries == MAX_READ_TRIES) {
+		pr_err("VBATT: shadow registers do not match\n");
+		return -EINVAL;
+	}
+
+	if (fg->wa_flags & PMI8998_V1_REV_WA)
+		temp = buf[0] << 8 | buf[1];
+	else
+		temp = buf[1] << 8 | buf[0];
+
+	pr_debug("buf: %x %x temp: %x\n", buf[0], buf[1], temp);
+	*val = div_u64((u64)temp * BATT_VOLTAGE_NUMR, BATT_VOLTAGE_DENR);
+	return 0;
+}
+
+int fg_set_constant_chg_voltage(struct fg_dev *fg, int volt_uv)
+{
+	u8 buf[2];
+	int rc;
+
+	if (volt_uv <= 0 || volt_uv > 15590000) {
+		pr_err("Invalid voltage %d\n", volt_uv);
+		return -EINVAL;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_VBATT_FULL, volt_uv, buf);
+
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_VBATT_FULL].addr_word,
+		fg->sp[FG_SRAM_VBATT_FULL].addr_byte, buf,
+		fg->sp[FG_SRAM_VBATT_FULL].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing vbatt_full, rc=%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+int fg_set_esr_timer(struct fg_dev *fg, int cycles_init,
+				int cycles_max, bool charging, int flags)
+{
+	u8 buf[2];
+	int rc, timer_max, timer_init;
+
+	if (cycles_init < 0 || cycles_max < 0)
+		return 0;
+
+	if (charging) {
+		timer_max = FG_SRAM_ESR_TIMER_CHG_MAX;
+		timer_init = FG_SRAM_ESR_TIMER_CHG_INIT;
+	} else {
+		timer_max = FG_SRAM_ESR_TIMER_DISCHG_MAX;
+		timer_init = FG_SRAM_ESR_TIMER_DISCHG_INIT;
+	}
+
+	fg_encode(fg->sp, timer_max, cycles_max, buf);
+	rc = fg_sram_write(fg,
+			fg->sp[timer_max].addr_word,
+			fg->sp[timer_max].addr_byte, buf,
+			fg->sp[timer_max].len, flags);
+	if (rc < 0) {
+		pr_err("Error in writing esr_timer_dischg_max, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, timer_init, cycles_init, buf);
+	rc = fg_sram_write(fg,
+			fg->sp[timer_init].addr_word,
+			fg->sp[timer_init].addr_byte, buf,
+			fg->sp[timer_init].len, flags);
+	if (rc < 0) {
+		pr_err("Error in writing esr_timer_dischg_init, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	fg_dbg(fg, FG_STATUS, "esr_%s_timer set to %d/%d\n",
+		charging ? "charging" : "discharging", cycles_init, cycles_max);
+	return 0;
+}
+
+static int fg_get_irq_index_byname(struct fg_dev *fg, const char *name,
+					int size)
+{
+	int i;
+
+	for (i = 0; i < size; i++) {
+		if (!fg->irqs[i].name)
+			continue;
+
+		if (strcmp(fg->irqs[i].name, name) == 0)
+			return i;
+	}
+
+	pr_err("%s is not in irq list\n", name);
+	return -ENOENT;
+}
+
+int fg_register_interrupts(struct fg_dev *fg, int size)
+{
+	struct device_node *child, *node = fg->dev->of_node;
+	struct property *prop;
+	const char *name;
+	int rc, irq, irq_index;
+
+	for_each_available_child_of_node(node, child) {
+		of_property_for_each_string(child, "interrupt-names", prop,
+						name) {
+			irq = of_irq_get_byname(child, name);
+			if (irq < 0) {
+				dev_err(fg->dev, "failed to get irq %s irq:%d\n",
+					name, irq);
+				return irq;
+			}
+
+			irq_index = fg_get_irq_index_byname(fg, name, size);
+			if (irq_index < 0)
+				return irq_index;
+
+			rc = devm_request_threaded_irq(fg->dev, irq, NULL,
+					fg->irqs[irq_index].handler,
+					IRQF_ONESHOT, name, fg);
+			if (rc < 0) {
+				dev_err(fg->dev, "failed to register irq handler for %s rc:%d\n",
+					name, rc);
+				return rc;
+			}
+
+			fg->irqs[irq_index].irq = irq;
+			if (fg->irqs[irq_index].wakeable)
+				enable_irq_wake(fg->irqs[irq_index].irq);
+		}
+	}
+
+	return 0;
+}
+
+void fg_unregister_interrupts(struct fg_dev *fg, void *data, int size)
+{
+	int i;
+
+	for (i = 0; i < size; i++) {
+		if (fg->irqs[i].irq)
+			devm_free_irq(fg->dev, fg->irqs[i].irq, data);
+	}
+
+}
+
+/* All the debugfs related functions are defined below */
+
+static struct fg_dbgfs dbgfs_data = {
+	.help_msg = {
+	.data =
+	"FG Debug-FS support\n"
+	"\n"
+	"Hierarchy schema:\n"
+	"/sys/kernel/debug/fg_sram\n"
+	"       /help            -- Static help text\n"
+	"       /address  -- Starting register address for reads or writes\n"
+	"       /count    -- Number of registers to read (only used for reads)\n"
+	"       /data     -- Initiates the SRAM read (formatted output)\n"
+	"\n",
+	},
+};
+
+static int fg_sram_dfs_open(struct inode *inode, struct file *file)
+{
+	struct fg_log_buffer *log;
+	struct fg_trans *trans;
+	u8 *data_buf;
+
+	size_t logbufsize = SZ_4K;
+	size_t databufsize = SZ_4K;
+
+	if (!dbgfs_data.fg) {
+		pr_err("Not initialized data\n");
+		return -EINVAL;
+	}
+
+	/* Per file "transaction" data */
+	trans = devm_kzalloc(dbgfs_data.fg->dev, sizeof(*trans), GFP_KERNEL);
+	if (!trans)
+		return -ENOMEM;
+
+	/* Allocate log buffer */
+	log = devm_kzalloc(dbgfs_data.fg->dev, logbufsize, GFP_KERNEL);
+	if (!log)
+		return -ENOMEM;
+
+	log->rpos = 0;
+	log->wpos = 0;
+	log->len = logbufsize - sizeof(*log);
+
+	/* Allocate data buffer */
+	data_buf = devm_kzalloc(dbgfs_data.fg->dev, databufsize, GFP_KERNEL);
+	if (!data_buf)
+		return -ENOMEM;
+
+	trans->log = log;
+	trans->data = data_buf;
+	trans->cnt = dbgfs_data.cnt;
+	trans->addr = dbgfs_data.addr;
+	trans->fg = dbgfs_data.fg;
+	trans->offset = trans->addr;
+	mutex_init(&trans->fg_dfs_lock);
+
+	file->private_data = trans;
+	return 0;
+}
+
+static int fg_sram_dfs_close(struct inode *inode, struct file *file)
+{
+	struct fg_trans *trans = file->private_data;
+
+	if (trans && trans->log && trans->data) {
+		file->private_data = NULL;
+		mutex_destroy(&trans->fg_dfs_lock);
+		devm_kfree(trans->fg->dev, trans->log);
+		devm_kfree(trans->fg->dev, trans->data);
+		devm_kfree(trans->fg->dev, trans);
+	}
+
+	return 0;
+}
+
+/**
+ * print_to_log: format a string and place into the log buffer
+ * @log: The log buffer to place the result into.
+ * @fmt: The format string to use.
+ * @...: The arguments for the format string.
+ *
+ * The return value is the number of characters written to @log buffer
+ * not including the trailing '\0'.
+ */
+static int print_to_log(struct fg_log_buffer *log, const char *fmt, ...)
+{
+	va_list args;
+	int cnt;
+	char *buf = &log->data[log->wpos];
+	size_t size = log->len - log->wpos;
+
+	va_start(args, fmt);
+	cnt = vscnprintf(buf, size, fmt, args);
+	va_end(args);
+
+	log->wpos += cnt;
+	return cnt;
+}
+
+/**
+ * write_next_line_to_log: Writes a single "line" of data into the log buffer
+ * @trans: Pointer to SRAM transaction data.
+ * @offset: SRAM address offset to start reading from.
+ * @pcnt: Pointer to 'cnt' variable.  Indicates the number of bytes to read.
+ *
+ * The 'offset' is a 12-bit SRAM address.
+ *
+ * On a successful read, the pcnt is decremented by the number of data
+ * bytes read from the SRAM.  When the cnt reaches 0, all requested bytes have
+ * been read.
+ */
+static int write_next_line_to_log(struct fg_trans *trans, int offset,
+				size_t *pcnt)
+{
+	int i;
+	u8 data[ITEMS_PER_LINE];
+	u16 address;
+	struct fg_log_buffer *log = trans->log;
+	int cnt = 0;
+	int items_to_read = min(ARRAY_SIZE(data), *pcnt);
+	int items_to_log = min(ITEMS_PER_LINE, items_to_read);
+
+	/* Buffer needs enough space for an entire line */
+	if ((log->len - log->wpos) < MAX_LINE_LENGTH)
+		goto done;
+
+	memcpy(data, trans->data + (offset - trans->addr), items_to_read);
+	*pcnt -= items_to_read;
+
+	if (trans->fg->version == GEN4_FG) {
+		/*
+		 * For GEN4 FG, address is in word and it increments by 1.
+		 * Each word holds 2 bytes. To keep the SRAM dump format
+		 * compatible, print 4 bytes per line which holds 2 words.
+		 */
+		address = trans->addr + ((offset - trans->addr) * 2 /
+				ITEMS_PER_LINE);
+	} else {
+		/*
+		 * For GEN3 FG, address is in word and it increments by 1.
+		 * Each word holds 4 bytes.
+		 */
+		address = trans->addr + ((offset - trans->addr) /
+			ITEMS_PER_LINE);
+	}
+
+	cnt = print_to_log(log, "%3.3d ", address & 0xfff);
+	if (cnt == 0)
+		goto done;
+
+	/* Log the data items */
+	for (i = 0; i < items_to_log; ++i) {
+		cnt = print_to_log(log, "%2.2X ", data[i]);
+		if (cnt == 0)
+			goto done;
+	}
+
+	/* If the last character was a space, then replace it with a newline */
+	if (log->wpos > 0 && log->data[log->wpos - 1] == ' ')
+		log->data[log->wpos - 1] = '\n';
+
+done:
+	return cnt;
+}
+
+/**
+ * get_log_data - reads data from SRAM and saves to the log buffer
+ * @trans: Pointer to SRAM transaction data.
+ *
+ * Returns the number of "items" read or SPMI error code for read failures.
+ */
+static int get_log_data(struct fg_trans *trans)
+{
+	int cnt, rc;
+	int last_cnt;
+	int items_read;
+	int total_items_read = 0;
+	u32 offset = trans->offset;
+	size_t item_cnt = trans->cnt;
+	struct fg_log_buffer *log = trans->log;
+
+	if (item_cnt == 0)
+		return 0;
+
+	if (item_cnt > SZ_4K) {
+		pr_err("Reading too many bytes\n");
+		return -EINVAL;
+	}
+
+	pr_debug("addr: %d offset: %d count: %d\n", trans->addr, trans->offset,
+		trans->cnt);
+	rc = fg_sram_read(trans->fg, trans->addr, 0,
+			trans->data, trans->cnt, 0);
+	if (rc < 0) {
+		pr_err("SRAM read failed: rc = %d\n", rc);
+		return rc;
+	}
+	/* Reset the log buffer 'pointers' */
+	log->wpos = log->rpos = 0;
+
+	/* Keep reading data until the log is full */
+	do {
+		last_cnt = item_cnt;
+		cnt = write_next_line_to_log(trans, offset, &item_cnt);
+		items_read = last_cnt - item_cnt;
+		offset += items_read;
+		total_items_read += items_read;
+	} while (cnt && item_cnt > 0);
+
+	/* Adjust the transaction offset and count */
+	trans->cnt = item_cnt;
+	trans->offset += total_items_read;
+
+	return total_items_read;
+}
+
+/**
+ * fg_sram_dfs_reg_read: reads value(s) from SRAM and fills user's buffer a
+ *  byte array (coded as string)
+ * @file: file pointer
+ * @buf: where to put the result
+ * @count: maximum space available in @buf
+ * @ppos: starting position
+ * @return number of user bytes read, or negative error value
+ */
+static ssize_t fg_sram_dfs_reg_read(struct file *file, char __user *buf,
+	size_t count, loff_t *ppos)
+{
+	struct fg_trans *trans = file->private_data;
+	struct fg_log_buffer *log = trans->log;
+	size_t ret;
+	size_t len;
+
+	mutex_lock(&trans->fg_dfs_lock);
+	/* Is the the log buffer empty */
+	if (log->rpos >= log->wpos) {
+		if (get_log_data(trans) <= 0) {
+			len = 0;
+			goto unlock_mutex;
+		}
+	}
+
+	len = min(count, log->wpos - log->rpos);
+
+	ret = copy_to_user(buf, &log->data[log->rpos], len);
+	if (ret == len) {
+		pr_err("error copy sram register values to user\n");
+		len = -EFAULT;
+		goto unlock_mutex;
+	}
+
+	/* 'ret' is the number of bytes not copied */
+	len -= ret;
+
+	*ppos += len;
+	log->rpos += len;
+
+unlock_mutex:
+	mutex_unlock(&trans->fg_dfs_lock);
+	return len;
+}
+
+/**
+ * fg_sram_dfs_reg_write: write user's byte array (coded as string) to SRAM.
+ * @file: file pointer
+ * @buf: user data to be written.
+ * @count: maximum space available in @buf
+ * @ppos: starting position
+ * @return number of user byte written, or negative error value
+ */
+static ssize_t fg_sram_dfs_reg_write(struct file *file, const char __user *buf,
+			size_t count, loff_t *ppos)
+{
+	int bytes_read;
+	int data;
+	int pos = 0;
+	int cnt = 0;
+	u8  *values;
+	char *kbuf;
+	size_t ret = 0;
+	struct fg_trans *trans = file->private_data;
+	u32 address = trans->addr;
+
+	mutex_lock(&trans->fg_dfs_lock);
+	/* Make a copy of the user data */
+	kbuf = kmalloc(count + 1, GFP_KERNEL);
+	if (!kbuf) {
+		ret = -ENOMEM;
+		goto unlock_mutex;
+	}
+
+	ret = copy_from_user(kbuf, buf, count);
+	if (ret == count) {
+		pr_err("failed to copy data from user\n");
+		ret = -EFAULT;
+		goto free_buf;
+	}
+
+	count -= ret;
+	*ppos += count;
+	kbuf[count] = '\0';
+
+	/* Override the text buffer with the raw data */
+	values = kbuf;
+
+	/* Parse the data in the buffer.  It should be a string of numbers */
+	while ((pos < count) &&
+		sscanf(kbuf + pos, "%i%n", &data, &bytes_read) == 1) {
+		/*
+		 * We shouldn't be receiving a string of characters that
+		 * exceeds a size of 5 to keep this functionally correct.
+		 * Also, we should make sure that pos never gets overflowed
+		 * beyond the limit.
+		 */
+		if (bytes_read > 5 || bytes_read > INT_MAX - pos) {
+			cnt = 0;
+			ret = -EINVAL;
+			break;
+		}
+		pos += bytes_read;
+		values[cnt++] = data & 0xff;
+	}
+
+	if (!cnt)
+		goto free_buf;
+
+	pr_debug("address %d, count %d\n", address, cnt);
+	/* Perform the write(s) */
+
+	ret = fg_sram_write(trans->fg, address, 0, values, cnt, 0);
+	if (ret) {
+		pr_err("SRAM write failed, err = %zu\n", ret);
+	} else {
+		ret = count;
+		trans->offset += cnt > 4 ? 4 : cnt;
+	}
+
+free_buf:
+	kfree(kbuf);
+unlock_mutex:
+	mutex_unlock(&trans->fg_dfs_lock);
+	return ret;
+}
+
+static const struct file_operations fg_sram_dfs_reg_fops = {
+	.open		= fg_sram_dfs_open,
+	.release	= fg_sram_dfs_close,
+	.read		= fg_sram_dfs_reg_read,
+	.write		= fg_sram_dfs_reg_write,
+};
+
+static int fg_sram_debugfs_create(struct fg_dev *fg)
+{
+	struct dentry *dfs_sram;
+	struct dentry *file;
+	mode_t dfs_mode = 0600;
+
+	pr_debug("Creating FG_SRAM debugfs file-system\n");
+	dfs_sram = debugfs_create_dir("sram", fg->dfs_root);
+	if (!dfs_sram) {
+		pr_err("error creating fg sram dfs rc=%ld\n",
+		       (long)dfs_sram);
+		return -ENOMEM;
+	}
+
+	dbgfs_data.help_msg.size = strlen(dbgfs_data.help_msg.data);
+	file = debugfs_create_blob("help", 0444, dfs_sram,
+					&dbgfs_data.help_msg);
+	if (!file) {
+		pr_err("error creating help entry\n");
+		goto err_remove_fs;
+	}
+
+	dbgfs_data.fg = fg;
+
+	debugfs_create_u32("count", dfs_mode, dfs_sram,
+					&(dbgfs_data.cnt));
+
+	debugfs_create_x32("address", dfs_mode, dfs_sram,
+					&(dbgfs_data.addr));
+
+	file = debugfs_create_file("data", dfs_mode, dfs_sram, &dbgfs_data,
+					&fg_sram_dfs_reg_fops);
+	if (!file) {
+		pr_err("error creating 'data' entry\n");
+		goto err_remove_fs;
+	}
+
+	return 0;
+
+err_remove_fs:
+	debugfs_remove_recursive(dfs_sram);
+	return -ENOMEM;
+}
+
+static int fg_alg_flags_open(struct inode *inode, struct file *file)
+{
+	file->private_data = inode->i_private;
+	return 0;
+}
+
+static ssize_t fg_alg_flags_read(struct file *file, char __user *userbuf,
+				 size_t count, loff_t *ppos)
+{
+	struct fg_dev *fg = file->private_data;
+	char buf[512];
+	u8 alg_flags = 0;
+	int rc, i, len;
+
+	rc = fg_sram_read(fg, fg->sp[FG_SRAM_ALG_FLAGS].addr_word,
+			  fg->sp[FG_SRAM_ALG_FLAGS].addr_byte, &alg_flags, 1,
+			  FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("failed to read algorithm flags rc=%d\n", rc);
+		return -EFAULT;
+	}
+
+	len = 0;
+	for (i = 0; i < ALG_FLAG_MAX; ++i) {
+		if (len > ARRAY_SIZE(buf) - 1)
+			return -EFAULT;
+		if (fg->alg_flags[i].invalid)
+			continue;
+
+		len += snprintf(buf + len, sizeof(buf) - sizeof(*buf) * len,
+				"%s = %d\n", fg->alg_flags[i].name,
+				(bool)(alg_flags & fg->alg_flags[i].bit));
+	}
+
+	return simple_read_from_buffer(userbuf, count, ppos, buf, len);
+}
+
+static const struct file_operations fg_alg_flags_fops = {
+	.open = fg_alg_flags_open,
+	.read = fg_alg_flags_read,
+};
+
+/*
+ * fg_debugfs_create: adds new fg_sram debugfs entry
+ * @return zero on success
+ */
+int fg_debugfs_create(struct fg_dev *fg)
+{
+	int rc;
+
+	pr_debug("Creating debugfs file-system\n");
+	fg->dfs_root = debugfs_create_dir("fg", NULL);
+	if (IS_ERR_OR_NULL(fg->dfs_root)) {
+		if (PTR_ERR(fg->dfs_root) == -ENODEV)
+			pr_err("debugfs is not enabled in the kernel\n");
+		else
+			pr_err("error creating fg dfs root rc=%ld\n",
+			       (long)fg->dfs_root);
+		return -ENODEV;
+	}
+
+	rc = fg_sram_debugfs_create(fg);
+	if (rc < 0) {
+		pr_err("failed to create sram dfs rc=%d\n", rc);
+		goto err_remove_fs;
+	}
+
+	if (fg->alg_flags) {
+		if (!debugfs_create_file("alg_flags", 0400, fg->dfs_root, fg,
+					 &fg_alg_flags_fops)) {
+			pr_err("failed to create alg_flags file\n");
+			goto err_remove_fs;
+		}
+	}
+
+	return 0;
+
+err_remove_fs:
+	debugfs_remove_recursive(fg->dfs_root);
+	return -ENOMEM;
+}
+
+void fg_stay_awake(struct fg_dev *fg, int awake_reason)
+{
+	spin_lock(&fg->awake_lock);
+
+	if (!fg->awake_status)
+		pm_stay_awake(fg->dev);
+
+	fg->awake_status |= awake_reason;
+
+	spin_unlock(&fg->awake_lock);
+}
+
+void fg_relax(struct fg_dev *fg, int awake_reason)
+{
+	spin_lock(&fg->awake_lock);
+
+	fg->awake_status &= ~awake_reason;
+
+	if (!fg->awake_status)
+		pm_relax(fg->dev);
+
+	spin_unlock(&fg->awake_lock);
+}
diff --git a/drivers/power/supply/qcom/of_batterydata.c b/drivers/power/supply/qcom/of_batterydata.c
new file mode 100644
index 000000000..e2f537e40
--- /dev/null
+++ b/drivers/power/supply/qcom/of_batterydata.c
@@ -0,0 +1,678 @@
+/* Copyright (c) 2013-2019, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt)	"%s: " fmt, __func__
+
+#include <linux/err.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/power_supply.h>
+#include "batterydata-lib.h"
+#include "of_batterydata.h"
+
+static int of_batterydata_read_lut(const struct device_node *np,
+			int max_cols, int max_rows, int *ncols, int *nrows,
+			int *col_legend_data, int *row_legend_data,
+			int *lut_data)
+{
+	struct property *prop;
+	const __be32 *data;
+	int cols, rows, size, i, j, *out_values;
+
+	prop = of_find_property(np, "qcom,lut-col-legend", NULL);
+	if (!prop) {
+		pr_err("%s: No col legend found\n", np->name);
+		return -EINVAL;
+	} else if (!prop->value) {
+		pr_err("%s: No col legend value found, np->name\n", np->name);
+		return -ENODATA;
+	} else if (prop->length > max_cols * sizeof(int)) {
+		pr_err("%s: Too many columns\n", np->name);
+		return -EINVAL;
+	}
+
+	cols = prop->length/sizeof(int);
+	*ncols = cols;
+	data = prop->value;
+	for (i = 0; i < cols; i++)
+		*col_legend_data++ = be32_to_cpup(data++);
+
+	rows = 0;
+
+	prop = of_find_property(np, "qcom,lut-row-legend", NULL);
+	if (!prop || row_legend_data == NULL) {
+		/* single row lut */
+		rows = 1;
+	} else if (!prop->value) {
+		pr_err("%s: No row legend value found\n", np->name);
+		return -ENODATA;
+	} else if (prop->length > max_rows * sizeof(int)) {
+		pr_err("%s: Too many rows\n", np->name);
+		return -EINVAL;
+	}
+
+	if (rows != 1) {
+		rows = prop->length/sizeof(int);
+		*nrows = rows;
+		data = prop->value;
+		for (i = 0; i < rows; i++)
+			*row_legend_data++ = be32_to_cpup(data++);
+	}
+
+	prop = of_find_property(np, "qcom,lut-data", NULL);
+	if (!prop) {
+		pr_err("prop 'qcom,lut-data' not found\n");
+		return -EINVAL;
+	}
+	data = prop->value;
+	size = prop->length/sizeof(int);
+	if (size != cols * rows) {
+		pr_err("%s: data size mismatch, %dx%d != %d\n",
+				np->name, cols, rows, size);
+		return -EINVAL;
+	}
+	for (i = 0; i < rows; i++) {
+		out_values = lut_data + (max_cols * i);
+		for (j = 0; j < cols; j++) {
+			*out_values++ = be32_to_cpup(data++);
+			pr_debug("Value = %d\n", *(out_values-1));
+		}
+	}
+
+	return 0;
+}
+
+static int of_batterydata_read_sf_lut(struct device_node *data_node,
+				const char *name, struct sf_lut *lut)
+{
+	struct device_node *node = of_find_node_by_name(data_node, name);
+	int rc;
+
+	if (!lut) {
+		pr_debug("No lut provided, skipping\n");
+		return 0;
+	} else if (!node) {
+		pr_err("Couldn't find %s node.\n", name);
+		return -EINVAL;
+	}
+
+	rc = of_batterydata_read_lut(node, PC_CC_COLS, PC_CC_ROWS,
+			&lut->cols, &lut->rows, lut->row_entries,
+			lut->percent, *lut->sf);
+	if (rc) {
+		pr_err("Failed to read %s node.\n", name);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int of_batterydata_read_pc_temp_ocv_lut(struct device_node *data_node,
+				const char *name, struct pc_temp_ocv_lut *lut)
+{
+	struct device_node *node = of_find_node_by_name(data_node, name);
+	int rc;
+
+	if (!lut) {
+		pr_debug("No lut provided, skipping\n");
+		return 0;
+	} else if (!node) {
+		pr_err("Couldn't find %s node.\n", name);
+		return -EINVAL;
+	}
+	rc = of_batterydata_read_lut(node, PC_TEMP_COLS, PC_TEMP_ROWS,
+			&lut->cols, &lut->rows, lut->temp, lut->percent,
+			*lut->ocv);
+	if (rc) {
+		pr_err("Failed to read %s node.\n", name);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int of_batterydata_read_ibat_temp_acc_lut(struct device_node *data_node,
+			const char *name, struct ibat_temp_acc_lut *lut)
+{
+	struct device_node *node = of_find_node_by_name(data_node, name);
+	int rc;
+
+	if (!lut) {
+		pr_debug("No lut provided, skipping\n");
+		return 0;
+	} else if (!node) {
+		pr_debug("Couldn't find %s node.\n", name);
+		return 0;
+	}
+	rc = of_batterydata_read_lut(node, ACC_TEMP_COLS, ACC_IBAT_ROWS,
+			&lut->cols, &lut->rows, lut->temp, lut->ibat,
+			*lut->acc);
+	if (rc) {
+		pr_err("Failed to read %s node.\n", name);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int of_batterydata_read_single_row_lut(struct device_node *data_node,
+				const char *name, struct single_row_lut *lut)
+{
+	struct device_node *node = of_find_node_by_name(data_node, name);
+	int rc;
+
+	if (!lut) {
+		pr_debug("No lut provided, skipping\n");
+		return 0;
+	} else if (!node) {
+		pr_err("Couldn't find %s node.\n", name);
+		return -EINVAL;
+	}
+
+	rc = of_batterydata_read_lut(node, MAX_SINGLE_LUT_COLS, 1,
+			&lut->cols, NULL, lut->x, NULL, lut->y);
+	if (rc) {
+		pr_err("Failed to read %s node.\n", name);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int of_batterydata_read_batt_id_kohm(const struct device_node *np,
+				const char *propname, struct batt_ids *batt_ids)
+{
+	struct property *prop;
+	const __be32 *data;
+	int num, i, *id_kohm = batt_ids->kohm;
+
+	prop = of_find_property(np, "qcom,batt-id-kohm", NULL);
+	if (!prop) {
+		pr_err("%s: No battery id resistor found\n", np->name);
+		return -EINVAL;
+	} else if (!prop->value) {
+		pr_err("%s: No battery id resistor value found, np->name\n",
+						np->name);
+		return -ENODATA;
+	} else if (prop->length > MAX_BATT_ID_NUM * sizeof(__be32)) {
+		pr_err("%s: Too many battery id resistors\n", np->name);
+		return -EINVAL;
+	}
+
+	num = prop->length/sizeof(__be32);
+	batt_ids->num = num;
+	data = prop->value;
+	for (i = 0; i < num; i++)
+		*id_kohm++ = be32_to_cpup(data++);
+
+	return 0;
+}
+
+#define OF_PROP_READ(property, qpnp_dt_property, node, rc, optional)	\
+do {									\
+	if (rc)								\
+		break;							\
+	rc = of_property_read_u32(node, "qcom," qpnp_dt_property,	\
+					&property);			\
+									\
+	if ((rc == -EINVAL) && optional) {				\
+		property = -EINVAL;					\
+		rc = 0;							\
+	} else if (rc) {						\
+		pr_err("Error reading " #qpnp_dt_property		\
+				" property rc = %d\n", rc);		\
+	}								\
+} while (0)
+
+static int of_batterydata_load_battery_data(struct device_node *node,
+				int best_id_kohm,
+				struct bms_battery_data *batt_data)
+{
+	int rc;
+
+	rc = of_batterydata_read_single_row_lut(node, "qcom,fcc-temp-lut",
+			batt_data->fcc_temp_lut);
+	if (rc)
+		return rc;
+
+	rc = of_batterydata_read_pc_temp_ocv_lut(node,
+			"qcom,pc-temp-ocv-lut",
+			batt_data->pc_temp_ocv_lut);
+	if (rc)
+		return rc;
+
+	rc = of_batterydata_read_sf_lut(node, "qcom,rbatt-sf-lut",
+			batt_data->rbatt_sf_lut);
+	if (rc)
+		return rc;
+
+	rc = of_batterydata_read_ibat_temp_acc_lut(node, "qcom,ibat-acc-lut",
+						batt_data->ibat_acc_lut);
+	if (rc)
+		return rc;
+
+	rc = of_property_read_string(node, "qcom,battery-type",
+					&batt_data->battery_type);
+	if (rc) {
+		pr_err("Error reading qcom,battery-type property rc=%d\n", rc);
+		batt_data->battery_type = NULL;
+		return rc;
+	}
+
+	OF_PROP_READ(batt_data->fcc, "fcc-mah", node, rc, false);
+	OF_PROP_READ(batt_data->default_rbatt_mohm,
+			"default-rbatt-mohm", node, rc, false);
+	OF_PROP_READ(batt_data->rbatt_capacitive_mohm,
+			"rbatt-capacitive-mohm", node, rc, false);
+	OF_PROP_READ(batt_data->flat_ocv_threshold_uv,
+			"flat-ocv-threshold-uv", node, rc, true);
+	OF_PROP_READ(batt_data->max_voltage_uv,
+			"max-voltage-uv", node, rc, true);
+	OF_PROP_READ(batt_data->cutoff_uv, "v-cutoff-uv", node, rc, true);
+	OF_PROP_READ(batt_data->iterm_ua, "chg-term-ua", node, rc, true);
+	OF_PROP_READ(batt_data->fastchg_current_ma,
+			"fastchg-current-ma", node, rc, true);
+	OF_PROP_READ(batt_data->fg_cc_cv_threshold_mv,
+			"fg-cc-cv-threshold-mv", node, rc, true);
+
+	batt_data->batt_id_kohm = best_id_kohm;
+
+	return rc;
+}
+
+static int64_t of_batterydata_convert_battery_id_kohm(int batt_id_uv,
+				int rpull_up, int vadc_vdd)
+{
+	int64_t resistor_value_kohm, denom;
+
+	if (batt_id_uv == 0) {
+		/* vadc not correct or batt id line grounded, report 0 kohms */
+		return 0;
+	}
+	/* calculate the battery id resistance reported via ADC */
+	denom = div64_s64(vadc_vdd * 1000000LL, batt_id_uv) - 1000000LL;
+
+	if (denom == 0) {
+		/* batt id connector might be open, return 0 kohms */
+		return 0;
+	}
+	resistor_value_kohm = div64_s64(rpull_up * 1000000LL + denom/2, denom);
+
+	pr_debug("batt id voltage = %d, resistor value = %lld\n",
+			batt_id_uv, resistor_value_kohm);
+
+	return resistor_value_kohm;
+}
+
+struct device_node *of_batterydata_get_best_profile(
+		const struct device_node *batterydata_container_node,
+		int batt_id_kohm, const char *batt_type)
+{
+	struct batt_ids batt_ids;
+	struct device_node *node, *best_node = NULL, *generic_node = NULL;
+	const char *battery_type = NULL;
+	int delta = 0, best_delta = 0, best_id_kohm = 0, id_range_pct,
+		i = 0, rc = 0, limit = 0;
+	bool in_range = false;
+
+	/* read battery id range percentage for best profile */
+	rc = of_property_read_u32(batterydata_container_node,
+			"qcom,batt-id-range-pct", &id_range_pct);
+
+	if (rc) {
+		if (rc == -EINVAL) {
+			id_range_pct = 0;
+		} else {
+			pr_err("failed to read battery id range\n");
+			return ERR_PTR(-ENXIO);
+		}
+	}
+
+	/*
+	 * Find the battery data with a battery id resistor closest to this one
+	 */
+	for_each_child_of_node(batterydata_container_node, node) {
+		if (batt_type != NULL) {
+			rc = of_property_read_string(node, "qcom,battery-type",
+							&battery_type);
+			if (!rc && strcmp(battery_type, batt_type) == 0) {
+				best_node = node;
+				best_id_kohm = batt_id_kohm;
+				break;
+			}
+		} else {
+			rc = of_batterydata_read_batt_id_kohm(node,
+							"qcom,batt-id-kohm",
+							&batt_ids);
+			if (rc)
+				continue;
+			for (i = 0; i < batt_ids.num; i++) {
+				delta = abs(batt_ids.kohm[i] - batt_id_kohm);
+				limit = (batt_ids.kohm[i] * id_range_pct) / 100;
+				in_range = (delta <= limit);
+				/*
+				 * Check if the delta is the lowest one
+				 * and also if the limits are in range
+				 * before selecting the best node.
+				 */
+				if ((delta < best_delta || !best_node)
+					&& in_range) {
+					best_node = node;
+					best_delta = delta;
+					best_id_kohm = batt_ids.kohm[i];
+				}
+			}
+		}
+		rc = of_property_read_string(node, "qcom,battery-type",
+							&battery_type);
+		if (!rc && strcmp(battery_type, "itech_3000mah") == 0)
+				generic_node = node;
+	}
+
+	if (best_node == NULL) {
+		/* now that best_node is null, there is no need to
+		 * check whether generic node is null. */
+		best_node = generic_node;
+		pr_err("No battery data found,use generic one\n");
+		return best_node;
+	}
+
+	/* check that profile id is in range of the measured batt_id */
+	if (abs(best_id_kohm - batt_id_kohm) >
+			((best_id_kohm * id_range_pct) / 100)) {
+		pr_err("out of range: profile id %d batt id %d pct %d",
+			best_id_kohm, batt_id_kohm, id_range_pct);
+		return NULL;
+	}
+
+	rc = of_property_read_string(best_node, "qcom,battery-type",
+							&battery_type);
+	if (!rc)
+		pr_info("%s found\n", battery_type);
+	else
+		pr_info("%s found\n", best_node->name);
+
+	return best_node;
+}
+EXPORT_SYMBOL(of_batterydata_get_best_profile);
+
+struct device_node *of_batterydata_get_best_aged_profile(
+		const struct device_node *batterydata_container_node,
+		int batt_id_kohm, int batt_age_level, int *avail_age_level)
+{
+	struct batt_ids batt_ids;
+	struct device_node *node, *best_node = NULL;
+	const char *battery_type = NULL;
+	int delta = 0, best_id_kohm = 0, id_range_pct, i = 0, rc = 0, limit = 0;
+	u32 val;
+	bool in_range = false;
+
+	/* read battery id range percentage for best profile */
+	rc = of_property_read_u32(batterydata_container_node,
+			"qcom,batt-id-range-pct", &id_range_pct);
+
+	if (rc) {
+		if (rc == -EINVAL) {
+			id_range_pct = 0;
+		} else {
+			pr_err("failed to read battery id range\n");
+			return ERR_PTR(-ENXIO);
+		}
+	}
+
+	/*
+	 * Find the battery data with a battery id resistor closest to this one
+	 */
+	for_each_available_child_of_node(batterydata_container_node, node) {
+		val = 0;
+		of_property_read_u32(node, "qcom,batt-age-level", &val);
+		rc = of_batterydata_read_batt_id_kohm(node,
+						"qcom,batt-id-kohm", &batt_ids);
+		if (rc)
+			continue;
+		for (i = 0; i < batt_ids.num; i++) {
+			delta = abs(batt_ids.kohm[i] - batt_id_kohm);
+			limit = (batt_ids.kohm[i] * id_range_pct) / 100;
+			in_range = (delta <= limit);
+
+			/*
+			 * Check if the battery aging level matches and the
+			 * limits are in range before selecting the best node.
+			 */
+			if ((batt_age_level == val || !best_node) && in_range) {
+				best_node = node;
+				best_id_kohm = batt_ids.kohm[i];
+				*avail_age_level = val;
+				break;
+			}
+		}
+	}
+
+	if (best_node == NULL) {
+		pr_err("No battery data found\n");
+		return best_node;
+	}
+
+	/* check that profile id is in range of the measured batt_id */
+	if (abs(best_id_kohm - batt_id_kohm) >
+			((best_id_kohm * id_range_pct) / 100)) {
+		pr_err("out of range: profile id %d batt id %d pct %d",
+			best_id_kohm, batt_id_kohm, id_range_pct);
+		return NULL;
+	}
+
+	rc = of_property_read_string(best_node, "qcom,battery-type",
+							&battery_type);
+	if (!rc)
+		pr_info("%s age level %d found\n", battery_type,
+			*avail_age_level);
+	else
+		pr_info("%s age level %d found\n", best_node->name,
+			*avail_age_level);
+
+	return best_node;
+}
+EXPORT_SYMBOL(of_batterydata_get_best_aged_profile);
+
+int of_batterydata_get_aged_profile_count(
+		const struct device_node *batterydata_node,
+		int batt_id_kohm, int *count)
+{
+	struct device_node *node;
+	int id_range_pct, i = 0, rc = 0, limit = 0, delta = 0;
+	bool in_range = false;
+	u32 batt_id;
+
+	/* read battery id range percentage for best profile */
+	rc = of_property_read_u32(batterydata_node,
+			"qcom,batt-id-range-pct", &id_range_pct);
+	if (rc) {
+		if (rc == -EINVAL) {
+			id_range_pct = 0;
+		} else {
+			pr_err("failed to read battery id range\n");
+			return -ENXIO;
+		}
+	}
+
+	for_each_available_child_of_node(batterydata_node, node) {
+		if (!of_find_property(node, "qcom,batt-age-level", NULL))
+			continue;
+
+		if (!of_find_property(node, "qcom,soh-range", NULL))
+			continue;
+
+		rc = of_property_read_u32(node, "qcom,batt-id-kohm", &batt_id);
+		if (rc)
+			continue;
+
+		delta = abs(batt_id_kohm - batt_id);
+		limit = (batt_id_kohm * id_range_pct) / 100;
+		in_range = (delta <= limit);
+
+		if (!in_range) {
+			pr_debug("not in range batt_id: %d\n", batt_id);
+			continue;
+		}
+
+		i++;
+	}
+
+	if (i <= 1) {
+		pr_err("Less number of profiles to support SOH\n");
+		return -EINVAL;
+	}
+
+	*count = i;
+	return 0;
+}
+EXPORT_SYMBOL(of_batterydata_get_aged_profile_count);
+
+int of_batterydata_read_soh_aged_profiles(
+		const struct device_node *batterydata_node,
+		int batt_id_kohm, struct soh_range *soh_data)
+{
+	struct device_node *node;
+	u32 val, temp[2], i = 0;
+	int rc, batt_id, id_range_pct, limit = 0, delta = 0;
+	bool in_range = false;
+
+	if (!batterydata_node || !soh_data)
+		return -ENODEV;
+
+	/* read battery id range percentage for best profile */
+	rc = of_property_read_u32(batterydata_node,
+			"qcom,batt-id-range-pct", &id_range_pct);
+	if (rc) {
+		if (rc == -EINVAL) {
+			id_range_pct = 0;
+		} else {
+			pr_err("failed to read battery id range\n");
+			return -ENXIO;
+		}
+	}
+
+	for_each_available_child_of_node(batterydata_node, node) {
+		rc = of_property_read_u32(node, "qcom,batt-age-level", &val);
+		if (rc)
+			continue;
+
+		rc = of_property_read_u32(node, "qcom,batt-id-kohm", &batt_id);
+		if (rc)
+			continue;
+
+		delta = abs(batt_id_kohm - batt_id);
+		limit = (batt_id_kohm * id_range_pct) / 100;
+		in_range = (delta <= limit);
+
+		if (!in_range) {
+			pr_debug("not in range batt_id: %d\n", batt_id);
+			continue;
+		}
+
+		if (!of_find_property(node, "qcom,soh-range", NULL))
+			continue;
+
+		rc = of_property_count_elems_of_size(node, "qcom,soh-range",
+						sizeof(u32));
+		if (rc != 2) {
+			pr_err("Incorrect element size for qcom,soh-range, rc=%d\n",
+				rc);
+			return -EINVAL;
+		}
+
+		rc = of_property_read_u32_array(node, "qcom,soh-range", temp,
+						2);
+		if (rc < 0) {
+			pr_err("Error in reading qcom,soh-range, rc=%d\n", rc);
+			return rc;
+		}
+
+		if (temp[0] > 100 || temp[1] > 100 || (temp[0] > temp[1])) {
+			pr_err("Incorrect SOH range [%d %d]\n", temp[0],
+				temp[1]);
+			return -ERANGE;
+		}
+
+		pr_debug("batt_age_level: %d soh: [%d %d]\n", val, temp[0],
+			temp[1]);
+		soh_data[i].batt_age_level = val;
+		soh_data[i].soh_min = temp[0];
+		soh_data[i].soh_max = temp[1];
+		i++;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(of_batterydata_read_soh_aged_profiles);
+
+int of_batterydata_read_data(struct device_node *batterydata_container_node,
+				struct bms_battery_data *batt_data,
+				int batt_id_uv)
+{
+	struct device_node *node, *best_node;
+	struct batt_ids batt_ids;
+	const char *battery_type = NULL;
+	int delta, best_delta, batt_id_kohm, rpull_up_kohm,
+		vadc_vdd_uv, best_id_kohm, i, rc = 0;
+
+	node = batterydata_container_node;
+	OF_PROP_READ(rpull_up_kohm, "rpull-up-kohm", node, rc, false);
+	OF_PROP_READ(vadc_vdd_uv, "vref-batt-therm", node, rc, false);
+	if (rc)
+		return rc;
+
+	batt_id_kohm = of_batterydata_convert_battery_id_kohm(batt_id_uv,
+					rpull_up_kohm, vadc_vdd_uv);
+	best_node = NULL;
+	best_delta = 0;
+	best_id_kohm = 0;
+
+	/*
+	 * Find the battery data with a battery id resistor closest to this one
+	 */
+	for_each_child_of_node(batterydata_container_node, node) {
+		rc = of_batterydata_read_batt_id_kohm(node,
+						"qcom,batt-id-kohm",
+						&batt_ids);
+		if (rc)
+			continue;
+		for (i = 0; i < batt_ids.num; i++) {
+			delta = abs(batt_ids.kohm[i] - batt_id_kohm);
+			if (delta < best_delta || !best_node) {
+				best_node = node;
+				best_delta = delta;
+				best_id_kohm = batt_ids.kohm[i];
+			}
+		}
+	}
+
+	if (best_node == NULL) {
+		pr_err("No battery data found\n");
+		return -ENODATA;
+	}
+	rc = of_property_read_string(best_node, "qcom,battery-type",
+							&battery_type);
+	if (!rc)
+		pr_info("%s loaded\n", battery_type);
+	else
+		pr_info("%s loaded\n", best_node->name);
+
+	return of_batterydata_load_battery_data(best_node,
+					best_id_kohm, batt_data);
+}
+EXPORT_SYMBOL(of_batterydata_read_data);
+
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/power/supply/qcom/of_batterydata.h b/drivers/power/supply/qcom/of_batterydata.h
new file mode 100644
index 000000000..427dc2357
--- /dev/null
+++ b/drivers/power/supply/qcom/of_batterydata.h
@@ -0,0 +1,91 @@
+/* Copyright (c) 2013-2014, 2016-2019 The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/of.h>
+#include "batterydata-lib.h"
+
+/**
+ * of_batterydata_read_data() - Populate battery data from the device tree
+ * @container_node: pointer to the battery-data container device node
+ *		containing the profile nodes.
+ * @batt_data: pointer to an allocated bms_battery_data structure that the
+ *		loaded profile will be written to.
+ * @batt_id_uv: ADC voltage of the battery id line used to differentiate
+ *		between different battery profiles. If there are multiple
+ *		battery data in the device tree, the one with the closest
+ *		battery id resistance will be automatically loaded.
+ *
+ * This routine loads the closest match battery data from device tree based on
+ * the battery id reading. Then, it will try to load all the relevant data from
+ * the device tree battery data profile.
+ *
+ * If any of the lookup table pointers are NULL, this routine will skip trying
+ * to read them.
+ */
+int of_batterydata_read_data(struct device_node *container_node,
+				struct bms_battery_data *batt_data,
+				int batt_id_uv);
+/**
+ * of_batterydata_get_best_profile() - Find matching battery data device node
+ * @batterydata_container_node: pointer to the battery-data container device
+ *		node containing the profile nodes.
+ * @batt_id_kohm: Battery ID in KOhms for which we want to find the profile.
+ * @batt_type: Battery type which we want to force load the profile.
+ *
+ * This routine returns a device_node pointer to the closest match battery data
+ * from device tree based on the battery id reading.
+ */
+struct device_node *of_batterydata_get_best_profile(
+		const struct device_node *batterydata_container_node,
+		int batt_id_kohm, const char *batt_type);
+
+/**
+ * of_batterydata_get_best_aged_profile() - Find best aged battery profile
+ * @batterydata_container_node: pointer to the battery-data container device
+ *		node containing the profile nodes.
+ * @batt_id_kohm: Battery ID in KOhms for which we want to find the profile.
+ * @batt_age_level: Battery age level.
+ * @avail_age_level: Available battery age level.
+ *
+ * This routine returns a device_node pointer to the closest match battery data
+ * from device tree based on the battery id reading and age level.
+ */
+struct device_node *of_batterydata_get_best_aged_profile(
+		const struct device_node *batterydata_container_node,
+		int batt_id_kohm, int batt_age_level, int *avail_age_level);
+
+/**
+ * of_batterydata_get_aged_profile_count() - Gets the number of aged profiles
+ * @batterydata_node: pointer to the battery-data container device
+ *		node containing the profile nodes.
+ * @batt_id_kohm: Battery ID in KOhms for which we want to find the profile.
+ * @count: Number of aged profiles available to support SOH based profile
+ * loading.
+ *
+ * This routine returns zero if valid number of aged profiles are available.
+ */
+int of_batterydata_get_aged_profile_count(
+		const struct device_node *batterydata_node,
+		int batt_id_kohm, int *count);
+
+/**
+ * of_batterydata_read_soh_aged_profiles() - Reads the data from aged profiles
+ * @batterydata_node: pointer to the battery-data container device
+ *		node containing the profile nodes.
+ * @batt_id_kohm: Battery ID in KOhms for which we want to find the profile.
+ * @soh_data: SOH data from the profile if it is found to be valid.
+ *
+ * This routine returns zero if SOH data of aged profiles is valid.
+ */
+int of_batterydata_read_soh_aged_profiles(
+		const struct device_node *batterydata_node,
+		int batt_id_kohm, struct soh_range *soh_data);
diff --git a/drivers/power/supply/qcom/pm8150b_charger.c b/drivers/power/supply/qcom/pm8150b_charger.c
new file mode 100644
index 000000000..861a3b34f
--- /dev/null
+++ b/drivers/power/supply/qcom/pm8150b_charger.c
@@ -0,0 +1,1091 @@
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+#include <linux/interrupt.h>
+#include <linux/power_supply.h>
+#include <linux/of.h>
+#include <linux/of_irq.h>
+#include "smb5-reg.h"
+#include "smb5-lib.h"
+
+static struct smb_params smb5_pm8150b_params = {
+	.otg_cl			= {
+		.name	= "usb otg current limit",
+		.reg	= DCDC_OTG_CURRENT_LIMIT_CFG_REG,
+		.min_u	= 500000,
+		.max_u	= 1000000,
+		.step_u	= 500000,
+	},
+	.dc_icl 	= {
+		.name	= "DC input current limit",
+		.reg	= DCDC_CFG_REF_MAX_PSNS_REG,
+		.min_u	= 0,
+		.max_u	= 1200000,
+		.step_u = 40000,
+	},
+};
+
+#define smblib_err(chg, fmt, ...)		\
+	pr_err("%s: %s: " fmt, chg->name,	\
+		__func__, ##__VA_ARGS__)	\
+
+#define smblib_dbg(chg, reason, fmt, ...)			\
+	do {							\
+		if (*chg->debug_mask & (reason))		\
+			pr_err("%s: %s: " fmt, chg->name,	\
+				__func__, ##__VA_ARGS__);	\
+		else						\
+			pr_debug("%s: %s: " fmt, chg->name,	\
+				__func__, ##__VA_ARGS__);	\
+	} while (0)
+
+struct smb_dt_props {
+
+};
+
+struct smb5 {
+	struct smb_charger	chg;
+	struct smb_dt_props	dt;
+};
+
+static int __debug_mask = PR_INTERRUPT | PR_MISC | PR_PARALLEL | PR_OTG | PR_WLS | PR_OEM;
+
+static int smb5_parse_dt(struct smb5 *chip)
+{
+	return 0;
+}
+
+/*************************
+ * DC PSY REGISTRATION   *
+ *************************/
+
+static enum power_supply_property smb5_dc_props[] = {
+	POWER_SUPPLY_PROP_STATUS,
+	POWER_SUPPLY_PROP_ONLINE,
+	POWER_SUPPLY_PROP_HEALTH,
+	/* battery */
+	POWER_SUPPLY_PROP_PRESENT,
+	POWER_SUPPLY_PROP_CHARGE_TYPE,
+};
+
+static int smb5_dc_get_prop(struct power_supply *psy,
+		enum power_supply_property psp,
+		union power_supply_propval *val)
+{
+	struct smb5 *chip = power_supply_get_drvdata(psy);
+	struct smb_charger *chg = &chip->chg;
+	int rc = 0;
+
+	switch (psp) {
+	case POWER_SUPPLY_PROP_STATUS:
+		rc = smblib_get_prop_batt_status(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_ONLINE:
+//		rc = smblib_get_prop_dc_online(chg, val);
+		rc = smblib_get_prop_usb_online(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_HEALTH:
+		rc = smblib_get_prop_batt_health(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_PRESENT:
+		rc = smblib_get_prop_batt_present(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_TYPE:
+		rc = smblib_get_prop_batt_charge_type(chg, val);
+		break;
+	default:
+		return -EINVAL;
+	}
+	if (rc < 0) {
+		pr_debug("Couldn't get prop %d rc = %d\n", psp, rc);
+		return -ENODATA;
+	}
+
+	return 0;
+}
+
+static const struct power_supply_desc dc_psy_desc = {
+	.name = "pm8150b-charger",
+	.type = POWER_SUPPLY_TYPE_MAINS,
+	.properties = smb5_dc_props,
+	.num_properties = ARRAY_SIZE(smb5_dc_props),
+	.get_property = smb5_dc_get_prop,
+};
+
+static int smb5_init_dc_psy(struct smb5 *chip)
+{
+	struct power_supply_config dc_cfg = {};
+	struct smb_charger *chg = &chip->chg;
+
+	dc_cfg.drv_data = chip;
+	dc_cfg.of_node = chg->dev->of_node;
+	chg->dc_psy = devm_power_supply_register(chg->dev,
+						  &dc_psy_desc,
+						  &dc_cfg);
+	if (IS_ERR(chg->dc_psy)) {
+		pr_err("Couldn't register dc power supply\n");
+		return PTR_ERR(chg->dc_psy);
+	}
+
+	return 0;
+}
+#if 0
+/*************************
+ * BATT PSY REGISTRATION *
+ *************************/
+static enum power_supply_property smb5_batt_props[] = {
+	POWER_SUPPLY_PROP_PRESENT,
+	POWER_SUPPLY_PROP_CHARGE_TYPE,
+	POWER_SUPPLY_PROP_VOLTAGE_NOW,
+	POWER_SUPPLY_PROP_CURRENT_NOW,
+	POWER_SUPPLY_PROP_CHARGE_FULL,
+	POWER_SUPPLY_PROP_CAPACITY,
+};
+
+static int smb5_batt_get_prop(struct power_supply *psy,
+		enum power_supply_property psp,
+		union power_supply_propval *val)
+{
+	struct smb_charger *chg = power_supply_get_drvdata(psy);
+	int rc = 0;
+
+	switch (psp) {
+	case POWER_SUPPLY_PROP_PRESENT:
+		rc = smblib_get_prop_batt_present(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_TYPE:
+		rc = smblib_get_prop_batt_charge_type(chg, val);
+		break;
+	case POWER_SUPPLY_PROP_VOLTAGE_NOW:
+		rc = smblib_get_prop_from_bms(chg,
+				POWER_SUPPLY_PROP_VOLTAGE_NOW, val);
+		break;
+	case POWER_SUPPLY_PROP_CURRENT_NOW:
+		rc = smblib_get_prop_from_bms(chg,
+				POWER_SUPPLY_PROP_CURRENT_NOW, val);
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_FULL:
+		rc = smblib_get_prop_from_bms(chg,
+				POWER_SUPPLY_PROP_CHARGE_FULL, val);
+		break;
+	case POWER_SUPPLY_PROP_CAPACITY:
+		rc = smblib_get_prop_from_bms(chg,
+				POWER_SUPPLY_PROP_CAPACITY, val);
+		break;
+	default:
+		pr_err("batt power supply prop %d not supported\n", psp);
+		return -EINVAL;
+	}
+
+	if (rc < 0) {
+		pr_debug("Couldn't get prop %d rc = %d\n", psp, rc);
+		return -ENODATA;
+	}
+
+	return 0;
+}
+
+static const struct power_supply_desc batt_psy_desc = {
+	.name = "battery",
+	.type = POWER_SUPPLY_TYPE_BATTERY,
+	.properties = smb5_batt_props,
+	.num_properties = ARRAY_SIZE(smb5_batt_props),
+	.get_property = smb5_batt_get_prop,
+};
+
+static int smb5_init_batt_psy(struct smb5 *chip)
+{
+	struct power_supply_config batt_cfg = {};
+	struct smb_charger *chg = &chip->chg;
+	int rc = 0;
+
+	batt_cfg.drv_data = chg;
+	batt_cfg.of_node = chg->dev->of_node;
+	chg->batt_psy = devm_power_supply_register(chg->dev,
+					   &batt_psy_desc,
+					   &batt_cfg);
+	if (IS_ERR(chg->batt_psy)) {
+		pr_err("Couldn't register battery power supply\n");
+		return PTR_ERR(chg->batt_psy);
+	}
+
+	return rc;
+}
+#endif
+#define RAW_ITERM(iterm_ma, max_range)				\
+		div_s64((int64_t)iterm_ma * ADC_CHG_ITERM_MASK, max_range)
+static int smb5_configure_iterm_thresholds_adc(struct smb5 *chip)
+{
+	u8 *buf;
+	int rc = 0;
+	s16 raw_hi_thresh, max_limit_ma;
+	struct smb_charger *chg = &chip->chg;
+
+	max_limit_ma = ITERM_LIMITS_PM8150B_MA;
+
+	/*
+	 * Conversion:
+	 *	raw (A) = (term_current * ADC_CHG_ITERM_MASK) / max_limit_ma
+	 * Note: raw needs to be converted to big-endian format.
+	 */
+
+	raw_hi_thresh = RAW_ITERM(-400, max_limit_ma);
+	raw_hi_thresh = sign_extend32(raw_hi_thresh, 15);
+	buf = (u8 *)&raw_hi_thresh;
+	rc = smblib_write(chg, CHGR_ADC_ITERM_UP_THD_MSB_REG,
+				buf[1]);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't set term MSB rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = smblib_write(chg, CHGR_ADC_ITERM_UP_THD_LSB_REG,
+				buf[0]);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't set term LSB rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+static int smb5_configure_iterm_thresholds(struct smb5 *chip)
+{
+	int rc = 0;
+	struct smb_charger *chg = &chip->chg;
+
+	rc = smblib_masked_write(chg, CHGR_ADC_TERM_CFG_REG,
+			TERM_BASED_ON_SYNC_CONV_OR_SAMPLE_CNT,
+			TERM_BASED_ON_SAMPLE_CNT);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure ADC_ITERM_CFG rc=%d\n",
+				rc);
+		return rc;
+	}
+	rc = smb5_configure_iterm_thresholds_adc(chip);
+
+	return rc;
+}
+
+static int smb5_configure_mitigation(struct smb_charger *chg)
+{
+	int rc;
+	u8 src_cfg = 0;
+
+	src_cfg = THERMREG_SW_ICL_ADJUST_BIT;
+
+	rc = smblib_masked_write(chg, MISC_THERMREG_SRC_CFG_REG,
+		THERMREG_SW_ICL_ADJUST_BIT | THERMREG_DIE_ADC_SRC_EN_BIT |
+		THERMREG_DIE_CMP_SRC_EN_BIT | THERMREG_SKIN_ADC_SRC_EN_BIT |
+		SKIN_ADC_CFG_BIT | THERMREG_CONNECTOR_ADC_SRC_EN_BIT, src_cfg);
+	if (rc < 0) {
+		dev_err(chg->dev,
+				"Couldn't configure THERM_SRC reg rc=%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int smb5_init_dc_peripheral(struct smb_charger *chg)
+{
+	int rc = 0;
+
+	/* Set DCIN ICL to 100 mA */
+	rc = smblib_set_charge_param(chg, &chg->param.dc_icl, DCIN_ICL_MIN_UA);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't set dc_icl rc=%d\n", rc);
+		return rc;
+	}
+
+	/* Disable DC Input missing poller function */
+	rc = smblib_masked_write(chg, DCIN_LOAD_CFG_REG,
+					INPUT_MISS_POLL_EN_BIT, 0);
+	if (rc < 0) {
+		dev_err(chg->dev,
+			"Couldn't disable DC Input missing poller rc=%d\n", rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+static int smb5_init_hw(struct smb5 *chip)
+{
+	struct smb_charger *chg = &chip->chg;
+	int rc;
+	u8 val = 0, mask = 0;
+	union power_supply_propval pval;
+
+	/* configure temperature mitigation */
+	rc = smb5_configure_mitigation(chg);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure mitigation rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	/*
+	 * Disable HVDCP by default
+	 */
+	rc = smblib_masked_write(chg, USBIN_OPTIONS_1_CFG_REG,
+			(HVDCP_AUTH_ALG_EN_CFG_BIT | HVDCP_EN_BIT |
+			 HVDCP_AUTONOMOUS_MODE_EN_CFG_BIT),
+			0);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure HVDCP rc=%d\n", rc);
+		return rc;
+	}
+
+	/* Use ICL results from HW */
+	rc = smblib_icl_override(chg, HW_AUTO_MODE);
+	if (rc < 0) {
+		pr_err("Couldn't disable ICL override rc=%d\n", rc);
+		return rc;
+	}
+
+	/* set OTG current limit */
+	rc = smblib_set_charge_param(chg, &chg->param.otg_cl, 1000000);
+	if (rc < 0) {
+		pr_err("Couldn't set otg current limit rc=%d\n", rc);
+		return rc;
+	}
+
+	/* Initialize DC peripheral configurations */
+	rc = smb5_init_dc_peripheral(chg);
+	if (rc < 0) {
+		dev_err(chg->dev,
+				"Couldn't disable DC Input missing poller rc=%d\n", rc);
+		return rc;
+	}
+
+	/*
+	 * AICL configuration: enable aicl and aicl rerun and based on DT
+	 * configuration enable/disable ADB based AICL and Suspend on collapse.
+	 */
+	mask = USBIN_AICL_PERIODIC_RERUN_EN_BIT | USBIN_AICL_ADC_EN_BIT
+			| USBIN_AICL_EN_BIT | SUSPEND_ON_COLLAPSE_USBIN_BIT;
+	val = USBIN_AICL_PERIODIC_RERUN_EN_BIT | USBIN_AICL_EN_BIT;
+
+	rc = smblib_masked_write(chg, USBIN_AICL_OPTIONS_CFG_REG,
+			mask, val);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't config AICL rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_write(chg, AICL_RERUN_TIME_CFG_REG,
+				AICL_RERUN_TIME_12S_VAL);
+	if (rc < 0) {
+		dev_err(chg->dev,
+			"Couldn't configure AICL rerun interval rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, DCIN_BASE + 0x65 , BIT(5), 0);
+	if (rc < 0) {
+		dev_err(chg->dev,
+			"Couldn't configure IMP rc=%d\n", rc);
+	}
+
+	/* configure VBUS for software control */
+	rc = smblib_masked_write(chg, DCDC_OTG_CFG_REG, OTG_EN_SRC_CFG_BIT, 0);
+	if (rc < 0) {
+		dev_err(chg->dev,
+			"Couldn't configure VBUS for SW control rc=%d\n", rc);
+		return rc;
+	}
+
+	val = (ilog2(16 / 16) << BARK_WDOG_TIMEOUT_SHIFT)
+			& BARK_WDOG_TIMEOUT_MASK;
+	val |= BITE_WDOG_TIMEOUT_8S;
+	val |= (0x7 << SNARL_WDOG_TIMEOUT_SHIFT)
+			& SNARL_WDOG_TIMEOUT_MASK;
+
+	rc = smblib_masked_write(chg, SNARL_BARK_BITE_WD_CFG_REG,
+			BITE_WDOG_DISABLE_CHARGING_CFG_BIT |
+			SNARL_WDOG_TIMEOUT_MASK | BARK_WDOG_TIMEOUT_MASK |
+			BITE_WDOG_TIMEOUT_MASK,
+			val);
+	if (rc < 0) {
+		pr_err("Couldn't configue WD config rc=%d\n", rc);
+		return rc;
+	}
+
+	/* enable WD BARK and enable it on plugin */
+	val = WDOG_TIMER_EN_ON_PLUGIN_BIT | BARK_WDOG_INT_EN_BIT;
+	rc = smblib_masked_write(chg, WD_CFG_REG,
+			WATCHDOG_TRIGGER_AFP_EN_BIT |
+			WDOG_TIMER_EN_ON_PLUGIN_BIT |
+			BARK_WDOG_INT_EN_BIT |
+			WDOG_TIMER_EN_BIT,
+			WDOG_TIMER_EN_ON_PLUGIN_BIT |
+			BARK_WDOG_INT_EN_BIT);
+	if (rc < 0) {
+		pr_err("Couldn't configue WD config rc=%d\n", rc);
+		return rc;
+	}
+
+	/* set termination current threshold values */
+	rc = smb5_configure_iterm_thresholds(chip);
+	if (rc < 0) {
+		pr_err("Couldn't configure ITERM thresholds rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	/* Update float charger setting and set DCD timeout 300ms */
+	/* Recover DCD time to deault value 600ms */
+	rc = smblib_masked_write(chg, USBIN_OPTIONS_2_CFG_REG,
+				FLOAT_OPTIONS_MASK, 0);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't change float charger setting rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/*
+	 *  Disable Charge inhibit threshold
+	 */
+	rc = smblib_masked_write(chg, CHGR_CFG2_REG,
+			CHARGER_INHIBIT_BIT, 0);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure charge inhibit threshold rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = smblib_write(chg, CHGR_FAST_CHARGE_SAFETY_TIMER_CFG_REG,
+					FAST_CHARGE_SAFETY_TIMER_1536_MIN);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't set CHGR_FAST_CHARGE_SAFETY_TIMER_CFG_REG rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, CHGR_CFG2_REG, RECHG_MASK, 0);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure VBAT-rechg CHG_CFG2_REG rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, CHGR_CFG2_REG, RECHG_MASK,
+				SOC_BASED_RECHG_BIT);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure SOC-rechg CHG_CFG2_REG rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/* program the auto-recharge threshold */
+	pval.intval = 99;
+	rc = smblib_set_prop_rechg_soc_thresh(chg, &pval);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure CHG_RCHG_SOC_REG rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	/* Program the sample count for SOC based recharge to 1 */
+	rc = smblib_masked_write(chg, CHGR_NO_SAMPLE_TERM_RCHG_CFG_REG,
+					NO_OF_SAMPLE_FOR_RCHG, 0);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure CHGR_NO_SAMPLE_FOR_TERM_RCHG_CFG rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = smblib_disable_hw_jeita(chg, true);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't set hw jeita rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, DCDC_ENG_SDCDC_CFG5_REG,
+			ENG_SDCDC_BAT_HPWR_MASK, BOOST_MODE_THRESH_3P6_V);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure DCDC_ENG_SDCDC_CFG5 rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	/*
+	 * 1. set 0x154a bit2 to 1 to fix huawei scp cable 3A for SDP issue
+	 * 2. set 0x154a bit3 to 0 to enable AICL for debug access mode cable
+	 * 3. set 0x154a bit0 to 1 to enable debug access mode detect
+	 * 4. set 0x154a bit4 to 0 to disable typec FMB mode
+	 */
+	rc = smblib_masked_write(chg, TYPE_C_DEBUG_ACC_SNK_CFG, 0x1F, 0x07);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure TYPE_C_DEBUG_ACC_SNK_CFG rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+ /****************************
+ * DETERMINE INITIAL STATUS *
+ ****************************/
+
+static int smb5_determine_initial_status(struct smb5 *chip)
+{
+	struct smb_irq_data irq_data = {chip, "determine-initial-status"};
+	struct smb_charger *chg = &chip->chg;
+	union power_supply_propval val;
+	int rc;
+
+	rc = smblib_get_prop_usb_present(chg, &val);
+	if (rc < 0) {
+		pr_err("Couldn't get usb present rc=%d\n", rc);
+		return rc;
+	}
+
+	usb_plugin_irq_handler(0, &irq_data);
+	chg_state_change_irq_handler(0, &irq_data);
+
+	return 0;
+}
+
+
+/**************************
+ * INTERRUPT REGISTRATION *
+ **************************/
+
+static struct smb_irq_info smb5_irqs[] = {
+	/* CHARGER IRQs */
+	[CHGR_ERROR_IRQ] = {
+		.name		= "chgr-error",
+		.handler	= default_irq_handler,
+	},
+	[CHG_STATE_CHANGE_IRQ] = {
+		.name		= "chg-state-change",
+		.handler	= chg_state_change_irq_handler,
+		.wake		= true,
+	},
+	[STEP_CHG_STATE_CHANGE_IRQ] = {
+		.name		= "step-chg-state-change",
+	},
+	[STEP_CHG_SOC_UPDATE_FAIL_IRQ] = {
+		.name		= "step-chg-soc-update-fail",
+	},
+	[STEP_CHG_SOC_UPDATE_REQ_IRQ] = {
+		.name		= "step-chg-soc-update-req",
+	},
+	[FG_FVCAL_QUALIFIED_IRQ] = {
+		.name		= "fg-fvcal-qualified",
+	},
+	[VPH_ALARM_IRQ] = {
+		.name		= "vph-alarm",
+	},
+	[VPH_DROP_PRECHG_IRQ] = {
+		.name		= "vph-drop-prechg",
+	},
+	/* DCDC IRQs */
+	[OTG_FAIL_IRQ] = {
+		.name		= "otg-fail",
+		.handler	= default_irq_handler,
+	},
+	[OTG_OC_DISABLE_SW_IRQ] = {
+		.name		= "otg-oc-disable-sw",
+	},
+	[OTG_OC_HICCUP_IRQ] = {
+		.name		= "otg-oc-hiccup",
+	},
+	[BSM_ACTIVE_IRQ] = {
+		.name		= "bsm-active",
+	},
+	[HIGH_DUTY_CYCLE_IRQ] = {
+		.name		= "high-duty-cycle",
+		.handler	= default_irq_handler,
+		.wake		= true,
+	},
+	[INPUT_CURRENT_LIMITING_IRQ] = {
+		.name		= "input-current-limiting",
+		.handler	= default_irq_handler,
+	},
+	[CONCURRENT_MODE_DISABLE_IRQ] = {
+		.name		= "concurrent-mode-disable",
+	},
+	[SWITCHER_POWER_OK_IRQ] = {
+		.name		= "switcher-power-ok",
+		.handler	= default_irq_handler,
+	},
+	/* BATTERY IRQs */
+	[BAT_TEMP_IRQ] = {
+		.name		= "bat-temp",
+		.handler	= default_irq_handler,
+	},
+	[ALL_CHNL_CONV_DONE_IRQ] = {
+		.name		= "all-chnl-conv-done",
+	},
+	[BAT_OV_IRQ] = {
+		.name		= "bat-ov",
+		.handler	= default_irq_handler,
+	},
+	[BAT_LOW_IRQ] = {
+		.name		= "bat-low",
+		.handler	= default_irq_handler,
+	},
+	[BAT_THERM_OR_ID_MISSING_IRQ] = {
+		.name		= "bat-therm-or-id-missing",
+		.handler	= default_irq_handler,
+	},
+	[BAT_TERMINAL_MISSING_IRQ] = {
+		.name		= "bat-terminal-missing",
+		.handler	= default_irq_handler,
+	},
+	[BUCK_OC_IRQ] = {
+		.name		= "buck-oc",
+	},
+	[VPH_OV_IRQ] = {
+		.name		= "vph-ov",
+	},
+	/* USB INPUT IRQs */
+	[USBIN_COLLAPSE_IRQ] = {
+		.name		= "usbin-collapse",
+		.handler	= default_irq_handler,
+	},
+	[USBIN_VASHDN_IRQ] = {
+		.name		= "usbin-vashdn",
+		.handler	= default_irq_handler,
+	},
+	[USBIN_UV_IRQ] = {
+		.name		= "usbin-uv",
+		.handler	= default_irq_handler,
+		.wake		= true,
+	},
+	[USBIN_OV_IRQ] = {
+		.name		= "usbin-ov",
+		.handler	= default_irq_handler,
+	},
+	[USBIN_PLUGIN_IRQ] = {
+		.name		= "usbin-plugin",
+		.handler	= usb_plugin_irq_handler,
+		.wake           = true,
+	},
+	[USBIN_REVI_CHANGE_IRQ] = {
+		.name		= "usbin-revi-change",
+	},
+	[USBIN_SRC_CHANGE_IRQ] = {
+		.name		= "usbin-src-change",
+		.handler	= default_irq_handler,
+		.wake           = true,
+	},
+	[USBIN_ICL_CHANGE_IRQ] = {
+		.name		= "usbin-icl-change",
+		.handler	= default_irq_handler,
+		.wake           = true,
+	},
+	/* DC INPUT IRQs */
+	[DCIN_VASHDN_IRQ] = {
+		.name		= "dcin-vashdn",
+	},
+	[DCIN_UV_IRQ] = {
+		.name		= "dcin-uv",
+		.handler	= default_irq_handler,
+		.wake           = true,
+	},
+	[DCIN_OV_IRQ] = {
+		.name		= "dcin-ov",
+		.handler	= default_irq_handler,
+	},
+	[DCIN_PLUGIN_IRQ] = {
+		.name		= "dcin-plugin",
+		.handler	= dc_plugin_irq_handler,
+		.wake           = true,
+	},
+	[DCIN_REVI_IRQ] = {
+		.name		= "dcin-revi",
+	},
+	[DCIN_PON_IRQ] = {
+		.name		= "dcin-pon",
+		.handler	= default_irq_handler,
+	},
+	[DCIN_EN_IRQ] = {
+		.name		= "dcin-en",
+		.handler	= default_irq_handler,
+	},
+	/* TYPEC IRQs */
+	[TYPEC_OR_RID_DETECTION_CHANGE_IRQ] = {
+		.name		= "typec-or-rid-detect-change",
+		.handler	= default_irq_handler,
+	},
+	[TYPEC_VPD_DETECT_IRQ] = {
+		.name		= "typec-vpd-detect",
+	},
+	[TYPEC_CC_STATE_CHANGE_IRQ] = {
+		.name		= "typec-cc-state-change",
+		.handler	= default_irq_handler,
+		.wake           = true,
+	},
+	[TYPEC_VCONN_OC_IRQ] = {
+		.name		= "typec-vconn-oc",
+		.handler	= default_irq_handler,
+	},
+	[TYPEC_VBUS_CHANGE_IRQ] = {
+		.name		= "typec-vbus-change",
+	},
+	[TYPEC_ATTACH_DETACH_IRQ] = {
+		.name		= "typec-attach-detach",
+		.handler	= default_irq_handler,
+		.wake		= true,
+	},
+	[TYPEC_LEGACY_CABLE_DETECT_IRQ] = {
+		.name		= "typec-legacy-cable-detect",
+		.handler	= default_irq_handler,
+	},
+	[TYPEC_TRY_SNK_SRC_DETECT_IRQ] = {
+		.name		= "typec-try-snk-src-detect",
+	},
+	/* MISCELLANEOUS IRQs */
+	[WDOG_SNARL_IRQ] = {
+		.name		= "wdog-snarl",
+		.handler	= default_irq_handler,
+		.wake		= false,
+	},
+	[WDOG_BARK_IRQ] = {
+		.name		= "wdog-bark",
+		.handler	= default_irq_handler,
+		.wake		= true,
+	},
+	[AICL_FAIL_IRQ] = {
+		.name		= "aicl-fail",
+	},
+	[AICL_DONE_IRQ] = {
+		.name		= "aicl-done",
+		.handler	= default_irq_handler,
+	},
+	[SMB_EN_IRQ] = {
+		.name		= "smb-en",
+		.handler	= default_irq_handler,
+	},
+	[IMP_TRIGGER_IRQ] = {
+		.name		= "imp-trigger",
+	},
+	/*
+	 * triggered when DIE or SKIN or CONNECTOR temperature across
+	 * either of the _REG_L, _REG_H, _RST, or _SHDN thresholds
+	 */
+	[TEMP_CHANGE_IRQ] = {
+		.name		= "temp-change",
+		.handler	= default_irq_handler,
+		.wake		= true,
+	},
+	[TEMP_CHANGE_SMB_IRQ] = {
+		.name		= "temp-change-smb",
+	},
+	/* FLASH */
+	[VREG_OK_IRQ] = {
+		.name		= "vreg-ok",
+	},
+	[ILIM_S2_IRQ] = {
+		.name		= "ilim2-s2",
+		.handler	= default_irq_handler,
+	},
+	[ILIM_S1_IRQ] = {
+		.name		= "ilim1-s1",
+	},
+	[VOUT_DOWN_IRQ] = {
+		.name		= "vout-down",
+	},
+	[VOUT_UP_IRQ] = {
+		.name		= "vout-up",
+	},
+	[FLASH_STATE_CHANGE_IRQ] = {
+		.name		= "flash-state-change",
+		.handler	= default_irq_handler,
+	},
+	[TORCH_REQ_IRQ] = {
+		.name		= "torch-req",
+	},
+	[FLASH_EN_IRQ] = {
+		.name		= "flash-en",
+	},
+	/* SDAM */
+	[SDAM_STS_IRQ] = {
+		.name		= "sdam-sts",
+		.handler	= default_irq_handler,
+	},
+};
+
+static int smb5_get_irq_index_byname(const char *irq_name)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(smb5_irqs); i++) {
+		if (strcmp(smb5_irqs[i].name, irq_name) == 0)
+			return i;
+	}
+
+	return -ENOENT;
+}
+
+static int smb5_request_interrupt(struct smb5 *chip,
+				struct device_node *node, const char *irq_name)
+{
+	struct smb_charger *chg = &chip->chg;
+	int rc, irq, irq_index;
+	struct smb_irq_data *irq_data;
+
+	irq = of_irq_get_byname(node, irq_name);
+	if (irq < 0) {
+		pr_err("Couldn't get irq %s byname\n", irq_name);
+		return irq;
+	}
+
+	irq_index = smb5_get_irq_index_byname(irq_name);
+	if (irq_index < 0) {
+		pr_err("%s is not a defined irq\n", irq_name);
+		return irq_index;
+	}
+
+	if (!smb5_irqs[irq_index].handler)
+		return 0;
+
+	irq_data = devm_kzalloc(chg->dev, sizeof(*irq_data), GFP_KERNEL);
+	if (!irq_data)
+		return -ENOMEM;
+
+	irq_data->parent_data = chip;
+	irq_data->name = irq_name;
+
+	smb5_irqs[irq_index].enabled = true;
+	rc = devm_request_threaded_irq(chg->dev, irq, NULL,
+					smb5_irqs[irq_index].handler,
+					IRQF_ONESHOT, irq_name, irq_data);
+	if (rc < 0) {
+		pr_err("Couldn't request irq %d\n", irq);
+		return rc;
+	}
+
+	smb5_irqs[irq_index].irq = irq;
+	smb5_irqs[irq_index].irq_data = irq_data;
+	if (smb5_irqs[irq_index].wake)
+		enable_irq_wake(irq);
+
+	return rc;
+}
+
+static int smb5_request_interrupts(struct smb5 *chip)
+{
+	struct smb_charger *chg = &chip->chg;
+	struct device_node *node = chg->dev->of_node;
+	int rc = 0;
+	const char *name;
+	struct property *prop;
+
+	of_property_for_each_string(node, "interrupt-names",
+				    prop, name) {
+		rc = smb5_request_interrupt(chip, node, name);
+		if (rc < 0)
+			return rc;
+	}
+
+	return rc;
+}
+
+static void smb5_free_interrupts(struct smb_charger *chg)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(smb5_irqs); i++) {
+		if (smb5_irqs[i].irq > 0) {
+			if (smb5_irqs[i].wake)
+				disable_irq_wake(smb5_irqs[i].irq);
+
+			devm_free_irq(chg->dev, smb5_irqs[i].irq,
+						smb5_irqs[i].irq_data);
+		}
+	}
+}
+
+static void smb5_disable_interrupts(struct smb_charger *chg)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(smb5_irqs); i++) {
+		if (smb5_irqs[i].irq > 0)
+			disable_irq(smb5_irqs[i].irq);
+	}
+}
+
+static int smb5_show_charger_status(struct smb5 *chip)
+{
+	struct smb_charger *chg = &chip->chg;
+	union power_supply_propval val;
+	int usb_present, batt_present, batt_health, batt_charge_type;
+	int rc;
+
+	rc = smblib_get_prop_usb_present(chg, &val);
+	if (rc < 0) {
+		pr_err("Couldn't get usb present rc=%d\n", rc);
+		return rc;
+	}
+	usb_present = val.intval;
+
+	rc = smblib_get_prop_batt_present(chg, &val);
+	if (rc < 0) {
+		pr_err("Couldn't get batt present rc=%d\n", rc);
+		return rc;
+	}
+	batt_present = val.intval;
+
+	rc = smblib_get_prop_batt_health(chg, &val);
+	if (rc < 0) {
+		pr_err("Couldn't get batt health rc=%d\n", rc);
+		val.intval = POWER_SUPPLY_HEALTH_UNKNOWN;
+	}
+	batt_health = val.intval;
+
+	rc = smblib_get_prop_batt_charge_type(chg, &val);
+	if (rc < 0) {
+		pr_err("Couldn't get batt charge type rc=%d\n", rc);
+		return rc;
+	}
+	batt_charge_type = val.intval;
+
+	pr_info("SMB5 status - usb:present=%d batt:present = %d health = %d charge = %d\n",
+		usb_present, batt_present, batt_health, batt_charge_type);
+	return rc;
+}
+
+static int smb5_probe(struct platform_device *pdev)
+{
+	struct smb5 *chip;
+	struct smb_charger *chg;
+	int rc = 0;
+
+	chip = devm_kzalloc(&pdev->dev, sizeof(*chip), GFP_KERNEL);
+	if (!chip)
+		return -ENOMEM;
+
+	chg = &chip->chg;
+	chg->dev = &pdev->dev;
+	chg->name = "pm8150b_charger";
+	chg->param = smb5_pm8150b_params;
+	chg->debug_mask = &__debug_mask;
+	chg->irq_info = smb5_irqs;
+
+	chg->regmap = dev_get_regmap(chg->dev->parent, NULL);
+	if (!chg->regmap) {
+		pr_err("parent regmap is missing\n");
+		return -EINVAL;
+	}
+
+	rc = smb5_parse_dt(chip);
+	if (rc < 0) {
+		pr_err("Couldn't parse device tree rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_init(chg);
+	if (rc < 0) {
+		pr_err("Smblib_init failed rc=%d\n", rc);
+		return rc;
+	}
+
+	/* set driver data before resources request it */
+	platform_set_drvdata(pdev, chip);
+
+	rc = smb5_init_hw(chip);
+	if (rc < 0) {
+		pr_err("Couldn't initialize hardware rc=%d\n", rc);
+		goto cleanup;
+	}
+
+	rc = smb5_init_dc_psy(chip);
+	if (rc < 0) {
+		pr_err("Couldn't initialize dc psy rc=%d\n", rc);
+		goto cleanup;
+	}
+#if 0
+	rc = smb5_init_batt_psy(chip);
+	if (rc < 0) {
+		pr_err("Couldn't initialize batt psy rc=%d\n", rc);
+		goto cleanup;
+	}
+#endif
+	rc = smb5_determine_initial_status(chip);
+	if (rc < 0) {
+		pr_err("Couldn't determine initial status rc=%d\n",
+			rc);
+		goto cleanup;
+	}
+
+	rc = smb5_request_interrupts(chip);
+	if (rc < 0) {
+		pr_err("Couldn't request interrupts rc=%d\n", rc);
+		goto cleanup;
+	}
+
+	rc = smb5_show_charger_status(chip);
+	if (rc < 0) {
+		pr_err("Failed in getting charger status rc=%d\n", rc);
+		goto free_irq;
+	}
+
+	return 0;
+
+free_irq:
+	smb5_free_interrupts(chg);
+cleanup:
+	smblib_deinit(chg);
+	platform_set_drvdata(pdev, NULL);
+
+	return rc;
+}
+
+static int smb5_remove(struct platform_device *pdev)
+{
+	struct smb5 *chip = platform_get_drvdata(pdev);
+	struct smb_charger *chg = &chip->chg;
+
+	/* force enable APSD */
+	smblib_masked_write(chg, USBIN_OPTIONS_1_CFG_REG,
+				BC1P2_SRC_DETECT_BIT, BC1P2_SRC_DETECT_BIT);
+
+	smb5_free_interrupts(chg);
+	smblib_deinit(chg);
+	platform_set_drvdata(pdev, NULL);
+
+	return 0;
+}
+
+static void smb5_shutdown(struct platform_device *pdev)
+{
+	struct smb5 *chip = platform_get_drvdata(pdev);
+	struct smb_charger *chg = &chip->chg;
+
+	/* disable all interrupts */
+	smb5_disable_interrupts(chg);
+
+	/* configure power role for UFP */
+	smblib_masked_write(chg, TYPE_C_MODE_CFG_REG,
+			TYPEC_POWER_ROLE_CMD_MASK, EN_SNK_ONLY_BIT);
+
+	/*fix PD bug.Set 0x1360 = 0x0c when shutdown*/
+	smblib_write(chg, USBIN_ADAPTER_ALLOW_CFG_REG, USBIN_ADAPTER_ALLOW_5V_TO_12V);
+}
+
+static const struct of_device_id match_table[] = {
+	{ .compatible = "qcom,pm8150b-charger", },
+	{ },
+};
+
+static struct platform_driver smb5_charger_driver = {
+	.driver		= {
+		.name		= "qcom,pm8150b-charger",
+		.owner		= THIS_MODULE,
+		.of_match_table	= match_table,
+	},
+	.probe		= smb5_probe,
+	.remove		= smb5_remove,
+	.shutdown	= smb5_shutdown,
+};
+module_platform_driver(smb5_charger_driver);
diff --git a/drivers/power/supply/qcom/pmic-voter.c b/drivers/power/supply/qcom/pmic-voter.c
new file mode 100644
index 000000000..7c0fce506
--- /dev/null
+++ b/drivers/power/supply/qcom/pmic-voter.c
@@ -0,0 +1,844 @@
+/* Copyright (c) 2015-2017, 2019 The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/debugfs.h>
+#include <linux/spinlock.h>
+#include <linux/errno.h>
+#include <linux/bitops.h>
+#include <linux/printk.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+
+#include "pmic-voter.h"
+
+#define NUM_MAX_CLIENTS		32
+#define DEBUG_FORCE_CLIENT	"DEBUG_FORCE_CLIENT"
+
+static DEFINE_SPINLOCK(votable_list_slock);
+static LIST_HEAD(votable_list);
+
+static struct dentry *debug_root;
+
+struct client_vote {
+	bool	enabled;
+	int	value;
+};
+
+struct votable {
+	const char		*name;
+	const char		*override_client;
+	struct list_head	list;
+	struct client_vote	votes[NUM_MAX_CLIENTS];
+	int			num_clients;
+	int			type;
+	int			effective_client_id;
+	int			effective_result;
+	int			override_result;
+	struct mutex		vote_lock;
+	void			*data;
+	int			(*callback)(struct votable *votable,
+						void *data,
+						int effective_result,
+						const char *effective_client);
+	char			*client_strs[NUM_MAX_CLIENTS];
+	bool			voted_on;
+	struct dentry		*root;
+	struct dentry		*status_ent;
+	u32			force_val;
+	bool			force_active;
+	struct dentry		*force_active_ent;
+};
+
+/**
+ * vote_set_any()
+ * @votable:	votable object
+ * @client_id:	client number of the latest voter
+ * @eff_res:	sets 0 or 1 based on the voting
+ * @eff_id:	Always returns the client_id argument
+ *
+ * Note that for SET_ANY voter, the value is always same as enabled. There is
+ * no idea of a voter abstaining from the election. Hence there is never a
+ * situation when the effective_id will be invalid, during election.
+ *
+ * Context:
+ *	Must be called with the votable->lock held
+ */
+static void vote_set_any(struct votable *votable, int client_id,
+				int *eff_res, int *eff_id)
+{
+	int i;
+
+	*eff_res = 0;
+
+	for (i = 0; i < votable->num_clients && votable->client_strs[i]; i++)
+		*eff_res |= votable->votes[i].enabled;
+
+	*eff_id = client_id;
+}
+
+/**
+ * vote_min() -
+ * @votable:	votable object
+ * @client_id:	client number of the latest voter
+ * @eff_res:	sets this to the min. of all the values amongst enabled voters.
+ *		If there is no enabled client, this is set to INT_MAX
+ * @eff_id:	sets this to the client id that has the min value amongst all
+ *		the enabled clients. If there is no enabled client, sets this
+ *		to -EINVAL
+ *
+ * Context:
+ *	Must be called with the votable->lock held
+ */
+static void vote_min(struct votable *votable, int client_id,
+				int *eff_res, int *eff_id)
+{
+	int i;
+
+	*eff_res = INT_MAX;
+	*eff_id = -EINVAL;
+	for (i = 0; i < votable->num_clients && votable->client_strs[i]; i++) {
+		if (votable->votes[i].enabled
+			&& *eff_res > votable->votes[i].value) {
+			*eff_res = votable->votes[i].value;
+			*eff_id = i;
+		}
+	}
+	if (*eff_id == -EINVAL)
+		*eff_res = -EINVAL;
+}
+
+/**
+ * vote_max() -
+ * @votable:	votable object
+ * @client_id:	client number of the latest voter
+ * @eff_res:	sets this to the max. of all the values amongst enabled voters.
+ *		If there is no enabled client, this is set to -EINVAL
+ * @eff_id:	sets this to the client id that has the max value amongst all
+ *		the enabled clients. If there is no enabled client, sets this to
+ *		-EINVAL
+ *
+ * Context:
+ *	Must be called with the votable->lock held
+ */
+static void vote_max(struct votable *votable, int client_id,
+				int *eff_res, int *eff_id)
+{
+	int i;
+
+	*eff_res = INT_MIN;
+	*eff_id = -EINVAL;
+	for (i = 0; i < votable->num_clients && votable->client_strs[i]; i++) {
+		if (votable->votes[i].enabled &&
+				*eff_res < votable->votes[i].value) {
+			*eff_res = votable->votes[i].value;
+			*eff_id = i;
+		}
+	}
+	if (*eff_id == -EINVAL)
+		*eff_res = -EINVAL;
+}
+
+static int get_client_id(struct votable *votable, const char *client_str)
+{
+	int i;
+
+	for (i = 0; i < votable->num_clients; i++) {
+		if (votable->client_strs[i]
+		 && (strcmp(votable->client_strs[i], client_str) == 0))
+			return i;
+	}
+
+	/* new client */
+	for (i = 0; i < votable->num_clients; i++) {
+		if (!votable->client_strs[i]) {
+			votable->client_strs[i]
+				= kstrdup(client_str, GFP_KERNEL);
+			if (!votable->client_strs[i])
+				return -ENOMEM;
+			return i;
+		}
+	}
+	return -EINVAL;
+}
+
+static char *get_client_str(struct votable *votable, int client_id)
+{
+	if (!votable || (client_id == -EINVAL))
+		return NULL;
+
+	return votable->client_strs[client_id];
+}
+
+void lock_votable(struct votable *votable)
+{
+	mutex_lock(&votable->vote_lock);
+}
+
+void unlock_votable(struct votable *votable)
+{
+	mutex_unlock(&votable->vote_lock);
+}
+
+/**
+ * is_override_vote_enabled() -
+ * is_override_vote_enabled_locked() -
+ *		The unlocked and locked variants of getting whether override
+		vote is enabled.
+ * @votable:	the votable object
+ *
+ * Returns:
+ *	True if the client's vote is enabled; false otherwise.
+ */
+bool is_override_vote_enabled_locked(struct votable *votable)
+{
+	if (!votable)
+		return false;
+
+	return votable->override_result != -EINVAL;
+}
+
+bool is_override_vote_enabled(struct votable *votable)
+{
+	bool enable;
+
+	if (!votable)
+		return false;
+
+	lock_votable(votable);
+	enable = is_override_vote_enabled_locked(votable);
+	unlock_votable(votable);
+
+	return enable;
+}
+
+/**
+ * is_client_vote_enabled() -
+ * is_client_vote_enabled_locked() -
+ *		The unlocked and locked variants of getting whether a client's
+		vote is enabled.
+ * @votable:	the votable object
+ * @client_str: client of interest
+ *
+ * Returns:
+ *	True if the client's vote is enabled; false otherwise.
+ */
+bool is_client_vote_enabled_locked(struct votable *votable,
+							const char *client_str)
+{
+
+	int client_id;
+
+	if (!votable || !client_str)
+		return false;
+
+	client_id = get_client_id(votable, client_str);
+	if (client_id < 0)
+		return false;
+
+	return votable->votes[client_id].enabled;
+}
+
+bool is_client_vote_enabled(struct votable *votable, const char *client_str)
+{
+	bool enabled;
+
+	if (!votable || !client_str)
+		return false;
+
+	lock_votable(votable);
+	enabled = is_client_vote_enabled_locked(votable, client_str);
+	unlock_votable(votable);
+	return enabled;
+}
+
+/**
+ * get_client_vote() -
+ * get_client_vote_locked() -
+ *		The unlocked and locked variants of getting a client's voted
+ *		value.
+ * @votable:	the votable object
+ * @client_str: client of interest
+ *
+ * Returns:
+ *	The value the client voted for. -EINVAL is returned if the client
+ *	is not enabled or the client is not found.
+ */
+int get_client_vote_locked(struct votable *votable, const char *client_str)
+{
+	int client_id;
+
+	if (!votable || !client_str)
+		return -EINVAL;
+
+	client_id = get_client_id(votable, client_str);
+	if (client_id < 0)
+		return -EINVAL;
+
+	if ((votable->type != VOTE_SET_ANY)
+		&& !votable->votes[client_id].enabled)
+		return -EINVAL;
+
+	return votable->votes[client_id].value;
+}
+
+int get_client_vote(struct votable *votable, const char *client_str)
+{
+	int value;
+
+	if (!votable || !client_str)
+		return -EINVAL;
+
+	lock_votable(votable);
+	value = get_client_vote_locked(votable, client_str);
+	unlock_votable(votable);
+	return value;
+}
+
+/**
+ * get_effective_result() -
+ * get_effective_result_locked() -
+ *		The unlocked and locked variants of getting the effective value
+ *		amongst all the enabled voters.
+ *
+ * @votable:	the votable object
+ *
+ * Returns:
+ *	The effective result.
+ *	For MIN and MAX votable, returns -EINVAL when the votable
+ *	object has been created but no clients have casted their votes or
+ *	the last enabled client disables its vote.
+ *	For SET_ANY votable it returns 0 when no clients have casted their votes
+ *	because for SET_ANY there is no concept of abstaining from election. The
+ *	votes for all the clients of SET_ANY votable is defaulted to false.
+ */
+int get_effective_result_locked(struct votable *votable)
+{
+	if (!votable)
+		return -EINVAL;
+
+	if (votable->force_active)
+		return votable->force_val;
+
+	if (votable->override_result != -EINVAL)
+		return votable->override_result;
+
+	return votable->effective_result;
+}
+
+int get_effective_result(struct votable *votable)
+{
+	int value;
+
+	if (!votable)
+		return -EINVAL;
+
+	lock_votable(votable);
+	value = get_effective_result_locked(votable);
+	unlock_votable(votable);
+	return value;
+}
+
+/**
+ * get_effective_client() -
+ * get_effective_client_locked() -
+ *		The unlocked and locked variants of getting the effective client
+ *		amongst all the enabled voters.
+ *
+ * @votable:	the votable object
+ *
+ * Returns:
+ *	The effective client.
+ *	For MIN and MAX votable, returns NULL when the votable
+ *	object has been created but no clients have casted their votes or
+ *	the last enabled client disables its vote.
+ *	For SET_ANY votable it returns NULL too when no clients have casted
+ *	their votes. But for SET_ANY since there is no concept of abstaining
+ *	from election, the only client that casts a vote or the client that
+ *	caused the result to change is returned.
+ */
+const char *get_effective_client_locked(struct votable *votable)
+{
+	if (!votable)
+		return NULL;
+
+	if (votable->force_active)
+		return DEBUG_FORCE_CLIENT;
+
+	if (votable->override_result != -EINVAL)
+		return votable->override_client;
+
+	return get_client_str(votable, votable->effective_client_id);
+}
+
+const char *get_effective_client(struct votable *votable)
+{
+	const char *client_str;
+
+	if (!votable)
+		return NULL;
+
+	lock_votable(votable);
+	client_str = get_effective_client_locked(votable);
+	unlock_votable(votable);
+	return client_str;
+}
+
+/**
+ * vote() -
+ *
+ * @votable:	the votable object
+ * @client_str: the voting client
+ * @enabled:	This provides a means for the client to exclude himself from
+ *		election. This clients val (the next argument) will be
+ *		considered only when he has enabled his participation.
+ *		Note that this takes a differnt meaning for SET_ANY type, as
+ *		there is no concept of abstaining from participation.
+ *		Enabled is treated as the boolean value the client is voting.
+ * @val:	The vote value. This is ignored for SET_ANY votable types.
+ *		For MIN, MAX votable types this value is used as the
+ *		clients vote value when the enabled is true, this value is
+ *		ignored if enabled is false.
+ *
+ * The callback is called only when there is a change in the election results or
+ * if it is the first time someone is voting.
+ *
+ * Returns:
+ *	The return from the callback when present and needs to be called
+ *	or zero.
+ */
+int vote(struct votable *votable, const char *client_str, bool enabled, int val)
+{
+	int effective_id = -EINVAL;
+	int effective_result;
+	int client_id;
+	int rc = 0;
+	bool similar_vote = false;
+
+	if (!votable || !client_str)
+		return -EINVAL;
+
+	lock_votable(votable);
+
+	client_id = get_client_id(votable, client_str);
+	if (client_id < 0) {
+		rc = client_id;
+		goto out;
+	}
+
+	/*
+	 * for SET_ANY the val is to be ignored, set it
+	 * to enabled so that the election still works based on
+	 * value regardless of the type
+	 */
+	if (votable->type == VOTE_SET_ANY)
+		val = enabled;
+
+	if ((votable->votes[client_id].enabled == enabled) &&
+		(votable->votes[client_id].value == val)) {
+		pr_debug("%s: %s,%d same vote %s of val=%d\n",
+				votable->name,
+				client_str, client_id,
+				enabled ? "on" : "off",
+				val);
+		similar_vote = true;
+	}
+
+	votable->votes[client_id].enabled = enabled;
+	votable->votes[client_id].value = val;
+
+	if (similar_vote && votable->voted_on) {
+		pr_debug("%s: %s,%d Ignoring similar vote %s of val=%d\n",
+			votable->name,
+			client_str, client_id, enabled ? "on" : "off", val);
+		goto out;
+	}
+
+	pr_debug("%s: %s,%d voting %s of val=%d\n",
+		votable->name,
+		client_str, client_id, enabled ? "on" : "off", val);
+	switch (votable->type) {
+	case VOTE_MIN:
+		vote_min(votable, client_id, &effective_result, &effective_id);
+		break;
+	case VOTE_MAX:
+		vote_max(votable, client_id, &effective_result, &effective_id);
+		break;
+	case VOTE_SET_ANY:
+		vote_set_any(votable, client_id,
+				&effective_result, &effective_id);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/*
+	 * Note that the callback is called with a NULL string and -EINVAL
+	 * result when there are no enabled votes
+	 */
+	if (!votable->voted_on
+			|| (effective_result != votable->effective_result)) {
+		if (strcmp(votable->name, "FG_WS") != 0) {
+			if (votable->override_result == -EINVAL) {
+				pr_info("%s: current vote is now %d voted by %s,%d, previous voted %d\n",
+						votable->name, effective_result,
+						get_client_str(votable, effective_id),
+						effective_id, votable->effective_result);
+			} else {
+				pr_info("%s: current override_result %d, %s set %d is miss\n",
+						votable->name, votable->override_result,
+						client_str, val);
+			}
+		}
+		votable->effective_client_id = effective_id;
+		votable->effective_result = effective_result;
+		if (votable->callback && !votable->force_active
+				&& (votable->override_result == -EINVAL))
+			rc = votable->callback(votable, votable->data,
+					effective_result,
+					get_client_str(votable, effective_id));
+	}
+
+	votable->voted_on = true;
+out:
+	unlock_votable(votable);
+	return rc;
+}
+
+/**
+ * vote_override() -
+ *
+ * @votable:		The votable object
+ * @override_client:	The voting client that will override other client's
+ *			votes, that are already present. When force_active
+ *			and override votes are set on a votable, force_active's
+ *			client will have the higher priority and it's vote will
+ *			be the effective one.
+ * @enabled:		This provides a means for the override client to exclude
+ *			itself from election. This client's vote
+ *			(the next argument) will be considered only when
+ *			it has enabled its participation. When this is
+ *			set true, this will force a value on a MIN/MAX votable
+ *			irrespective of its current value.
+ * @val:		The vote value. This will be effective only if enabled
+ *			is set true.
+ * Returns:
+ *	The result of vote. 0 is returned if the vote
+ *	is successfully set by the overriding client, when enabled is set.
+ */
+int vote_override(struct votable *votable, const char *override_client,
+		  bool enabled, int val)
+{
+	int rc = 0;
+
+	if (!votable || !override_client)
+		return -EINVAL;
+
+	lock_votable(votable);
+
+	pr_info("%s:client %s,enabled:%d,val:%d\n",
+			votable->name, override_client,
+			enabled, val);
+
+	if (votable->force_active) {
+		votable->override_result = enabled ? val : -EINVAL;
+		goto out;
+	}
+
+	if (enabled) {
+		rc = votable->callback(votable, votable->data,
+					val, override_client);
+		if (!rc) {
+			votable->override_client = override_client;
+			votable->override_result = val;
+		}
+	} else {
+		rc = votable->callback(votable, votable->data,
+			votable->effective_result,
+			get_client_str(votable, votable->effective_client_id));
+		votable->override_result = -EINVAL;
+	}
+
+out:
+	unlock_votable(votable);
+	return rc;
+}
+
+int rerun_election(struct votable *votable)
+{
+	int rc = 0;
+	int effective_result;
+
+	if (!votable)
+		return -EINVAL;
+
+	lock_votable(votable);
+	effective_result = get_effective_result_locked(votable);
+	if (votable->callback)
+		rc = votable->callback(votable,
+			votable->data,
+			effective_result,
+			get_client_str(votable, votable->effective_client_id));
+	unlock_votable(votable);
+	return rc;
+}
+
+struct votable *find_votable(const char *name)
+{
+	unsigned long flags;
+	struct votable *v;
+	bool found = false;
+
+	if (!name)
+		return NULL;
+
+	spin_lock_irqsave(&votable_list_slock, flags);
+	if (list_empty(&votable_list))
+		goto out;
+
+	list_for_each_entry(v, &votable_list, list) {
+		if (strcmp(v->name, name) == 0) {
+			found = true;
+			break;
+		}
+	}
+out:
+	spin_unlock_irqrestore(&votable_list_slock, flags);
+
+	if (found)
+		return v;
+	else
+		return NULL;
+}
+
+static int force_active_get(void *data, u64 *val)
+{
+	struct votable *votable = data;
+
+	*val = votable->force_active;
+
+	return 0;
+}
+
+static int force_active_set(void *data, u64 val)
+{
+	struct votable *votable = data;
+	int rc = 0;
+	int effective_result;
+	const char *client;
+
+	lock_votable(votable);
+	votable->force_active = !!val;
+
+	if (!votable->callback)
+		goto out;
+
+	if (votable->force_active) {
+		rc = votable->callback(votable, votable->data,
+			votable->force_val,
+			DEBUG_FORCE_CLIENT);
+	} else {
+		if (votable->override_result != -EINVAL) {
+			effective_result = votable->override_result;
+			client = votable->override_client;
+		} else {
+			effective_result = votable->effective_result;
+			client = get_client_str(votable,
+					votable->effective_client_id);
+		}
+		rc = votable->callback(votable, votable->data, effective_result,
+					client);
+	}
+out:
+	unlock_votable(votable);
+	return rc;
+}
+DEFINE_SIMPLE_ATTRIBUTE(votable_force_ops, force_active_get, force_active_set,
+		"%lld\n");
+
+static int show_votable_clients(struct seq_file *m, void *data)
+{
+	struct votable *votable = m->private;
+	int i;
+	char *type_str = "Unkonwn";
+	const char *effective_client_str;
+
+	lock_votable(votable);
+
+	for (i = 0; i < votable->num_clients; i++) {
+		if (votable->client_strs[i]) {
+			seq_printf(m, "%s: %s:\t\t\ten=%d v=%d\n",
+					votable->name,
+					votable->client_strs[i],
+					votable->votes[i].enabled,
+					votable->votes[i].value);
+		}
+	}
+
+	switch (votable->type) {
+	case VOTE_MIN:
+		type_str = "Min";
+		break;
+	case VOTE_MAX:
+		type_str = "Max";
+		break;
+	case VOTE_SET_ANY:
+		type_str = "Set_any";
+		break;
+	}
+
+	effective_client_str = get_effective_client_locked(votable);
+	seq_printf(m, "%s: effective=%s type=%s v=%d\n",
+			votable->name,
+			effective_client_str ? effective_client_str : "none",
+			type_str,
+			get_effective_result_locked(votable));
+	unlock_votable(votable);
+
+	return 0;
+}
+
+static int votable_status_open(struct inode *inode, struct file *file)
+{
+	struct votable *votable = inode->i_private;
+
+	return single_open(file, show_votable_clients, votable);
+}
+
+static const struct file_operations votable_status_ops = {
+	.owner		= THIS_MODULE,
+	.open		= votable_status_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+struct votable *create_votable(const char *name,
+				int votable_type,
+				int (*callback)(struct votable *votable,
+					void *data,
+					int effective_result,
+					const char *effective_client),
+				void *data)
+{
+	struct votable *votable;
+	unsigned long flags;
+
+	if (!name)
+		return ERR_PTR(-EINVAL);
+
+	votable = find_votable(name);
+	if (votable)
+		return ERR_PTR(-EEXIST);
+
+	if (debug_root == NULL) {
+		debug_root = debugfs_create_dir("pmic-votable", NULL);
+		if (!debug_root) {
+			pr_err("Couldn't create debug dir\n");
+			return ERR_PTR(-ENOMEM);
+		}
+	}
+
+	if (votable_type >= NUM_VOTABLE_TYPES) {
+		pr_err("Invalid votable_type specified for voter\n");
+		return ERR_PTR(-EINVAL);
+	}
+
+	votable = kzalloc(sizeof(struct votable), GFP_KERNEL);
+	if (!votable)
+		return ERR_PTR(-ENOMEM);
+
+	votable->name = kstrdup(name, GFP_KERNEL);
+	if (!votable->name) {
+		kfree(votable);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	votable->num_clients = NUM_MAX_CLIENTS;
+	votable->callback = callback;
+	votable->type = votable_type;
+	votable->data = data;
+	votable->override_result = -EINVAL;
+	mutex_init(&votable->vote_lock);
+
+	/*
+	 * Because effective_result and client states are invalid
+	 * before the first vote, initialize them to -EINVAL
+	 */
+	votable->effective_result = -EINVAL;
+	if (votable->type == VOTE_SET_ANY)
+		votable->effective_result = 0;
+	votable->effective_client_id = -EINVAL;
+
+	spin_lock_irqsave(&votable_list_slock, flags);
+	list_add(&votable->list, &votable_list);
+	spin_unlock_irqrestore(&votable_list_slock, flags);
+
+	votable->root = debugfs_create_dir(name, debug_root);
+	if (!votable->root) {
+		pr_err("Couldn't create debug dir %s\n", name);
+		kfree(votable->name);
+		kfree(votable);
+		return ERR_PTR(-ENOMEM);
+	}
+
+	votable->status_ent = debugfs_create_file("status", S_IFREG | 0444,
+				  votable->root, votable,
+				  &votable_status_ops);
+	if (!votable->status_ent) {
+		pr_err("Couldn't create status dbg file for %s\n", name);
+		debugfs_remove_recursive(votable->root);
+		kfree(votable->name);
+		kfree(votable);
+		return ERR_PTR(-EEXIST);
+	}
+
+	debugfs_create_u32("force_val",
+					S_IFREG | 0644,
+					votable->root,
+					&(votable->force_val));
+
+	votable->force_active_ent = debugfs_create_file("force_active",
+					S_IFREG | 0444,
+					votable->root, votable,
+					&votable_force_ops);
+	if (!votable->force_active_ent) {
+		pr_err("Couldn't create force_active dbg file for %s\n", name);
+		debugfs_remove_recursive(votable->root);
+		kfree(votable->name);
+		kfree(votable);
+		return ERR_PTR(-EEXIST);
+	}
+
+	return votable;
+}
+
+void destroy_votable(struct votable *votable)
+{
+	unsigned long flags;
+	int i;
+
+	if (!votable)
+		return;
+
+	spin_lock_irqsave(&votable_list_slock, flags);
+	list_del(&votable->list);
+	spin_unlock_irqrestore(&votable_list_slock, flags);
+
+	debugfs_remove_recursive(votable->root);
+
+	for (i = 0; i < votable->num_clients && votable->client_strs[i]; i++)
+		kfree(votable->client_strs[i]);
+
+	kfree(votable->name);
+	kfree(votable);
+}
diff --git a/drivers/power/supply/qcom/pmic-voter.h b/drivers/power/supply/qcom/pmic-voter.h
new file mode 100644
index 000000000..255891d47
--- /dev/null
+++ b/drivers/power/supply/qcom/pmic-voter.h
@@ -0,0 +1,54 @@
+/* Copyright (c) 2015-2016,2019 The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __PMIC_VOTER_H
+#define __PMIC_VOTER_H
+
+#include <linux/mutex.h>
+
+struct votable;
+
+enum votable_type {
+	VOTE_MIN,
+	VOTE_MAX,
+	VOTE_SET_ANY,
+	NUM_VOTABLE_TYPES,
+};
+
+bool is_client_vote_enabled(struct votable *votable, const char *client_str);
+bool is_client_vote_enabled_locked(struct votable *votable,
+							const char *client_str);
+bool is_override_vote_enabled(struct votable *votable);
+bool is_override_vote_enabled_locked(struct votable *votable);
+int get_client_vote(struct votable *votable, const char *client_str);
+int get_client_vote_locked(struct votable *votable, const char *client_str);
+int get_effective_result(struct votable *votable);
+int get_effective_result_locked(struct votable *votable);
+const char *get_effective_client(struct votable *votable);
+const char *get_effective_client_locked(struct votable *votable);
+int vote(struct votable *votable, const char *client_str, bool state, int val);
+int vote_override(struct votable *votable, const char *override_client,
+		  bool state, int val);
+int rerun_election(struct votable *votable);
+struct votable *find_votable(const char *name);
+struct votable *create_votable(const char *name,
+				int votable_type,
+				int (*callback)(struct votable *votable,
+						void *data,
+						int effective_result,
+						const char *effective_client),
+				void *data);
+void destroy_votable(struct votable *votable);
+void lock_votable(struct votable *votable);
+void unlock_votable(struct votable *votable);
+
+#endif /* __PMIC_VOTER_H */
diff --git a/drivers/power/supply/qcom/qpnp-fg-gen4.c b/drivers/power/supply/qcom/qpnp-fg-gen4.c
new file mode 100644
index 000000000..e958c5cde
--- /dev/null
+++ b/drivers/power/supply/qcom/qpnp-fg-gen4.c
@@ -0,0 +1,5902 @@
+/* Copyright (c) 2018-2020, The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt)	"FG: %s: " fmt, __func__
+
+#include <linux/alarmtimer.h>
+#include <linux/irq.h>
+#include <linux/ktime.h>
+#include <linux/nvmem-consumer.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/qpnp-pbs.h>
+#include <linux/qpnp-revid.h>
+#include <linux/thermal.h>
+#include <linux/syscalls.h>
+#include "fg-core.h"
+#include "fg-reg.h"
+#include "fg-alg.h"
+
+#define FG_GEN4_DEV_NAME	"qcom,fg-gen4"
+#define TTF_AWAKE_VOTER		"fg_ttf_awake"
+
+#define PERPH_SUBTYPE_REG		0x05
+#define FG_BATT_SOC_PM8150B		0x10
+#define FG_BATT_INFO_PM8150B		0x11
+#define FG_MEM_IF_PM8150B		0x0D
+#define FG_ADC_RR_PM8150B		0x13
+
+#define SDAM_COOKIE_OFFSET		0x80
+#define SDAM_CYCLE_COUNT_OFFSET		0x81
+#define SDAM_CAP_LEARN_OFFSET		0x91
+#define SDAM_COOKIE			0xA5
+#define SDAM_FG_PARAM_LENGTH		20
+
+#define FG_SRAM_LEN			972
+#define PROFILE_LEN			416
+#define PROFILE_COMP_LEN		24
+#define KI_COEFF_SOC_LEVELS		3
+#define ESR_CAL_LEVELS			2
+#define KI_COEFF_MAX			15564
+#define SLOPE_LIMIT_NUM_COEFFS		4
+#define SLOPE_LIMIT_COEFF_MAX		31128
+#define BATT_THERM_NUM_COEFFS		5
+#define RSLOW_NUM_COEFFS		4
+
+/* SRAM address/offset definitions in ascending order */
+#define BATT_THERM_CONFIG_WORD		3
+#define RATIO_CENTER_OFFSET		1
+#define BATT_THERM_COEFF_WORD		4
+#define BATT_THERM_COEFF_OFFSET		0
+#define BATT_TEMP_CONFIG_WORD		9
+#define BATT_TEMP_HOT_OFFSET		0
+#define BATT_TEMP_COLD_OFFSET		1
+#define BATT_TEMP_CONFIG2_WORD		10
+#define BATT_TEMP_HYST_DELTA_OFFSET	0
+#define ESR_CAL_SOC_MIN_OFFSET		1
+#define ESR_CAL_THRESH_WORD		11
+#define ESR_CAL_SOC_MAX_OFFSET		0
+#define ESR_CAL_TEMP_MIN_OFFSET		1
+#define ESR_PULSE_THRESH_WORD		12
+#define ESR_CAL_TEMP_MAX_OFFSET		0
+#define ESR_PULSE_THRESH_OFFSET		1
+#define DELTA_ESR_THR_WORD		14
+#define DELTA_ESR_THR_OFFSET		0
+#define ESR_TIMER_DISCHG_MAX_WORD	17
+#define ESR_TIMER_DISCHG_MAX_OFFSET	0
+#define ESR_TIMER_DISCHG_INIT_WORD	17
+#define ESR_TIMER_DISCHG_INIT_OFFSET	1
+#define ESR_TIMER_CHG_MAX_WORD		18
+#define ESR_TIMER_CHG_MAX_OFFSET	0
+#define ESR_TIMER_CHG_INIT_WORD		18
+#define ESR_TIMER_CHG_INIT_OFFSET	1
+#define CUTOFF_CURR_WORD		19
+#define CUTOFF_CURR_OFFSET		0
+#define CUTOFF_VOLT_WORD		20
+#define CUTOFF_VOLT_OFFSET		0
+#define KI_COEFF_CUTOFF_WORD		21
+#define KI_COEFF_CUTOFF_OFFSET		0
+#define SYS_TERM_CURR_WORD		22
+#define SYS_TERM_CURR_OFFSET		0
+#define VBATT_FULL_WORD			23
+#define VBATT_FULL_OFFSET		0
+#define KI_COEFF_FULL_SOC_NORM_WORD	24
+#define KI_COEFF_FULL_SOC_NORM_OFFSET	1
+#define KI_COEFF_LOW_DISCHG_WORD	25
+#define KI_COEFF_FULL_SOC_LOW_OFFSET	0
+#define KI_COEFF_LOW_DISCHG_OFFSET	1
+#define KI_COEFF_MED_DISCHG_WORD	26
+#define KI_COEFF_MED_DISCHG_OFFSET	0
+#define KI_COEFF_HI_DISCHG_WORD		26
+#define KI_COEFF_HI_DISCHG_OFFSET	1
+#define KI_COEFF_LO_MED_DCHG_THR_WORD	27
+#define KI_COEFF_LO_MED_DCHG_THR_OFFSET	0
+#define KI_COEFF_MED_HI_DCHG_THR_WORD	27
+#define KI_COEFF_MED_HI_DCHG_THR_OFFSET	1
+#define KI_COEFF_LOW_CHG_WORD		28
+#define KI_COEFF_LOW_CHG_OFFSET		0
+#define KI_COEFF_MED_CHG_WORD		28
+#define KI_COEFF_MED_CHG_OFFSET		1
+#define KI_COEFF_HI_CHG_WORD		29
+#define KI_COEFF_HI_CHG_OFFSET		0
+#define KI_COEFF_LO_MED_CHG_THR_WORD	29
+#define KI_COEFF_LO_MED_CHG_THR_OFFSET	1
+#define KI_COEFF_MED_HI_CHG_THR_WORD	30
+#define KI_COEFF_MED_HI_CHG_THR_OFFSET	0
+#define DELTA_BSOC_THR_WORD		30
+#define DELTA_BSOC_THR_OFFSET		1
+#define SLOPE_LIMIT_WORD		32
+#define SLOPE_LIMIT_OFFSET		0
+#define DELTA_MSOC_THR_WORD		32
+#define DELTA_MSOC_THR_OFFSET		1
+#define VBATT_LOW_WORD			35
+#define VBATT_LOW_OFFSET		1
+#define SYS_CONFIG_WORD			60
+#define SYS_CONFIG_OFFSET		0
+#define SYS_CONFIG2_OFFSET		1
+#define PROFILE_LOAD_WORD		65
+#define PROFILE_LOAD_OFFSET		0
+#define RSLOW_COEFF_DISCHG_WORD		78
+#define RSLOW_COEFF_LOW_OFFSET		0
+#define RSLOW_CONFIG_WORD		241
+#define RSLOW_CONFIG_OFFSET		0
+#define NOM_CAP_WORD			271
+#define NOM_CAP_OFFSET			0
+#define RCONN_WORD			275
+#define RCONN_OFFSET			0
+#define ACT_BATT_CAP_WORD		285
+#define ACT_BATT_CAP_OFFSET		0
+#define BATT_AGE_LEVEL_WORD		288
+#define BATT_AGE_LEVEL_OFFSET		0
+#define CYCLE_COUNT_WORD		291
+#define CYCLE_COUNT_OFFSET		0
+#define PROFILE_INTEGRITY_WORD		299
+#define PROFILE_INTEGRITY_OFFSET	0
+#define IBAT_FINAL_WORD			320
+#define IBAT_FINAL_OFFSET		0
+#define VBAT_FINAL_WORD			321
+#define VBAT_FINAL_OFFSET		0
+#define BATT_TEMP_WORD			328
+#define BATT_TEMP_OFFSET		0
+#define ESR_WORD			331
+#define ESR_OFFSET			0
+#define ESR_MDL_WORD			335
+#define ESR_MDL_OFFSET			0
+#define ESR_CHAR_WORD			336
+#define ESR_CHAR_OFFSET			0
+#define ESR_DELTA_DISCHG_WORD		340
+#define ESR_DELTA_DISCHG_OFFSET		0
+#define ESR_DELTA_CHG_WORD		341
+#define ESR_DELTA_CHG_OFFSET		0
+#define ESR_ACT_WORD			342
+#define ESR_ACT_OFFSET			0
+#define RSLOW_WORD			368
+#define RSLOW_OFFSET			0
+#define OCV_WORD			417
+#define OCV_OFFSET			0
+#define VOLTAGE_PRED_WORD		432
+#define VOLTAGE_PRED_OFFSET		0
+#define BATT_SOC_WORD			449
+#define BATT_SOC_OFFSET			0
+#define FULL_SOC_WORD			455
+#define FULL_SOC_OFFSET			0
+#define CC_SOC_SW_WORD			458
+#define CC_SOC_SW_OFFSET		0
+#define CC_SOC_WORD			460
+#define CC_SOC_OFFSET			0
+#define MONOTONIC_SOC_WORD		463
+#define MONOTONIC_SOC_OFFSET		0
+
+/* v2 SRAM address and offset in ascending order */
+#define LOW_PASS_VBATT_WORD		3
+#define LOW_PASS_VBATT_OFFSET		0
+#define RSLOW_SCALE_FN_DISCHG_V2_WORD	281
+#define RSLOW_SCALE_FN_DISCHG_V2_OFFSET	0
+#define RSLOW_SCALE_FN_CHG_V2_WORD	285
+#define RSLOW_SCALE_FN_CHG_V2_OFFSET	0
+#define ACT_BATT_CAP_v2_WORD		287
+#define ACT_BATT_CAP_v2_OFFSET		0
+#define IBAT_FLT_WORD			322
+#define IBAT_FLT_OFFSET			0
+#define VBAT_FLT_WORD			326
+#define VBAT_FLT_OFFSET			0
+#define RSLOW_v2_WORD			371
+#define RSLOW_v2_OFFSET			0
+#define OCV_v2_WORD			425
+#define OCV_v2_OFFSET			0
+#define VOLTAGE_PRED_v2_WORD		440
+#define VOLTAGE_PRED_v2_OFFSET		0
+#define BATT_SOC_v2_WORD		455
+#define BATT_SOC_v2_OFFSET		0
+#define FULL_SOC_v2_WORD		461
+#define FULL_SOC_v2_OFFSET		0
+#define CC_SOC_SW_v2_WORD		464
+#define CC_SOC_SW_v2_OFFSET		0
+#define CC_SOC_v2_WORD			466
+#define CC_SOC_v2_OFFSET		0
+#define MONOTONIC_SOC_v2_WORD		469
+#define MONOTONIC_SOC_v2_OFFSET		0
+#define FIRST_LOG_CURRENT_v2_WORD	471
+#define FIRST_LOG_CURRENT_v2_OFFSET	0
+
+#define DEFAULT_FFC_TERM_CURRENT	1500
+static struct fg_irq_info fg_irqs[FG_GEN4_IRQ_MAX];
+
+/* DT parameters for FG device */
+struct fg_dt_props {
+	bool	force_load_profile;
+	bool	rapid_soc_dec_en;
+	bool	five_pin_battery;
+	bool	esr_calib_dischg;
+	bool	soc_hi_res;
+	bool	soc_scale_mode;
+	int	*dec_rate_seq;
+	int	dec_rate_len;
+	int	cutoff_volt_mv;
+	int	empty_volt_mv;
+	int	sys_min_volt_mv;
+	int	cutoff_curr_ma;
+	int	sys_term_curr_ma;
+	int	ffc_sys_term_curr_ma;
+	int	delta_soc_thr;
+	int	vbatt_scale_thr_mv;
+	int	scale_timer_ms;
+	int	force_calib_level;
+	int	esr_timer_chg_fast[NUM_ESR_TIMERS];
+	int	esr_timer_chg_slow[NUM_ESR_TIMERS];
+	int	esr_timer_dischg_fast[NUM_ESR_TIMERS];
+	int	esr_timer_dischg_slow[NUM_ESR_TIMERS];
+	u32	esr_cal_soc_thresh[ESR_CAL_LEVELS];
+	int	esr_cal_temp_thresh[ESR_CAL_LEVELS];
+	int	esr_filter_factor;
+	int	delta_esr_disable_count;
+	int	delta_esr_thr_uohms;
+	int	rconn_uohms;
+	int	batt_temp_cold_thresh;
+	int	batt_temp_hot_thresh;
+	int	batt_temp_hyst;
+	int	batt_temp_delta;
+	u32	batt_therm_freq;
+	int	esr_pulse_thresh_ma;
+	int	esr_meas_curr_ma;
+	int	slope_limit_temp;
+	int	ki_coeff_low_chg;
+	int	ki_coeff_med_chg;
+	int	ki_coeff_hi_chg;
+	int	ki_coeff_lo_med_chg_thr_ma;
+	int	ki_coeff_med_hi_chg_thr_ma;
+	int	ffc_ki_coeff_lo_med_chg_thr_ma;
+	int	ffc_ki_coeff_med_hi_chg_thr_ma;
+	int	ki_coeff_cutoff_gain;
+	int	ki_coeff_full_soc_dischg[2];
+	int	ki_coeff_soc[KI_COEFF_SOC_LEVELS];
+	int	ki_coeff_low_dischg[KI_COEFF_SOC_LEVELS];
+	int	ki_coeff_med_dischg[KI_COEFF_SOC_LEVELS];
+	int	ki_coeff_hi_dischg[KI_COEFF_SOC_LEVELS];
+	int	ki_coeff_lo_med_dchg_thr_ma;
+	int	ki_coeff_med_hi_dchg_thr_ma;
+	int	slope_limit_coeffs[SLOPE_LIMIT_NUM_COEFFS];
+};
+
+struct fg_gen4_chip {
+	struct fg_dev		fg;
+	struct fg_dt_props	dt;
+	struct cycle_counter	*counter;
+	struct cap_learning	*cl;
+	struct device_node	*pbs_dev;
+	struct nvmem_device	*fg_nvmem;
+	struct votable		*delta_esr_irq_en_votable;
+	struct votable		*pl_disable_votable;
+	struct votable		*cp_disable_votable;
+	struct votable		*parallel_current_en_votable;
+	struct votable		*mem_attn_irq_en_votable;
+	struct work_struct	esr_calib_work;
+        struct work_struct	vbat_sync_work;
+	struct work_struct	soc_scale_work;
+	struct alarm		esr_fast_cal_timer;
+	struct alarm		soc_scale_alarm_timer;
+	struct delayed_work	pl_enable_work;
+	struct work_struct	pl_current_en_work;
+	struct completion	mem_attn;
+	struct mutex		soc_scale_lock;
+	struct mutex		esr_calib_lock;
+	ktime_t			last_restart_time;
+	char			batt_profile[PROFILE_LEN];
+	enum slope_limit_status	slope_limit_sts;
+	int			ki_coeff_full_soc[2];
+	int			delta_esr_count;
+	int			esr_soh_cycle_count;
+	int			soc_scale_msoc;
+	int			prev_soc_scale_msoc;
+	int			soc_scale_slope;
+	int			msoc_actual;
+	int			vbatt_avg;
+	int			vbatt_now;
+	int			vbatt_res;
+	int			scale_timer;
+	int			current_now;
+	int			calib_level;
+	bool			ki_coeff_dischg_en;
+	bool			slope_limit_en;
+	bool			esr_fast_calib;
+	bool			esr_fast_calib_done;
+	bool			esr_fast_cal_timer_expired;
+	bool			esr_fast_calib_retry;
+	bool			esr_fcc_ctrl_en;
+	bool			esr_soh_notified;
+	bool			rslow_low;
+	bool			rapid_soc_dec_en;
+	bool			vbatt_low;
+	bool			chg_term_good;
+	bool			soc_scale_mode;
+	bool			cold_thermal_support;
+};
+
+struct bias_config {
+	u8	status_reg;
+	u8	lsb_reg;
+	int	bias_kohms;
+};
+
+static int fg_gen4_debug_mask = FG_STATUS | FG_IRQ;
+module_param_named(
+	debug_mask, fg_gen4_debug_mask, int, 0600
+);
+
+static bool fg_profile_dump;
+module_param_named(
+	profile_dump, fg_profile_dump, bool, 0600
+);
+
+static int fg_sram_dump_period_ms = 20000;
+module_param_named(
+	sram_dump_period_ms, fg_sram_dump_period_ms, int, 0600
+);
+
+static int fg_restart_mp;
+static bool fg_sram_dump;
+static bool fg_esr_fast_cal_en;
+
+static int fg_gen4_validate_soc_scale_mode(struct fg_gen4_chip *chip);
+static int fg_gen4_esr_fast_calib_config(struct fg_gen4_chip *chip, bool en);
+
+static struct fg_sram_param pm8150b_v1_sram_params[] = {
+	PARAM(BATT_SOC, BATT_SOC_WORD, BATT_SOC_OFFSET, 4, 1, 1, 0, NULL,
+		fg_decode_default),
+	PARAM(FULL_SOC, FULL_SOC_WORD, FULL_SOC_OFFSET, 2, 1, 1, 0,
+		fg_encode_default, fg_decode_default),
+	PARAM(MONOTONIC_SOC, MONOTONIC_SOC_WORD, MONOTONIC_SOC_OFFSET, 2, 1, 1,
+		0, NULL, fg_decode_default),
+	PARAM(VOLTAGE_PRED, VOLTAGE_PRED_WORD, VOLTAGE_PRED_OFFSET, 2, 1000,
+		244141, 0, NULL, fg_decode_voltage_15b),
+	PARAM(OCV, OCV_WORD, OCV_OFFSET, 2, 1000, 244141, 0, NULL,
+		fg_decode_voltage_15b),
+	PARAM(VBAT_FINAL, VBAT_FINAL_WORD, VBAT_FINAL_OFFSET, 2, 1000, 244141,
+		0, NULL, fg_decode_voltage_15b),
+	PARAM(IBAT_FINAL, IBAT_FINAL_WORD, IBAT_FINAL_OFFSET, 2, 1000, 488282,
+		0, NULL, fg_decode_current_16b),
+	PARAM(ESR, ESR_WORD, ESR_OFFSET, 2, 1000, 244141, 0, fg_encode_default,
+		fg_decode_value_16b),
+	PARAM(ESR_MDL, ESR_MDL_WORD, ESR_MDL_OFFSET, 2, 1000, 244141, 0,
+		fg_encode_default, fg_decode_value_16b),
+	PARAM(ESR_ACT, ESR_ACT_WORD, ESR_ACT_OFFSET, 2, 1000, 244141, 0,
+		fg_encode_default, fg_decode_value_16b),
+	PARAM(RSLOW, RSLOW_WORD, RSLOW_OFFSET, 2, 1000, 244141, 0, NULL,
+		fg_decode_value_16b),
+	PARAM(CC_SOC, CC_SOC_WORD, CC_SOC_OFFSET, 4, 1, 1, 0, NULL,
+		fg_decode_cc_soc),
+	PARAM(CC_SOC_SW, CC_SOC_SW_WORD, CC_SOC_SW_OFFSET, 4, 1, 1, 0, NULL,
+		fg_decode_cc_soc),
+	PARAM(ACT_BATT_CAP, ACT_BATT_CAP_WORD, ACT_BATT_CAP_OFFSET, 2,
+		1, 1, 0, NULL, fg_decode_default),
+	/* Entries below here are configurable during initialization */
+	PARAM(CUTOFF_VOLT, CUTOFF_VOLT_WORD, CUTOFF_VOLT_OFFSET, 2, 1000000,
+		244141, 0, fg_encode_voltage, NULL),
+	PARAM(VBATT_LOW, VBATT_LOW_WORD, VBATT_LOW_OFFSET, 1, 1000,
+		15625, -2000, fg_encode_voltage, NULL),
+	PARAM(VBATT_FULL, VBATT_FULL_WORD, VBATT_FULL_OFFSET, 2, 1000,
+		244141, 0, fg_encode_voltage, fg_decode_voltage_15b),
+	PARAM(CUTOFF_CURR, CUTOFF_CURR_WORD, CUTOFF_CURR_OFFSET, 2,
+		100000, 48828, 0, fg_encode_current, NULL),
+	PARAM(SYS_TERM_CURR, SYS_TERM_CURR_WORD, SYS_TERM_CURR_OFFSET, 2,
+		100000, 48828, 0, fg_encode_current, NULL),
+	PARAM(DELTA_MSOC_THR, DELTA_MSOC_THR_WORD, DELTA_MSOC_THR_OFFSET,
+		1, 2048, 1000, 0, fg_encode_default, NULL),
+	PARAM(DELTA_BSOC_THR, DELTA_BSOC_THR_WORD, DELTA_BSOC_THR_OFFSET,
+		1, 2048, 1000, 0, fg_encode_default, NULL),
+	PARAM(ESR_TIMER_DISCHG_MAX, ESR_TIMER_DISCHG_MAX_WORD,
+		ESR_TIMER_DISCHG_MAX_OFFSET, 1, 1, 1, 0, fg_encode_default,
+		NULL),
+	PARAM(ESR_TIMER_DISCHG_INIT, ESR_TIMER_DISCHG_INIT_WORD,
+		ESR_TIMER_DISCHG_INIT_OFFSET, 1, 1, 1, 0, fg_encode_default,
+		NULL),
+	PARAM(ESR_TIMER_CHG_MAX, ESR_TIMER_CHG_MAX_WORD,
+		ESR_TIMER_CHG_MAX_OFFSET, 1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_TIMER_CHG_INIT, ESR_TIMER_CHG_INIT_WORD,
+		ESR_TIMER_CHG_INIT_OFFSET, 1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_PULSE_THRESH, ESR_PULSE_THRESH_WORD, ESR_PULSE_THRESH_OFFSET,
+		1, 1000, 15625, 0, fg_encode_default, NULL),
+	PARAM(DELTA_ESR_THR, DELTA_ESR_THR_WORD, DELTA_ESR_THR_OFFSET, 2, 1000,
+		61036, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_CUTOFF, KI_COEFF_CUTOFF_WORD, KI_COEFF_CUTOFF_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_FULL_SOC, KI_COEFF_FULL_SOC_NORM_WORD,
+		KI_COEFF_FULL_SOC_NORM_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_LOW_DISCHG, KI_COEFF_LOW_DISCHG_WORD,
+		KI_COEFF_LOW_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_DISCHG, KI_COEFF_MED_DISCHG_WORD,
+		KI_COEFF_MED_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_HI_DISCHG, KI_COEFF_HI_DISCHG_WORD,
+		KI_COEFF_HI_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_LOW_CHG, KI_COEFF_LOW_CHG_WORD, KI_COEFF_LOW_CHG_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_CHG, KI_COEFF_MED_CHG_WORD, KI_COEFF_MED_CHG_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_HI_CHG, KI_COEFF_HI_CHG_WORD, KI_COEFF_HI_CHG_OFFSET, 1,
+		1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(SLOPE_LIMIT, SLOPE_LIMIT_WORD, SLOPE_LIMIT_OFFSET, 1, 8192,
+		1000000, 0, fg_encode_default, NULL),
+	PARAM(BATT_TEMP_COLD, BATT_TEMP_CONFIG_WORD, BATT_TEMP_COLD_OFFSET, 1,
+		1, 1, 0, fg_encode_default, NULL),
+	PARAM(BATT_TEMP_HOT, BATT_TEMP_CONFIG_WORD, BATT_TEMP_HOT_OFFSET, 1,
+		1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_SOC_MIN, BATT_TEMP_CONFIG2_WORD, ESR_CAL_SOC_MIN_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_SOC_MAX, ESR_CAL_THRESH_WORD, ESR_CAL_SOC_MAX_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_TEMP_MIN, ESR_CAL_THRESH_WORD, ESR_CAL_TEMP_MIN_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_TEMP_MAX, ESR_PULSE_THRESH_WORD, ESR_CAL_TEMP_MAX_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+};
+
+static struct fg_sram_param pm8150b_v2_sram_params[] = {
+	PARAM(VBAT_TAU, LOW_PASS_VBATT_WORD, LOW_PASS_VBATT_OFFSET, 1, 1, 1, 0,
+		NULL, NULL),
+	PARAM(BATT_SOC, BATT_SOC_v2_WORD, BATT_SOC_v2_OFFSET, 4, 1, 1, 0, NULL,
+		fg_decode_default),
+	PARAM(FULL_SOC, FULL_SOC_v2_WORD, FULL_SOC_v2_OFFSET, 2, 1, 1, 0,
+		fg_encode_default, fg_decode_default),
+	PARAM(MONOTONIC_SOC, MONOTONIC_SOC_v2_WORD, MONOTONIC_SOC_v2_OFFSET, 2,
+		1, 1, 0, NULL, fg_decode_default),
+	PARAM(VOLTAGE_PRED, VOLTAGE_PRED_v2_WORD, VOLTAGE_PRED_v2_OFFSET, 2,
+		1000, 244141, 0, NULL, fg_decode_voltage_15b),
+	PARAM(OCV, OCV_v2_WORD, OCV_v2_OFFSET, 2, 1000, 244141, 0, NULL,
+		fg_decode_voltage_15b),
+	PARAM(VBAT_FLT, VBAT_FLT_WORD, VBAT_FLT_OFFSET, 4, 10000, 19073, 0,
+		NULL, fg_decode_voltage_24b),
+	PARAM(VBAT_FINAL, VBAT_FINAL_WORD, VBAT_FINAL_OFFSET, 2, 1000, 244141,
+		0, NULL, fg_decode_voltage_15b),
+	PARAM(IBAT_FINAL, IBAT_FINAL_WORD, IBAT_FINAL_OFFSET, 2, 1000, 488282,
+		0, NULL, fg_decode_current_16b),
+	PARAM(IBAT_FLT, IBAT_FLT_WORD, IBAT_FLT_OFFSET, 4, 10000, 19073, 0,
+		NULL, fg_decode_current_24b),
+	PARAM(ESR, ESR_WORD, ESR_OFFSET, 2, 1000, 244141, 0, fg_encode_default,
+		fg_decode_value_16b),
+	PARAM(ESR_MDL, ESR_MDL_WORD, ESR_MDL_OFFSET, 2, 1000, 244141, 0,
+		fg_encode_default, fg_decode_value_16b),
+	PARAM(ESR_ACT, ESR_ACT_WORD, ESR_ACT_OFFSET, 2, 1000, 244141, 0,
+		fg_encode_default, fg_decode_value_16b),
+	PARAM(RSLOW, RSLOW_v2_WORD, RSLOW_v2_OFFSET, 2, 1000, 244141, 0, NULL,
+		fg_decode_value_16b),
+	PARAM(CC_SOC, CC_SOC_v2_WORD, CC_SOC_v2_OFFSET, 4, 1, 1, 0, NULL,
+		fg_decode_cc_soc),
+	PARAM(CC_SOC_SW, CC_SOC_SW_v2_WORD, CC_SOC_SW_v2_OFFSET, 4, 1, 1, 0,
+		NULL, fg_decode_cc_soc),
+	PARAM(ACT_BATT_CAP, ACT_BATT_CAP_v2_WORD, ACT_BATT_CAP_v2_OFFSET, 2,
+		1, 1, 0, NULL, fg_decode_default),
+	/* Entries below here are configurable during initialization */
+	PARAM(CUTOFF_VOLT, CUTOFF_VOLT_WORD, CUTOFF_VOLT_OFFSET, 2, 1000000,
+		244141, 0, fg_encode_voltage, NULL),
+	PARAM(VBATT_LOW, VBATT_LOW_WORD, VBATT_LOW_OFFSET, 1, 1000,
+		15625, -2000, fg_encode_voltage, NULL),
+	PARAM(VBATT_FULL, VBATT_FULL_WORD, VBATT_FULL_OFFSET, 2, 1000,
+		244141, 0, fg_encode_voltage, fg_decode_voltage_15b),
+	PARAM(CUTOFF_CURR, CUTOFF_CURR_WORD, CUTOFF_CURR_OFFSET, 2,
+		100000, 48828, 0, fg_encode_current, NULL),
+	PARAM(SYS_TERM_CURR, SYS_TERM_CURR_WORD, SYS_TERM_CURR_OFFSET, 2,
+		100000, 48828, 0, fg_encode_current, NULL),
+	PARAM(DELTA_MSOC_THR, DELTA_MSOC_THR_WORD, DELTA_MSOC_THR_OFFSET,
+		1, 2048, 1000, 0, fg_encode_default, NULL),
+	PARAM(DELTA_BSOC_THR, DELTA_BSOC_THR_WORD, DELTA_BSOC_THR_OFFSET,
+		1, 2048, 1000, 0, fg_encode_default, NULL),
+	PARAM(ESR_TIMER_DISCHG_MAX, ESR_TIMER_DISCHG_MAX_WORD,
+		ESR_TIMER_DISCHG_MAX_OFFSET, 1, 1, 1, 0, fg_encode_default,
+		NULL),
+	PARAM(ESR_TIMER_DISCHG_INIT, ESR_TIMER_DISCHG_INIT_WORD,
+		ESR_TIMER_DISCHG_INIT_OFFSET, 1, 1, 1, 0, fg_encode_default,
+		NULL),
+	PARAM(ESR_TIMER_CHG_MAX, ESR_TIMER_CHG_MAX_WORD,
+		ESR_TIMER_CHG_MAX_OFFSET, 1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_TIMER_CHG_INIT, ESR_TIMER_CHG_INIT_WORD,
+		ESR_TIMER_CHG_INIT_OFFSET, 1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_PULSE_THRESH, ESR_PULSE_THRESH_WORD, ESR_PULSE_THRESH_OFFSET,
+		1, 1000, 15625, 0, fg_encode_default, NULL),
+	PARAM(DELTA_ESR_THR, DELTA_ESR_THR_WORD, DELTA_ESR_THR_OFFSET, 2, 1000,
+		61036, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_CUTOFF, KI_COEFF_CUTOFF_WORD, KI_COEFF_CUTOFF_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_FULL_SOC, KI_COEFF_FULL_SOC_NORM_WORD,
+		KI_COEFF_FULL_SOC_NORM_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_LOW_DISCHG, KI_COEFF_LOW_DISCHG_WORD,
+		KI_COEFF_LOW_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_DISCHG, KI_COEFF_MED_DISCHG_WORD,
+		KI_COEFF_MED_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_HI_DISCHG, KI_COEFF_HI_DISCHG_WORD,
+		KI_COEFF_HI_DISCHG_OFFSET, 1, 1000, 61035, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_LO_MED_DCHG_THR, KI_COEFF_LO_MED_DCHG_THR_WORD,
+		KI_COEFF_LO_MED_DCHG_THR_OFFSET, 1, 1000, 15625, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_HI_DCHG_THR, KI_COEFF_MED_HI_DCHG_THR_WORD,
+		KI_COEFF_MED_HI_DCHG_THR_OFFSET, 1, 1000, 15625, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_LOW_CHG, KI_COEFF_LOW_CHG_WORD, KI_COEFF_LOW_CHG_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_CHG, KI_COEFF_MED_CHG_WORD, KI_COEFF_MED_CHG_OFFSET,
+		1, 1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_HI_CHG, KI_COEFF_HI_CHG_WORD, KI_COEFF_HI_CHG_OFFSET, 1,
+		1000, 61035, 0, fg_encode_default, NULL),
+	PARAM(KI_COEFF_LO_MED_CHG_THR, KI_COEFF_LO_MED_CHG_THR_WORD,
+		KI_COEFF_LO_MED_CHG_THR_OFFSET, 1, 1000, 15625, 0,
+		fg_encode_default, NULL),
+	PARAM(KI_COEFF_MED_HI_CHG_THR, KI_COEFF_MED_HI_CHG_THR_WORD,
+		KI_COEFF_MED_HI_CHG_THR_OFFSET, 1, 1000, 15625, 0,
+		fg_encode_default, NULL),
+	PARAM(SLOPE_LIMIT, SLOPE_LIMIT_WORD, SLOPE_LIMIT_OFFSET, 1, 8192,
+		1000000, 0, fg_encode_default, NULL),
+	PARAM(BATT_TEMP_COLD, BATT_TEMP_CONFIG_WORD, BATT_TEMP_COLD_OFFSET, 1,
+		1, 1, 0, fg_encode_default, NULL),
+	PARAM(BATT_TEMP_HOT, BATT_TEMP_CONFIG_WORD, BATT_TEMP_HOT_OFFSET, 1,
+		1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_SOC_MIN, BATT_TEMP_CONFIG2_WORD, ESR_CAL_SOC_MIN_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_SOC_MAX, ESR_CAL_THRESH_WORD, ESR_CAL_SOC_MAX_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_TEMP_MIN, ESR_CAL_THRESH_WORD, ESR_CAL_TEMP_MIN_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+	PARAM(ESR_CAL_TEMP_MAX, ESR_PULSE_THRESH_WORD, ESR_CAL_TEMP_MAX_OFFSET,
+		1, 1, 1, 0, fg_encode_default, NULL),
+};
+
+/* All get functions below */
+
+struct bias_config id_table[3] = {
+	{0x65, 0x66, 400},
+	{0x6D, 0x6E, 100},
+	{0x75, 0x76, 30},
+};
+
+#define MAX_BIAS_CODE	0x70E4
+static int fg_gen4_get_batt_id(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int i, rc, batt_id_kohms;
+	u16 tmp = 0, bias_code = 0, delta = 0;
+	u8 val, bias_id = 0;
+
+	for (i = 0; i < ARRAY_SIZE(id_table); i++)  {
+		rc = fg_read(fg, fg->rradc_base + id_table[i].status_reg, &val,
+				1);
+		if (rc < 0) {
+			pr_err("Failed to read bias_sts, rc=%d\n", rc);
+			return rc;
+		}
+
+		if (val & BIAS_STS_READY) {
+			rc = fg_read(fg, fg->rradc_base + id_table[i].lsb_reg,
+					(u8 *)&tmp, 2);
+			if (rc < 0) {
+				pr_err("Failed to read bias_lsb_reg, rc=%d\n",
+					rc);
+				return rc;
+			}
+		}
+
+		pr_debug("bias_code[%d]: 0x%04x\n", i, tmp);
+
+		/*
+		 * Bias code closer to MAX_BIAS_CODE/2 is the one which should
+		 * be used for calculating battery id.
+		 */
+		if (!delta || abs(tmp - MAX_BIAS_CODE / 2) < delta) {
+			bias_id = i;
+			bias_code = tmp;
+			delta = abs(tmp - MAX_BIAS_CODE / 2);
+		}
+	}
+
+	pr_debug("bias_id: %d bias_code: 0x%04x\n", bias_id, bias_code);
+
+	/*
+	 * Following equation is used for calculating battery id.
+	 * batt_id(KOhms) = bias_id(KOhms) / ((MAX_BIAS_CODE / bias_code) - 1)
+	 */
+	batt_id_kohms = (id_table[bias_id].bias_kohms * bias_code) * 10 /
+			(MAX_BIAS_CODE - bias_code);
+	fg->batt_id_ohms = (batt_id_kohms * 1000) / 10;
+	return 0;
+}
+
+static int fg_gen4_get_nominal_capacity(struct fg_gen4_chip *chip,
+					int64_t *nom_cap_uah)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	u8 buf[2];
+
+	rc = fg_sram_read(fg, NOM_CAP_WORD, NOM_CAP_OFFSET, buf, 2,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading %04x[%d] rc=%d\n", NOM_CAP_WORD,
+			NOM_CAP_OFFSET, rc);
+		return rc;
+	}
+
+	*nom_cap_uah = (int)(buf[0] | buf[1] << 8) * 1000;
+	fg_dbg(fg, FG_CAP_LEARN, "nom_cap_uah: %lld\n", *nom_cap_uah);
+	return 0;
+}
+
+static int fg_gen4_get_learned_capacity(void *data, int64_t *learned_cap_uah)
+{
+	struct fg_gen4_chip *chip = data;
+	struct fg_dev *fg;
+	int rc, act_cap_mah;
+	u8 buf[2];
+
+	if (!chip)
+		return -ENODEV;
+
+	fg = &chip->fg;
+	if (chip->fg_nvmem)
+		rc = nvmem_device_read(chip->fg_nvmem, SDAM_CAP_LEARN_OFFSET, 2,
+					buf);
+	else
+		rc = fg_get_sram_prop(fg, FG_SRAM_ACT_BATT_CAP, &act_cap_mah);
+	if (rc < 0) {
+		pr_err("Error in getting learned capacity, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (chip->fg_nvmem)
+		*learned_cap_uah = (buf[0] | buf[1] << 8) * 1000;
+	else
+		*learned_cap_uah = act_cap_mah * 1000;
+
+	fg_dbg(fg, FG_CAP_LEARN, "learned_cap_uah:%lld\n", *learned_cap_uah);
+	return 0;
+}
+
+#define CC_SOC_30BIT	GENMASK(29, 0)
+#define BATT_SOC_32BIT	GENMASK(31, 0)
+static int fg_gen4_get_charge_counter(struct fg_gen4_chip *chip, int *val)
+{
+	int rc, cc_soc;
+	int64_t learned_cap_uah;
+
+	rc = fg_get_sram_prop(&chip->fg, FG_SRAM_CC_SOC_SW, &cc_soc);
+	if (rc < 0) {
+		pr_err("Error in getting CC_SOC_SW, rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_gen4_get_learned_capacity(chip, &learned_cap_uah);
+	if (rc < 0) {
+		pr_err("Error in getting learned capacity, rc=%d\n", rc);
+		return rc;
+	}
+
+	*val = div_s64(cc_soc * learned_cap_uah, CC_SOC_30BIT);
+	return 0;
+}
+
+static int fg_gen4_get_battery_temp(struct fg_dev *fg, int *val)
+{
+	int rc = 0;
+	u16 buf;
+	if (fg->batt_fake_temp != -EINVAL) {
+		*val = fg->batt_fake_temp;
+		pr_err("use fake batt temp =%d\n", fg->batt_fake_temp);
+		return 0;
+	}
+	rc = fg_sram_read(fg, BATT_TEMP_WORD, BATT_TEMP_OFFSET, (u8 *)&buf,
+			2, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Failed to read BATT_TEMP_WORD rc=%d\n", rc);
+		return rc;
+	}
+
+	/*
+	 * 10 bits representing temperature from -128 to 127 and each LSB is
+	 * 0.25 C. Multiply by 10 to convert it to deci degrees C.
+	 */
+	*val = sign_extend32(buf, 9) * 100 / 40;
+
+	return 0;
+}
+
+static int fg_gen4_tz_get_temp(struct thermal_zone_device *data, int *temperature)
+{
+	struct fg_dev *fg = (struct fg_dev *)data;
+	int rc, temp;
+
+	if (!temperature)
+		return -EINVAL;
+
+	rc = fg_gen4_get_battery_temp(fg, &temp);
+	if (rc < 0)
+		return rc;
+
+	/* Convert deciDegC to milliDegC */
+	*temperature = temp * 100;
+	return rc;
+}
+
+static struct thermal_zone_device_ops fg_gen4_tz_ops = {
+	.get_temp = fg_gen4_tz_get_temp,
+};
+
+static int fg_gen4_get_debug_batt_id(struct fg_dev *fg, int *batt_id)
+{
+	int rc;
+	u16 tmp;
+
+	rc = fg_read(fg, ADC_RR_FAKE_BATT_LOW_LSB(fg), (u8 *)&tmp, 2);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			ADC_RR_FAKE_BATT_LOW_LSB(fg), rc);
+		return rc;
+	}
+
+	/*
+	 * Following equation is used for calculating battery id.
+	 * batt_id(KOhms) = 30000 / ((MAX_BIAS_CODE / bias_code) - 1)
+	 */
+
+	batt_id[0] = (30000 * tmp) / (MAX_BIAS_CODE - tmp);
+
+	rc = fg_read(fg, ADC_RR_FAKE_BATT_HIGH_LSB(fg), (u8 *)&tmp, 2);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			ADC_RR_FAKE_BATT_HIGH_LSB(fg), rc);
+		return rc;
+	}
+
+	batt_id[1] = (30000 * tmp) / (MAX_BIAS_CODE - tmp);
+	pr_debug("debug batt_id range: [%d %d]\n", batt_id[0], batt_id[1]);
+	return 0;
+}
+
+static bool is_debug_batt_id(struct fg_dev *fg)
+{
+	int debug_batt_id[2], rc;
+
+	if (fg->batt_id_ohms < 0)
+		return false;
+
+	rc = fg_gen4_get_debug_batt_id(fg, debug_batt_id);
+	if (rc < 0) {
+		pr_err("Failed to get debug batt_id, rc=%d\n", rc);
+		return false;
+	}
+
+	if (is_between(debug_batt_id[0], debug_batt_id[1],
+		fg->batt_id_ohms)) {
+		fg_dbg(fg, FG_POWER_SUPPLY, "Debug battery id: %dohms\n",
+			fg->batt_id_ohms);
+		return true;
+	}
+
+	return false;
+}
+
+static int fg_gen4_get_prop_capacity(struct fg_dev *fg, int *val)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, msoc;
+
+	if (is_debug_batt_id(fg)) {
+		*val = DEBUG_BATT_SOC;
+		return 0;
+	}
+
+	if (fg->fg_restarting) {
+		*val = fg->last_soc;
+		return 0;
+	}
+
+	if (fg->battery_missing || !fg->soc_reporting_ready) {
+		*val = BATT_MISS_SOC;
+		return 0;
+	}
+
+	if (chip->vbatt_low) {
+		*val = EMPTY_SOC;
+		return 0;
+	}
+
+	if (fg->charge_full) {
+		*val = FULL_CAPACITY;
+		return 0;
+	}
+
+	rc = fg_get_msoc(fg, &msoc);
+	if (rc < 0)
+		return rc;
+
+	if (fg->empty_restart_fg && (msoc == 0))
+		msoc = EMPTY_REPORT_SOC;
+
+	*val = msoc;
+
+	if (chip->soc_scale_mode) {
+		mutex_lock(&chip->soc_scale_lock);
+		*val = chip->soc_scale_msoc;
+		mutex_unlock(&chip->soc_scale_lock);
+	} else {
+		rc = fg_get_msoc(fg, &msoc);
+		if (rc < 0)
+			return rc;
+
+		*val = msoc;
+	}
+
+	return 0;
+}
+
+static inline void get_esr_meas_current(int curr_ma, u8 *val)
+{
+	switch (curr_ma) {
+	case 60:
+		*val = ESR_MEAS_CUR_60MA;
+		break;
+	case 120:
+		*val = ESR_MEAS_CUR_120MA;
+		break;
+	case 180:
+		*val = ESR_MEAS_CUR_180MA;
+		break;
+	case 240:
+		*val = ESR_MEAS_CUR_240MA;
+		break;
+	default:
+		*val = ESR_MEAS_CUR_120MA;
+		break;
+	};
+
+	*val <<= ESR_PULL_DOWN_IVAL_SHIFT;
+}
+
+static int fg_gen4_get_power(struct fg_gen4_chip *chip, int *val, bool average)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, v_min, v_pred, esr_uohms, rslow_uohms;
+	s64 power;
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_VOLTAGE_PRED, &v_pred);
+	if (rc < 0)
+		return rc;
+
+	v_min = chip->dt.sys_min_volt_mv * 1000;
+	power = (s64)v_min * (v_pred - v_min);
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_ESR_ACT, &esr_uohms);
+	if (rc < 0) {
+		pr_err("failed to get ESR_ACT, rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_RSLOW, &rslow_uohms);
+	if (rc < 0) {
+		pr_err("failed to get Rslow, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (average)
+		power = div_s64(power, esr_uohms + rslow_uohms);
+	else
+		power = div_s64(power, esr_uohms);
+
+	pr_debug("V_min: %d V_pred: %d ESR: %d Rslow: %d power: %lld\n", v_min,
+		v_pred, esr_uohms, rslow_uohms, power);
+
+	*val = power;
+	return 0;
+}
+
+static int fg_gen4_get_prop_soc_scale(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_VBAT_FLT, &chip->vbatt_avg);
+	if (rc < 0) {
+		pr_err("Failed to get filtered battery voltage, rc = %d\n",
+			rc);
+		return rc;
+	}
+
+	rc = fg_get_battery_voltage(fg, &chip->vbatt_now);
+	if (rc < 0) {
+		pr_err("Failed to get battery voltage, rc =%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_get_battery_current(fg, &chip->current_now);
+	if (rc < 0) {
+		pr_err("Failed to get battery current rc=%d\n", rc);
+		return rc;
+	}
+
+	chip->vbatt_now = DIV_ROUND_CLOSEST(chip->vbatt_now, 1000);
+	chip->vbatt_avg = DIV_ROUND_CLOSEST(chip->vbatt_avg, 1000);
+	chip->vbatt_res = chip->vbatt_avg - chip->dt.cutoff_volt_mv;
+	fg_dbg(fg, FG_FVSS, "Vbatt now=%d Vbatt avg=%d Vbatt res=%d\n",
+		chip->vbatt_now, chip->vbatt_avg, chip->vbatt_res);
+
+	return rc;
+}
+
+#define SDAM1_MEM_124_REG	0xB0BC
+static int fg_gen4_set_calibrate_level(struct fg_gen4_chip *chip, int val)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	u8 buf;
+
+	if (!chip->pbs_dev)
+		return -ENODEV;
+
+	if (is_debug_batt_id(fg))
+		return 0;
+
+	if (val < 0 || val > 0x83) {
+		pr_err("Incorrect calibration level %d\n", val);
+		return -EINVAL;
+	}
+
+	if (val == chip->calib_level)
+		return 0;
+
+	if (chip->dt.force_calib_level != -EINVAL)
+		val = chip->dt.force_calib_level;
+
+	buf = (u8)val;
+	rc = fg_write(fg, SDAM1_MEM_124_REG, &buf, 1);
+	if (rc < 0) {
+		pr_err("Error in writing to 0x%04X, rc=%d\n",
+			SDAM1_MEM_124_REG, rc);
+		return rc;
+	}
+
+	buf = 0x1;
+	rc = qpnp_pbs_trigger_event(chip->pbs_dev, buf);
+	if (rc < 0) {
+		pr_err("Error in triggering PBS rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_read(fg, SDAM1_MEM_124_REG, &buf, 1);
+	if (rc < 0) {
+		pr_err("Error in reading from 0x%04X, rc=%d\n",
+			SDAM1_MEM_124_REG, rc);
+		return rc;
+	}
+
+	if (buf) {
+		pr_err("Incorrect return value: %x\n", buf);
+		return -EINVAL;
+	}
+
+	if (is_parallel_charger_available(fg)) {
+		cancel_work_sync(&chip->pl_current_en_work);
+		schedule_work(&chip->pl_current_en_work);
+	}
+
+	chip->calib_level = val;
+	fg_dbg(fg, FG_POWER_SUPPLY, "Set calib_level to %x\n", val);
+	return 0;
+}
+
+/* ALG callback functions below */
+
+static int fg_gen4_store_learned_capacity(void *data, int64_t learned_cap_uah)
+{
+	struct fg_gen4_chip *chip = data;
+	struct fg_dev *fg;
+	int16_t cc_mah;
+	int rc;
+	u8 cookie = SDAM_COOKIE;
+
+	if (!chip)
+		return -ENODEV;
+
+	fg = &chip->fg;
+	if (fg->battery_missing || !learned_cap_uah)
+		return -EPERM;
+
+	cc_mah = div64_s64(learned_cap_uah, 1000);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ACT_BATT_CAP].addr_word,
+			fg->sp[FG_SRAM_ACT_BATT_CAP].addr_byte, (u8 *)&cc_mah,
+			fg->sp[FG_SRAM_ACT_BATT_CAP].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing act_batt_cap_bkup, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (chip->fg_nvmem) {
+		rc = nvmem_device_write(chip->fg_nvmem, SDAM_CAP_LEARN_OFFSET,
+					2, (u8 *)&cc_mah);
+		if (rc < 0) {
+			pr_err("Error in writing learned capacity to SDAM, rc=%d\n",
+				rc);
+			return rc;
+		}
+
+		rc = nvmem_device_write(chip->fg_nvmem, SDAM_COOKIE_OFFSET, 1,
+					&cookie);
+		if (rc < 0) {
+			pr_err("Error in writing cookie to SDAM, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	fg_dbg(fg, FG_CAP_LEARN, "learned capacity %llduah/%dmah stored\n",
+		chip->cl->learned_cap_uah, cc_mah);
+	return 0;
+}
+
+static int fg_gen4_prime_cc_soc_sw(void *data, u32 batt_soc)
+{
+	struct fg_gen4_chip *chip = data;
+	struct fg_dev *fg;
+	int rc, cc_soc_sw;
+
+	if (!chip)
+		return -ENODEV;
+
+	fg = &chip->fg;
+	if (batt_soc == CC_SOC_30BIT)
+		cc_soc_sw = batt_soc;
+	else
+		cc_soc_sw = div64_s64((int64_t)batt_soc * CC_SOC_30BIT,
+				BATT_SOC_32BIT);
+
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_CC_SOC_SW].addr_word,
+		fg->sp[FG_SRAM_CC_SOC_SW].addr_byte, (u8 *)&cc_soc_sw,
+		fg->sp[FG_SRAM_CC_SOC_SW].len, FG_IMA_ATOMIC);
+	if (rc < 0)
+		pr_err("Error in writing cc_soc_sw, rc=%d\n", rc);
+	else
+		fg_dbg(fg, FG_STATUS, "cc_soc_sw: %x\n", cc_soc_sw);
+
+	return rc;
+}
+
+static bool fg_gen4_cl_ok_to_begin(void *data)
+{
+	struct fg_gen4_chip *chip = data;
+	struct fg_dev *fg;
+	int rc, val = 0;
+
+	if (!chip)
+		return false;
+
+	fg = &chip->fg;
+
+	if (chip->cl->dt.ibat_flt_thr_ma <= 0)
+		return true;
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_IBAT_FLT, &val);
+	if (rc < 0) {
+		pr_err("Failed to get filtered battery current, rc = %d\n",
+			rc);
+		return true;
+	}
+
+	/* convert to milli-units */
+	val = DIV_ROUND_CLOSEST(val, 1000);
+
+	pr_debug("IBAT_FLT thr: %d val: %d\n", chip->cl->dt.ibat_flt_thr_ma,
+		val);
+
+	if (abs(val) > chip->cl->dt.ibat_flt_thr_ma)
+		return false;
+
+	return true;
+}
+
+static int fg_gen4_get_cc_soc_sw(void *data, int *cc_soc_sw)
+{
+	struct fg_gen4_chip *chip = data;
+	struct fg_dev *fg;
+	int rc, temp;
+
+	if (!chip)
+		return -ENODEV;
+
+	fg = &chip->fg;
+	rc = fg_get_sram_prop(fg, FG_SRAM_CC_SOC_SW, &temp);
+	if (rc < 0) {
+		pr_err("Error in getting CC_SOC_SW, rc=%d\n", rc);
+		return rc;
+	}
+
+	*cc_soc_sw = temp;
+	return rc;
+}
+
+static int fg_gen4_restore_count(void *data, u16 *buf, int length)
+{
+	struct fg_gen4_chip *chip = data;
+	int id, rc = 0;
+	u8 tmp[2];
+
+	if (!chip)
+		return -ENODEV;
+
+	if (!buf || length > BUCKET_COUNT)
+		return -EINVAL;
+
+	for (id = 0; id < length; id++) {
+		if (chip->fg_nvmem)
+			rc = nvmem_device_read(chip->fg_nvmem,
+				SDAM_CYCLE_COUNT_OFFSET + (id * 2), 2, tmp);
+		else
+			rc = fg_sram_read(&chip->fg, CYCLE_COUNT_WORD + id,
+					CYCLE_COUNT_OFFSET, (u8 *)tmp, 2,
+					FG_IMA_DEFAULT);
+		if (rc < 0)
+			pr_err("failed to read bucket %d rc=%d\n", id, rc);
+		else
+			*buf++ = tmp[0] | tmp[1] << 8;
+	}
+
+	return rc;
+}
+
+static int fg_gen4_store_count(void *data, u16 *buf, int id, int length)
+{
+	struct fg_gen4_chip *chip = data;
+	int rc;
+
+	if (!chip)
+		return -ENODEV;
+
+	if (!buf || length > BUCKET_COUNT * 2 || id < 0 ||
+		id > BUCKET_COUNT - 1 || ((id * 2) + length) > BUCKET_COUNT * 2)
+		return -EINVAL;
+
+	if (chip->fg_nvmem)
+		rc = nvmem_device_write(chip->fg_nvmem,
+			SDAM_CYCLE_COUNT_OFFSET + (id * 2), length, (u8 *)buf);
+	else
+		rc = fg_sram_write(&chip->fg, CYCLE_COUNT_WORD + id,
+				CYCLE_COUNT_OFFSET, (u8 *)buf, length,
+				FG_IMA_DEFAULT);
+	if (rc < 0)
+		pr_err("failed to write bucket rc=%d\n", rc);
+
+	return rc;
+}
+
+/* All worker and helper functions below */
+
+static int fg_parse_dt_property_u32_array(struct device_node *node,
+				const char *prop_name, int *buf, int len)
+{
+	int rc;
+
+	rc = of_property_count_elems_of_size(node, prop_name, sizeof(u32));
+	if (rc < 0) {
+		if (rc == -EINVAL)
+			return 0;
+		else
+			return rc;
+	} else if (rc != len) {
+		pr_err("Incorrect length %d for %s, rc=%d\n", len, prop_name,
+			rc);
+		return -EINVAL;
+	}
+
+	rc = of_property_read_u32_array(node, prop_name, buf, len);
+	if (rc < 0) {
+		pr_err("Error in reading %s, rc=%d\n", prop_name, rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static void fg_gen4_update_rslow_coeff(struct fg_dev *fg, int batt_temp)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, i;
+	bool rslow_low = false;
+	u8 buf[RSLOW_NUM_COEFFS];
+
+	if (!fg->bp.rslow_normal_coeffs || !fg->bp.rslow_low_coeffs)
+		return;
+
+	/* Update Rslow low coefficients when Tbatt is < 0 C */
+	if (batt_temp < 0)
+		rslow_low = true;
+
+	if (chip->rslow_low == rslow_low)
+		return;
+
+	for (i = 0; i < RSLOW_NUM_COEFFS; i++) {
+		if (rslow_low)
+			buf[i] = fg->bp.rslow_low_coeffs[i] & 0xFF;
+		else
+			buf[i] = fg->bp.rslow_normal_coeffs[i] & 0xFF;
+	}
+
+	rc = fg_sram_write(fg, RSLOW_COEFF_DISCHG_WORD, RSLOW_COEFF_LOW_OFFSET,
+			buf, RSLOW_NUM_COEFFS, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Failed to write RLOW_COEFF_DISCHG_WORD rc=%d\n", rc);
+	} else {
+		chip->rslow_low = rslow_low;
+		fg_dbg(fg, FG_STATUS, "Updated Rslow %s coefficients\n",
+			rslow_low ? "low" : "normal");
+	}
+}
+
+#define KI_COEFF_FULL_SOC_NORM_DEFAULT	2442
+#define KI_COEFF_FULL_SOC_LOW_DEFAULT	2442
+static int fg_gen4_adjust_ki_coeff_full_soc(struct fg_gen4_chip *chip,
+						int batt_temp)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, ki_coeff_full_soc_norm, ki_coeff_full_soc_low;
+	u8 val;
+
+	if ((batt_temp < 0) ||
+		(fg->charge_status == POWER_SUPPLY_STATUS_DISCHARGING)) {
+		ki_coeff_full_soc_norm = 0;
+		ki_coeff_full_soc_low = 0;
+	} else if (fg->charge_status == POWER_SUPPLY_STATUS_CHARGING) {
+		ki_coeff_full_soc_norm = chip->dt.ki_coeff_full_soc_dischg[0];
+		ki_coeff_full_soc_low = chip->dt.ki_coeff_full_soc_dischg[1];
+	}
+
+	if (chip->ki_coeff_full_soc[0] == ki_coeff_full_soc_norm &&
+		chip->ki_coeff_full_soc[1] == ki_coeff_full_soc_low)
+		return 0;
+
+	fg_encode(fg->sp, FG_SRAM_KI_COEFF_FULL_SOC, ki_coeff_full_soc_norm,
+		&val);
+	rc = fg_sram_write(fg, KI_COEFF_FULL_SOC_NORM_WORD,
+			KI_COEFF_FULL_SOC_NORM_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ki_coeff_full_soc_norm, rc=%d\n", rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_KI_COEFF_FULL_SOC, ki_coeff_full_soc_low,
+		&val);
+	rc = fg_sram_write(fg, KI_COEFF_LOW_DISCHG_WORD,
+			KI_COEFF_FULL_SOC_LOW_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ki_coeff_full_soc_low, rc=%d\n", rc);
+		return rc;
+	}
+
+	chip->ki_coeff_full_soc[0] = ki_coeff_full_soc_norm;
+	chip->ki_coeff_full_soc[1] = ki_coeff_full_soc_low;
+	fg_dbg(fg, FG_STATUS, "Wrote ki_coeff_full_soc [%d %d]\n",
+		ki_coeff_full_soc_norm, ki_coeff_full_soc_low);
+	return 0;
+}
+
+static int fg_gen4_set_ki_coeff_dischg(struct fg_dev *fg, int ki_coeff_low,
+		int ki_coeff_med, int ki_coeff_hi)
+{
+	int rc;
+	u8 val;
+
+	if (ki_coeff_low >= 0) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_LOW_DISCHG, ki_coeff_low,
+			&val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_DISCHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_DISCHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_DISCHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_low, rc=%d\n", rc);
+			return rc;
+		}
+		fg_dbg(fg, FG_STATUS, "Wrote ki_coeff_low %d\n", ki_coeff_low);
+	}
+
+	if (ki_coeff_med >= 0) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_MED_DISCHG, ki_coeff_med,
+			&val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_MED_DISCHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_MED_DISCHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_MED_DISCHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_med, rc=%d\n", rc);
+			return rc;
+		}
+		fg_dbg(fg, FG_STATUS, "Wrote ki_coeff_med %d\n", ki_coeff_med);
+	}
+
+	if (ki_coeff_hi >= 0) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_HI_DISCHG, ki_coeff_hi,
+			&val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_HI_DISCHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_HI_DISCHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_HI_DISCHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_hi, rc=%d\n", rc);
+			return rc;
+		}
+		fg_dbg(fg, FG_STATUS, "Wrote ki_coeff_hi %d\n", ki_coeff_hi);
+	}
+
+	return 0;
+}
+
+#define KI_COEFF_LOW_DISCHG_DEFAULT	367
+#define KI_COEFF_MED_DISCHG_DEFAULT	62
+#define KI_COEFF_HI_DISCHG_DEFAULT	0
+static int fg_gen4_adjust_ki_coeff_dischg(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, i, msoc;
+	int ki_coeff_low = KI_COEFF_LOW_DISCHG_DEFAULT;
+	int ki_coeff_med = KI_COEFF_MED_DISCHG_DEFAULT;
+	int ki_coeff_hi = KI_COEFF_HI_DISCHG_DEFAULT;
+
+	if (!chip->ki_coeff_dischg_en)
+		return 0;
+
+	rc = fg_gen4_get_prop_capacity(fg, &msoc);
+	if (rc < 0) {
+		pr_err("Error in getting capacity, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (fg->charge_status == POWER_SUPPLY_STATUS_DISCHARGING) {
+		for (i = KI_COEFF_SOC_LEVELS - 1; i >= 0; i--) {
+			if (msoc < chip->dt.ki_coeff_soc[i]) {
+				ki_coeff_low = chip->dt.ki_coeff_low_dischg[i];
+				ki_coeff_med = chip->dt.ki_coeff_med_dischg[i];
+				ki_coeff_hi = chip->dt.ki_coeff_hi_dischg[i];
+			}
+		}
+	}
+
+	rc = fg_gen4_set_ki_coeff_dischg(fg,
+			ki_coeff_low, ki_coeff_med, ki_coeff_hi);
+	if (rc < 0)
+		return rc;
+
+	return 0;
+}
+
+static int fg_gen4_slope_limit_config(struct fg_gen4_chip *chip, int batt_temp)
+{
+	struct fg_dev *fg = &chip->fg;
+	enum slope_limit_status status;
+	int rc;
+	u8 buf;
+
+	if (!chip->slope_limit_en || chip->rapid_soc_dec_en)
+		return 0;
+
+	if (fg->charge_status == POWER_SUPPLY_STATUS_CHARGING ||
+		fg->charge_status == POWER_SUPPLY_STATUS_FULL) {
+		if (batt_temp < chip->dt.slope_limit_temp)
+			status = LOW_TEMP_CHARGE;
+		else
+			status = HIGH_TEMP_CHARGE;
+	} else {
+		if (batt_temp < chip->dt.slope_limit_temp)
+			status = LOW_TEMP_DISCHARGE;
+		else
+			status = HIGH_TEMP_DISCHARGE;
+	}
+
+	if (chip->slope_limit_sts == status)
+		return 0;
+
+	fg_encode(fg->sp, FG_SRAM_SLOPE_LIMIT,
+		chip->dt.slope_limit_coeffs[status], &buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_SLOPE_LIMIT].addr_word,
+			fg->sp[FG_SRAM_SLOPE_LIMIT].addr_byte, &buf,
+			fg->sp[FG_SRAM_SLOPE_LIMIT].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in configuring slope_limit coefficient, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	chip->slope_limit_sts = status;
+	fg_dbg(fg, FG_STATUS, "Slope limit status: %d value: %x\n", status,
+		buf);
+	return 0;
+}
+
+static int fg_gen4_configure_cutoff_current(struct fg_dev *fg, int current_ma)
+{
+	int rc;
+	u8 buf[2];
+
+	fg_encode(fg->sp, FG_SRAM_CUTOFF_CURR, current_ma, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_CUTOFF_CURR].addr_word,
+			fg->sp[FG_SRAM_CUTOFF_CURR].addr_byte, buf,
+			fg->sp[FG_SRAM_CUTOFF_CURR].len, FG_IMA_DEFAULT);
+	if (rc < 0)
+		pr_err("Error in writing cutoff_curr, rc=%d\n", rc);
+
+	return rc;
+}
+
+#define SLOPE_LIMIT_DEFAULT	5738
+#define CUTOFF_CURRENT_MAX	15999
+static int fg_gen4_rapid_soc_config(struct fg_gen4_chip *chip, bool en)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, slope_limit_coeff, cutoff_curr_ma;
+	u8 buf;
+
+	slope_limit_coeff = en ? SLOPE_LIMIT_COEFF_MAX : SLOPE_LIMIT_DEFAULT;
+	fg_encode(fg->sp, FG_SRAM_SLOPE_LIMIT, slope_limit_coeff, &buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_SLOPE_LIMIT].addr_word,
+			fg->sp[FG_SRAM_SLOPE_LIMIT].addr_byte, &buf,
+			fg->sp[FG_SRAM_SLOPE_LIMIT].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in configuring slope_limit coefficient, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	cutoff_curr_ma = en ? CUTOFF_CURRENT_MAX : chip->dt.cutoff_curr_ma;
+	rc = fg_gen4_configure_cutoff_current(fg, cutoff_curr_ma);
+	if (rc < 0)
+		return rc;
+
+	fg_dbg(fg, FG_STATUS, "Configured slope limit coeff %d cutoff current %d mA\n",
+		slope_limit_coeff, cutoff_curr_ma);
+	return 0;
+}
+
+static int fg_gen4_get_batt_profile(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	struct device_node *node = fg->dev->of_node;
+	struct device_node *batt_node, *profile_node;
+	const char *data;
+	int rc, len;
+
+	batt_node = of_find_node_by_name(node, "qcom,battery-data");
+	if (!batt_node) {
+		pr_err("Batterydata not available\n");
+		return -ENXIO;
+	}
+
+	profile_node = of_batterydata_get_best_profile(batt_node,
+				fg->batt_id_ohms / 1000, NULL);
+
+
+	if (IS_ERR(profile_node))
+		return PTR_ERR(profile_node);
+
+	if (!profile_node) {
+		pr_err("couldn't find profile handle\n");
+		return -ENODATA;
+	}
+
+	rc = of_property_read_string(profile_node, "qcom,battery-type",
+			&fg->bp.batt_type_str);
+	if (rc < 0) {
+		pr_err("battery type unavailable, rc:%d\n", rc);
+		return rc;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,max-voltage-uv",
+			&fg->bp.float_volt_uv);
+	if (rc < 0) {
+		pr_err("battery float voltage unavailable, rc:%d\n", rc);
+		fg->bp.float_volt_uv = -EINVAL;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,fastchg-current-ma",
+			&fg->bp.fastchg_curr_ma);
+	if (rc < 0) {
+		pr_err("battery fastchg current unavailable, rc:%d\n", rc);
+		fg->bp.fastchg_curr_ma = -EINVAL;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,ffc-low-temp-term-current-ma",
+			&fg->bp.ffc_low_temp_term_curr_ma);
+	if (rc < 0) {
+		pr_err("battery system current unavailable, rc:%d\n", rc);
+		fg->bp.ffc_low_temp_term_curr_ma = -DEFAULT_FFC_TERM_CURRENT;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,ffc-high-temp-term-current-ma",
+			&fg->bp.ffc_high_temp_term_curr_ma);
+	if (rc < 0) {
+		pr_err("battery system current unavailable, rc:%d\n", rc);
+		fg->bp.ffc_high_temp_term_curr_ma = -DEFAULT_FFC_TERM_CURRENT;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,fg-cc-cv-threshold-mv",
+			&fg->bp.vbatt_full_mv);
+	if (rc < 0) {
+		pr_err("battery cc_cv threshold unavailable, rc:%d\n", rc);
+		fg->bp.vbatt_full_mv = -EINVAL;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,fg-ffc-cc-cv-threshold-mv",
+			&fg->bp.ffc_vbatt_full_mv);
+	if (rc < 0) {
+		pr_err("battery ffc cc_cv threshold unavailable, rc:%d\n", rc);
+		fg->bp.ffc_vbatt_full_mv = -EINVAL;
+	}
+
+	rc = of_property_read_u32(profile_node, "qcom,nom-batt-capacity-mah",
+			&fg->bp.nom_cap_uah);
+	if (rc < 0) {
+		pr_err("battery nominal capacity unavailable, rc:%d\n", rc);
+		fg->bp.nom_cap_uah = -EINVAL;
+	}
+
+	if (of_find_property(profile_node, "qcom,therm-coefficients", &len)) {
+		len /= sizeof(u32);
+		if (len == BATT_THERM_NUM_COEFFS) {
+			if (!fg->bp.therm_coeffs) {
+				fg->bp.therm_coeffs = devm_kcalloc(fg->dev,
+					BATT_THERM_NUM_COEFFS, sizeof(u32),
+					GFP_KERNEL);
+				if (!fg->bp.therm_coeffs)
+					return -ENOMEM;
+			}
+		}
+
+		rc = of_property_read_u32_array(profile_node,
+			"qcom,therm-coefficients", fg->bp.therm_coeffs, len);
+		if (rc < 0) {
+			pr_err("Couldn't read therm coefficients, rc:%d\n", rc);
+			devm_kfree(fg->dev, fg->bp.therm_coeffs);
+			fg->bp.therm_coeffs = NULL;
+		}
+
+		rc = of_property_read_u32(profile_node,
+			"qcom,therm-center-offset", &fg->bp.therm_ctr_offset);
+		if (rc < 0) {
+			pr_err("battery therm-center-offset unavailable, rc:%d\n",
+				rc);
+			fg->bp.therm_ctr_offset = -EINVAL;
+		}
+	}
+
+	if (of_find_property(profile_node, "qcom,therm-pull-up", NULL)) {
+		rc = of_property_read_u32(profile_node, "qcom,therm-pull-up",
+				&fg->bp.therm_pull_up_kohms);
+		if (rc < 0) {
+			pr_err("Couldn't read therm-pull-up, rc:%d\n", rc);
+			fg->bp.therm_pull_up_kohms = -EINVAL;
+		}
+	}
+
+	if (of_find_property(profile_node, "qcom,rslow-normal-coeffs", NULL) &&
+		of_find_property(profile_node, "qcom,rslow-low-coeffs", NULL)) {
+		if (!fg->bp.rslow_normal_coeffs) {
+			fg->bp.rslow_normal_coeffs = devm_kcalloc(fg->dev,
+						RSLOW_NUM_COEFFS, sizeof(u32),
+						GFP_KERNEL);
+			if (!fg->bp.rslow_normal_coeffs)
+				return -ENOMEM;
+		}
+
+		if (!fg->bp.rslow_low_coeffs) {
+			fg->bp.rslow_low_coeffs = devm_kcalloc(fg->dev,
+						RSLOW_NUM_COEFFS, sizeof(u32),
+						GFP_KERNEL);
+			if (!fg->bp.rslow_low_coeffs) {
+				devm_kfree(fg->dev, fg->bp.rslow_normal_coeffs);
+				fg->bp.rslow_normal_coeffs = NULL;
+				return -ENOMEM;
+			}
+		}
+
+		rc = fg_parse_dt_property_u32_array(profile_node,
+			"qcom,rslow-normal-coeffs",
+			fg->bp.rslow_normal_coeffs, RSLOW_NUM_COEFFS);
+		if (rc < 0) {
+			devm_kfree(fg->dev, fg->bp.rslow_normal_coeffs);
+			fg->bp.rslow_normal_coeffs = NULL;
+			devm_kfree(fg->dev, fg->bp.rslow_low_coeffs);
+			fg->bp.rslow_low_coeffs = NULL;
+			return rc;
+		}
+
+		rc = fg_parse_dt_property_u32_array(profile_node,
+			"qcom,rslow-low-coeffs",
+			fg->bp.rslow_low_coeffs, RSLOW_NUM_COEFFS);
+		if (rc < 0) {
+			devm_kfree(fg->dev, fg->bp.rslow_normal_coeffs);
+			fg->bp.rslow_normal_coeffs = NULL;
+			devm_kfree(fg->dev, fg->bp.rslow_low_coeffs);
+			fg->bp.rslow_low_coeffs = NULL;
+			return rc;
+		}
+	}
+
+	data = of_get_property(profile_node, "qcom,fg-profile-data", &len);
+	if (!data) {
+		pr_err("No profile data available\n");
+		return -ENODATA;
+	}
+
+	if (len != PROFILE_LEN) {
+		pr_err("battery profile incorrect size: %d\n", len);
+		return -EINVAL;
+	}
+
+	fg->profile_available = true;
+	memcpy(chip->batt_profile, data, len);
+
+	return 0;
+}
+
+static int fg_gen4_bp_params_config(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, i;
+	u8 buf, therm_coeffs[BATT_THERM_NUM_COEFFS * 2];
+	u8 rslow_coeffs[RSLOW_NUM_COEFFS], val, mask;
+	u16 rslow_scalefn;
+
+	if (fg->bp.vbatt_full_mv > 0) {
+		rc = fg_set_constant_chg_voltage(fg,
+				fg->bp.vbatt_full_mv * 1000);
+		if (rc < 0)
+			return rc;
+	}
+
+	if (fg->bp.therm_coeffs) {
+		/* Each coefficient is a 16-bit value */
+		for (i = 0; i < BATT_THERM_NUM_COEFFS; i++) {
+			therm_coeffs[i*2] = fg->bp.therm_coeffs[i] & 0xFF;
+			therm_coeffs[i*2 + 1] = fg->bp.therm_coeffs[i] >> 8;
+		}
+		rc = fg_sram_write(fg, BATT_THERM_COEFF_WORD,
+			BATT_THERM_COEFF_OFFSET, therm_coeffs,
+			BATT_THERM_NUM_COEFFS * 2, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing therm-coeffs, rc=%d\n", rc);
+			return rc;
+		}
+
+		buf = fg->bp.therm_ctr_offset;
+		rc = fg_sram_write(fg, BATT_THERM_CONFIG_WORD,
+			RATIO_CENTER_OFFSET, &buf, 1, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing therm-ctr-offset, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (fg->bp.rslow_normal_coeffs && fg->bp.rslow_low_coeffs) {
+		rc = fg_sram_read(fg, RSLOW_COEFF_DISCHG_WORD,
+				RSLOW_COEFF_LOW_OFFSET, rslow_coeffs,
+				RSLOW_NUM_COEFFS, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Failed to read RLOW_COEFF_DISCHG_WORD rc=%d\n",
+				rc);
+			return rc;
+		}
+
+		/* Read Rslow coefficients back and set the status */
+		for (i = 0; i < RSLOW_NUM_COEFFS; i++) {
+			buf = fg->bp.rslow_low_coeffs[i] & 0xFF;
+			if (rslow_coeffs[i] == buf) {
+				chip->rslow_low = true;
+			} else {
+				chip->rslow_low = false;
+				break;
+			}
+		}
+		fg_dbg(fg, FG_STATUS, "Rslow_low: %d\n", chip->rslow_low);
+	}
+
+	/*
+	 * Since this SRAM word falls inside profile region, configure it after
+	 * the profile is loaded. This parameter doesn't come from battery
+	 * profile DT property.
+	 */
+	if (fg->wa_flags & PM8150B_V1_RSLOW_COMP_WA) {
+		val = 0;
+		mask = BIT(1);
+		rc = fg_sram_masked_write(fg, RSLOW_CONFIG_WORD,
+				RSLOW_CONFIG_OFFSET, mask, val, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing RSLOW_CONFIG_WORD, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (fg->wa_flags & PM8150B_V2_RSLOW_SCALE_FN_WA) {
+		rslow_scalefn = 0x4000;
+		rc = fg_sram_write(fg, RSLOW_SCALE_FN_CHG_V2_WORD,
+				RSLOW_SCALE_FN_CHG_V2_OFFSET,
+				(u8 *)&rslow_scalefn, 2, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing RSLOW_SCALE_FN_CHG_WORD rc=%d\n",
+				rc);
+			return rc;
+		}
+
+		rc = fg_sram_write(fg, RSLOW_SCALE_FN_DISCHG_V2_WORD,
+				RSLOW_SCALE_FN_DISCHG_V2_OFFSET,
+				(u8 *)&rslow_scalefn, 2, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing RSLOW_SCALE_FN_DISCHG_WORD rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (fg->bp.therm_pull_up_kohms > 0) {
+		switch (fg->bp.therm_pull_up_kohms) {
+		case 30:
+			buf = BATT_THERM_PULL_UP_30K;
+			break;
+		case 100:
+			buf = BATT_THERM_PULL_UP_100K;
+			break;
+		case 400:
+			buf = BATT_THERM_PULL_UP_400K;
+			break;
+		default:
+			return -EINVAL;
+		}
+
+		rc = fg_masked_write(fg, ADC_RR_BATT_THERM_BASE_CFG1(fg),
+					BATT_THERM_PULL_UP_MASK, buf);
+		if (rc < 0) {
+			pr_err("failed to write to 0x%04X, rc=%d\n",
+				ADC_RR_BATT_THERM_BASE_CFG1(fg), rc);
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+static void clear_battery_profile(struct fg_dev *fg)
+{
+	u8 val = 0;
+	int rc;
+
+	rc = fg_sram_write(fg, PROFILE_INTEGRITY_WORD,
+			PROFILE_INTEGRITY_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (rc < 0)
+		pr_err("failed to write profile integrity rc=%d\n", rc);
+}
+
+#define PROFILE_LOAD_BIT	BIT(0)
+#define BOOTLOADER_LOAD_BIT	BIT(1)
+#define BOOTLOADER_RESTART_BIT	BIT(2)
+#define HLOS_RESTART_BIT	BIT(3)
+#define FIRST_PROFILE_LOAD_BIT	BIT(4)
+static bool is_profile_load_required(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	u8 buf[PROFILE_COMP_LEN], val;
+	bool profiles_same = false, valid_integrity = false;
+	int rc, i;
+	u8 white_list_values[] = {
+		HLOS_RESTART_BIT,
+		BOOTLOADER_LOAD_BIT,
+		BOOTLOADER_LOAD_BIT | BOOTLOADER_RESTART_BIT,
+		BOOTLOADER_RESTART_BIT | HLOS_RESTART_BIT,
+		BOOTLOADER_LOAD_BIT | FIRST_PROFILE_LOAD_BIT,
+		BOOTLOADER_LOAD_BIT | BOOTLOADER_RESTART_BIT |
+			FIRST_PROFILE_LOAD_BIT,
+		HLOS_RESTART_BIT | BOOTLOADER_RESTART_BIT |
+			FIRST_PROFILE_LOAD_BIT,
+	};
+
+	rc = fg_sram_read(fg, PROFILE_INTEGRITY_WORD,
+			PROFILE_INTEGRITY_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("failed to read profile integrity rc=%d\n", rc);
+		return false;
+	}
+
+	/* Check if integrity bit is set */
+	if (val & PROFILE_LOAD_BIT) {
+		fg_dbg(fg, FG_STATUS, "Battery profile integrity bit is set\n");
+
+		/* Whitelist the values */
+		val &= ~PROFILE_LOAD_BIT;
+		for (i = 0; i < ARRAY_SIZE(white_list_values); i++)  {
+			if (val == white_list_values[i]) {
+				valid_integrity = true;
+				break;
+			}
+		}
+
+		if (!valid_integrity) {
+			val |= PROFILE_LOAD_BIT;
+			pr_warn("Garbage value in profile integrity word: 0x%x\n",
+				val);
+			return true;
+		}
+
+		rc = fg_sram_read(fg, PROFILE_LOAD_WORD, PROFILE_LOAD_OFFSET,
+				buf, PROFILE_COMP_LEN, FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in reading battery profile, rc:%d\n", rc);
+			fg->profile_load_status = PROFILE_SKIPPED;
+			return false;
+		}
+		profiles_same = memcmp(chip->batt_profile, buf,
+					PROFILE_COMP_LEN) == 0;
+		if (profiles_same) {
+			fg_dbg(fg, FG_STATUS, "Battery profile is same, not loading it\n");
+			fg->profile_load_status = PROFILE_LOADED;
+			return false;
+		}
+
+		if (!chip->dt.force_load_profile) {
+			pr_warn("Profiles doesn't match, skipping loading it since force_load_profile is disabled\n");
+			if (fg_profile_dump) {
+				pr_info("FG: loaded profile:\n");
+				dump_sram(fg, buf, PROFILE_LOAD_WORD,
+					PROFILE_COMP_LEN);
+				pr_info("FG: available profile:\n");
+				dump_sram(fg, chip->batt_profile,
+					PROFILE_LOAD_WORD, PROFILE_LEN);
+			}
+			fg->profile_load_status = PROFILE_SKIPPED;
+			return false;
+		}
+
+		fg_dbg(fg, FG_STATUS, "Profiles are different, loading the correct one\n");
+	} else {
+		fg_dbg(fg, FG_STATUS, "Profile integrity bit is not set\n");
+		if (fg_profile_dump) {
+			pr_info("FG: profile to be loaded:\n");
+			dump_sram(fg, chip->batt_profile, PROFILE_LOAD_WORD,
+				PROFILE_LEN);
+		}
+	}
+	return true;
+}
+
+#define SOC_READY_WAIT_TIME_MS	1000
+static int qpnp_fg_gen4_load_profile(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	u8 val, mask, buf[2];
+	int rc;
+
+	rc = fg_masked_write(fg, BATT_SOC_RESTART(fg), RESTART_GO_BIT,
+				0);
+	if (rc < 0) {
+		pr_err("Error in writing to %04x, rc=%d\n",
+			BATT_SOC_RESTART(fg), rc);
+		return rc;
+	}
+
+	/* load battery profile */
+	rc = fg_sram_write(fg, PROFILE_LOAD_WORD, PROFILE_LOAD_OFFSET,
+			chip->batt_profile, PROFILE_LEN, FG_IMA_ATOMIC);
+	if (rc < 0) {
+		pr_err("Error in writing battery profile, rc:%d\n", rc);
+		return rc;
+	}
+
+	/* Enable side loading for voltage and current */
+	val = mask = BIT(0);
+	rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+			SYS_CONFIG_OFFSET, mask, val, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in setting SYS_CONFIG_WORD[0], rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/* Clear first logged main current ADC values */
+	buf[0] = buf[1] = 0;
+	rc = fg_sram_write(fg, FIRST_LOG_CURRENT_v2_WORD,
+			FIRST_LOG_CURRENT_v2_OFFSET, buf, 2,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in clearing FIRST_LOG_CURRENT rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/* Set the profile integrity bit */
+	val = HLOS_RESTART_BIT | PROFILE_LOAD_BIT;
+	rc = fg_sram_write(fg, PROFILE_INTEGRITY_WORD,
+			PROFILE_INTEGRITY_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("failed to write profile integrity rc=%d\n", rc);
+		return rc;
+	}
+
+	chip->last_restart_time = ktime_get();
+	rc = fg_restart(fg, SOC_READY_WAIT_TIME_MS);
+	if (rc < 0) {
+		pr_err("Error in restarting FG, rc=%d\n", rc);
+		return rc;
+	}
+
+	/* Clear side loading for voltage and current */
+	val = 0;
+	mask = BIT(0);
+	rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+			SYS_CONFIG_OFFSET, mask, val, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in clearing SYS_CONFIG_WORD[0], rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static bool is_sdam_cookie_set(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	u8 cookie;
+
+	rc = nvmem_device_read(chip->fg_nvmem, SDAM_COOKIE_OFFSET, 1,
+				&cookie);
+	if (rc < 0) {
+		pr_err("Error in reading SDAM_COOKIE rc=%d\n", rc);
+		return false;
+	}
+
+	fg_dbg(fg, FG_STATUS, "cookie: %x\n", cookie);
+	return (cookie == SDAM_COOKIE);
+}
+
+static void fg_gen4_clear_sdam(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	u8 buf[SDAM_FG_PARAM_LENGTH] = { 0 };
+	int rc;
+
+	/*
+	 * Clear all bytes of SDAM used to store FG parameters when it is first
+	 * profile load so that the junk values would not be used.
+	 */
+	rc = nvmem_device_write(chip->fg_nvmem, SDAM_CYCLE_COUNT_OFFSET,
+			SDAM_FG_PARAM_LENGTH, buf);
+	if (rc < 0)
+		pr_err("Error in clearing SDAM rc=%d\n", rc);
+	else
+		fg_dbg(fg, FG_STATUS, "Cleared SDAM\n");
+}
+
+static void fg_gen4_post_profile_load(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, act_cap_mah;
+	u8 buf[16] = {0};
+
+	/* If SDAM cookie is not set, read back from SRAM and load it in SDAM */
+	if (chip->fg_nvmem && !is_sdam_cookie_set(chip)) {
+		fg_gen4_clear_sdam(chip);
+		rc = fg_sram_read(&chip->fg, CYCLE_COUNT_WORD,
+					CYCLE_COUNT_OFFSET, buf, 16,
+					FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in reading cycle counters from SRAM rc=%d\n",
+				rc);
+		} else {
+			rc = nvmem_device_write(chip->fg_nvmem,
+				SDAM_CYCLE_COUNT_OFFSET, 16, (u8 *)buf);
+			if (rc < 0)
+				pr_err("Error in writing cycle counters to SDAM rc=%d\n",
+					rc);
+		}
+
+		rc = fg_get_sram_prop(fg, FG_SRAM_ACT_BATT_CAP, &act_cap_mah);
+		if (rc < 0) {
+			pr_err("Error in getting learned capacity, rc=%d\n",
+				rc);
+		} else {
+			rc = nvmem_device_write(chip->fg_nvmem,
+				SDAM_CAP_LEARN_OFFSET, 2, (u8 *)&act_cap_mah);
+			if (rc < 0)
+				pr_err("Error in writing learned capacity to SDAM, rc=%d\n",
+					rc);
+		}
+	}
+
+	/* Restore the cycle counters so that it would be valid at this point */
+	rc = restore_cycle_count(chip->counter);
+	if (rc < 0)
+		pr_err("Error in restoring cycle_count, rc=%d\n", rc);
+
+}
+
+static void profile_load_work(struct work_struct *work)
+{
+	struct fg_dev *fg = container_of(work,
+				struct fg_dev,
+				profile_load_work.work);
+	struct fg_gen4_chip *chip = container_of(fg,
+				struct fg_gen4_chip, fg);
+	int64_t nom_cap_uah, learned_cap_uah = 0;
+	u8 val, buf[2];
+	int rc;
+
+	vote(fg->awake_votable, PROFILE_LOAD, true, 0);
+
+	rc = fg_gen4_get_batt_id(chip);
+	if (rc < 0) {
+		pr_err("Error in getting battery id, rc:%d\n", rc);
+		goto out;
+	}
+
+	rc = fg_gen4_get_batt_profile(fg);
+	if (rc < 0) {
+		fg->profile_load_status = PROFILE_MISSING;
+		pr_warn("profile for batt_id=%dKOhms not found..using OTP, rc:%d\n",
+			fg->batt_id_ohms / 1000, rc);
+		goto out;
+	}
+
+	if (!fg->profile_available)
+		goto out;
+
+	if (!is_profile_load_required(chip))
+		goto done;
+
+	clear_cycle_count(chip->counter);
+	if (chip->fg_nvmem && !is_sdam_cookie_set(chip))
+		fg_gen4_clear_sdam(chip);
+
+	fg_dbg(fg, FG_STATUS, "profile loading started\n");
+
+	rc = qpnp_fg_gen4_load_profile(chip);
+	if (rc < 0)
+		goto out;
+
+	fg_dbg(fg, FG_STATUS, "SOC is ready\n");
+	fg->profile_load_status = PROFILE_LOADED;
+
+	if (fg->wa_flags & PM8150B_V1_DMA_WA)
+		msleep(1000);
+
+	if (learned_cap_uah == 0) {
+		/*
+		 * Whenever battery profile is loaded, read nominal capacity and
+		 * write it to actual (or aged) capacity as it is outside the
+		 * profile region and might contain OTP values. learned_cap_uah
+		 * would have non-zero value if multiple profile loading is
+		 * enabled and a profile got loaded already.
+		 */
+		rc = fg_sram_read(fg, NOM_CAP_WORD, NOM_CAP_OFFSET, buf, 2,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in reading %04x[%d] rc=%d\n",
+				NOM_CAP_WORD, NOM_CAP_OFFSET, rc);
+		} else {
+			nom_cap_uah = (buf[0] | buf[1] << 8) * 1000;
+			rc = fg_gen4_store_learned_capacity(chip, nom_cap_uah);
+			if (rc < 0)
+				pr_err("Error in writing to ACT_BATT_CAP rc=%d\n",
+					rc);
+		}
+	}
+done:
+	rc = fg_sram_read(fg, PROFILE_INTEGRITY_WORD,
+			PROFILE_INTEGRITY_OFFSET, &val, 1, FG_IMA_DEFAULT);
+	if (!rc && (val & FIRST_PROFILE_LOAD_BIT)) {
+		fg_dbg(fg, FG_STATUS, "First profile load bit is set\n");
+	}
+
+	fg_gen4_post_profile_load(chip);
+
+	rc = fg_gen4_bp_params_config(fg);
+	if (rc < 0)
+		pr_err("Error in configuring battery profile params, rc:%d\n",
+			rc);
+
+	rc = fg_gen4_get_nominal_capacity(chip, &nom_cap_uah);
+	if (!rc) {
+		rc = cap_learning_post_profile_init(chip->cl, nom_cap_uah);
+		if (rc < 0)
+			pr_err("Error in cap_learning_post_profile_init rc=%d\n",
+				rc);
+	}
+
+	batt_psy_initialized(fg);
+	fg_notify_charger(fg);
+
+	fg_dbg(fg, FG_STATUS, "profile loaded successfully");
+out:
+	if (!chip->esr_fast_calib || is_debug_batt_id(fg)) {
+		/* If it is debug battery, then disable ESR fast calibration */
+		fg_gen4_esr_fast_calib_config(chip, false);
+		chip->esr_fast_calib = false;
+	}
+
+	fg->soc_reporting_ready = true;
+	vote(fg->awake_votable, ESR_FCC_VOTER, true, 0);
+	schedule_delayed_work(&chip->pl_enable_work, msecs_to_jiffies(5000));
+	vote(fg->awake_votable, PROFILE_LOAD, false, 0);
+	if (!work_pending(&fg->status_change_work)) {
+		pm_stay_awake(fg->dev);
+		schedule_work(&fg->status_change_work);
+	}
+
+	rc = fg_gen4_validate_soc_scale_mode(chip);
+	if (rc < 0)
+		pr_err("Failed to validate SOC scale mode, rc=%d\n", rc);
+}
+
+static void get_batt_psy_props(struct fg_dev *fg)
+{
+	union power_supply_propval prop = {0, };
+	int rc;
+
+	if (!batt_psy_initialized(fg))
+		return;
+
+	rc = power_supply_get_property(fg->batt_psy, POWER_SUPPLY_PROP_STATUS,
+			&prop);
+	if (rc < 0) {
+		pr_err("Error in getting charging status, rc=%d\n", rc);
+		return;
+	}
+
+	fg->charge_status = prop.intval;
+	fg->charge_done = (prop.intval == POWER_SUPPLY_STATUS_FULL);
+
+	rc = power_supply_get_property(fg->batt_psy, POWER_SUPPLY_PROP_HEALTH,
+		&prop);
+	if (rc < 0) {
+		pr_err("Error in getting battery health, rc=%d\n", rc);
+		return;
+	}
+
+	fg->health = prop.intval;
+}
+
+static int fg_gen4_configure_full_soc(struct fg_dev *fg, int bsoc)
+{
+	int rc;
+	u8 full_soc[2] = {0xFF, 0xFF}, buf[2];
+
+	/*
+	 * Once SOC masking condition is cleared, FULL_SOC and MONOTONIC_SOC
+	 * needs to be updated to reflect the same. Write battery SOC to
+	 * FULL_SOC and write a full value to MONOTONIC_SOC.
+	 */
+	fg_encode(fg->sp, FG_SRAM_FULL_SOC, bsoc, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_FULL_SOC].addr_word,
+			fg->sp[FG_SRAM_FULL_SOC].addr_byte, buf,
+			fg->sp[FG_SRAM_FULL_SOC].len, FG_IMA_ATOMIC);
+	if (rc < 0) {
+		pr_err("failed to write full_soc rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_MONOTONIC_SOC].addr_word,
+			fg->sp[FG_SRAM_MONOTONIC_SOC].addr_byte, full_soc,
+			fg->sp[FG_SRAM_MONOTONIC_SOC].len, FG_IMA_ATOMIC);
+	if (rc < 0) {
+		pr_err("failed to write monotonic_soc rc=%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int fg_gen4_esr_fcc_config(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	bool cp_en = false, esr_fcc_ctrl_en;
+	u8 val, mask;
+
+	if (chip->cp_disable_votable)
+		cp_en = !get_effective_result(chip->cp_disable_votable);
+
+	fg_dbg(fg, FG_POWER_SUPPLY, "chg_sts: %d cp_en: %d esr_fcc_ctrl_en: %d\n",
+		fg->charge_status, cp_en,
+		chip->esr_fcc_ctrl_en);
+
+	if (fg->charge_status == POWER_SUPPLY_STATUS_CHARGING && cp_en) {
+		if (chip->esr_fcc_ctrl_en)
+			return 0;
+
+		/*
+		 * When parallel charging or Qnovo or Charge pump is enabled,
+		 * configure ESR FCC to 300mA to trigger an ESR pulse. Without
+		 * this, FG can request the main charger to increase FCC when it
+		 * is supposed to decrease it.
+		 */
+		val = GEN4_ESR_FCC_300MA << GEN4_ESR_FAST_CRG_IVAL_SHIFT |
+			ESR_FAST_CRG_CTL_EN_BIT;
+		esr_fcc_ctrl_en = true;
+	} else {
+		if (!chip->esr_fcc_ctrl_en)
+			return 0;
+
+		/*
+		 * If we're here, then it means either the device is not in
+		 * charging state or parallel charging / Qnovo / Charge pump is
+		 * disabled. Disable ESR fast charge current control in SW.
+		 */
+		val = GEN4_ESR_FCC_1A << GEN4_ESR_FAST_CRG_IVAL_SHIFT;
+		esr_fcc_ctrl_en = false;
+	}
+
+	mask = GEN4_ESR_FAST_CRG_IVAL_MASK | ESR_FAST_CRG_CTL_EN_BIT;
+	rc = fg_masked_write(fg, BATT_INFO_ESR_FAST_CRG_CFG(fg), mask, val);
+	if (rc < 0) {
+		pr_err("Error in writing to %04x, rc=%d\n",
+			BATT_INFO_ESR_FAST_CRG_CFG(fg), rc);
+		return rc;
+	}
+
+	chip->esr_fcc_ctrl_en = esr_fcc_ctrl_en;
+	fg_dbg(fg, FG_STATUS, "esr_fcc_ctrl_en set to %d\n",
+		chip->esr_fcc_ctrl_en);
+	return 0;
+}
+
+static int fg_gen4_configure_esr_cal_soc(struct fg_dev *fg, int soc_min,
+					int soc_max)
+{
+	int rc;
+	u8 buf[2];
+
+	fg_encode(fg->sp, FG_SRAM_ESR_CAL_SOC_MIN, soc_min, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ESR_CAL_SOC_MIN].addr_word,
+			fg->sp[FG_SRAM_ESR_CAL_SOC_MIN].addr_byte, buf,
+			fg->sp[FG_SRAM_ESR_CAL_SOC_MIN].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_CAL_SOC_MIN, rc=%d\n", rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_ESR_CAL_SOC_MAX, soc_max, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ESR_CAL_SOC_MAX].addr_word,
+			fg->sp[FG_SRAM_ESR_CAL_SOC_MAX].addr_byte, buf,
+			fg->sp[FG_SRAM_ESR_CAL_SOC_MAX].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_CAL_SOC_MAX, rc=%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int fg_gen4_configure_esr_cal_temp(struct fg_dev *fg, int temp_min,
+					int temp_max)
+{
+	int rc;
+	u8 buf[2];
+
+	fg_encode(fg->sp, FG_SRAM_ESR_CAL_TEMP_MIN, temp_min, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ESR_CAL_TEMP_MIN].addr_word,
+			fg->sp[FG_SRAM_ESR_CAL_TEMP_MIN].addr_byte, buf,
+			fg->sp[FG_SRAM_ESR_CAL_TEMP_MIN].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_CAL_TEMP_MIN, rc=%d\n", rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_ESR_CAL_TEMP_MAX, temp_max, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ESR_CAL_TEMP_MAX].addr_word,
+			fg->sp[FG_SRAM_ESR_CAL_TEMP_MAX].addr_byte, buf,
+			fg->sp[FG_SRAM_ESR_CAL_TEMP_MAX].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_CAL_TEMP_MAX, rc=%d\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+#define ESR_CAL_TEMP_MIN	-127
+#define ESR_CAL_TEMP_MAX	127
+static int fg_gen4_esr_fast_calib_config(struct fg_gen4_chip *chip, bool en)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, esr_timer_chg_init, esr_timer_chg_max, esr_timer_dischg_init,
+		esr_timer_dischg_max, esr_fast_cal_ms, esr_cal_soc_min,
+		esr_cal_soc_max, esr_cal_temp_min, esr_cal_temp_max;
+	u8 val, mask;
+
+	esr_timer_chg_init = esr_timer_chg_max = -EINVAL;
+	esr_timer_dischg_init = esr_timer_dischg_max = -EINVAL;
+	if (en) {
+		esr_timer_chg_init = chip->dt.esr_timer_chg_fast[TIMER_RETRY];
+		esr_timer_chg_max = chip->dt.esr_timer_chg_fast[TIMER_MAX];
+		esr_timer_dischg_init =
+				chip->dt.esr_timer_dischg_fast[TIMER_RETRY];
+		esr_timer_dischg_max =
+				chip->dt.esr_timer_dischg_fast[TIMER_MAX];
+
+		esr_cal_soc_min = 0;
+		esr_cal_soc_max = FULL_SOC_RAW;
+		esr_cal_temp_min = ESR_CAL_TEMP_MIN;
+		esr_cal_temp_max = ESR_CAL_TEMP_MAX;
+
+		vote(chip->delta_esr_irq_en_votable, DELTA_ESR_IRQ_VOTER,
+			true, 0);
+		chip->esr_fast_calib_done = false;
+	} else {
+		chip->esr_fast_calib_done = true;
+
+		esr_timer_chg_init = chip->dt.esr_timer_chg_slow[TIMER_RETRY];
+		esr_timer_chg_max = chip->dt.esr_timer_chg_slow[TIMER_MAX];
+		esr_timer_dischg_init =
+				chip->dt.esr_timer_dischg_slow[TIMER_RETRY];
+		esr_timer_dischg_max =
+				chip->dt.esr_timer_dischg_slow[TIMER_MAX];
+
+		esr_cal_soc_min = chip->dt.esr_cal_soc_thresh[0];
+		esr_cal_soc_max = chip->dt.esr_cal_soc_thresh[1];
+		esr_cal_temp_min = chip->dt.esr_cal_temp_thresh[0];
+		esr_cal_temp_max = chip->dt.esr_cal_temp_thresh[1];
+
+		vote(chip->delta_esr_irq_en_votable, DELTA_ESR_IRQ_VOTER,
+			false, 0);
+	}
+
+	rc = fg_set_esr_timer(fg, esr_timer_chg_init, esr_timer_chg_max, true,
+				FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in setting ESR charge timer, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = fg_set_esr_timer(fg, esr_timer_dischg_init, esr_timer_dischg_max,
+				false, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in setting ESR discharge timer, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = fg_gen4_configure_esr_cal_soc(fg, esr_cal_soc_min,
+			esr_cal_soc_max);
+	if (rc < 0) {
+		pr_err("Error in configuring SOC thresholds, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	rc = fg_gen4_configure_esr_cal_temp(fg, esr_cal_temp_min,
+			esr_cal_temp_max);
+	if (rc < 0) {
+		pr_err("Error in configuring temperature thresholds, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	/*
+	 * Disable ESR discharging timer and ESR pulsing during
+	 * discharging when ESR fast calibration is disabled. Otherwise, keep
+	 * it enabled so that ESR pulses can happen during discharging.
+	 */
+	val = en ? BIT(6) | BIT(7) : 0;
+	mask = BIT(6) | BIT(7);
+	rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+			SYS_CONFIG_OFFSET, mask, val, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing SYS_CONFIG_WORD, rc=%d\n", rc);
+		return rc;
+	}
+
+	/*
+	 * esr_fast_cal_timer won't be initialized if esr_fast_calib is
+	 * not enabled. Hence don't start/cancel the timer.
+	 */
+	if (!chip->esr_fast_calib)
+		goto out;
+
+	if (en) {
+		/* Set ESR fast calibration timer to 50 seconds as default */
+		esr_fast_cal_ms = 50000;
+		if (chip->dt.esr_timer_chg_fast > 0 &&
+			chip->dt.delta_esr_disable_count > 0)
+			esr_fast_cal_ms = 3 * chip->dt.delta_esr_disable_count *
+				chip->dt.esr_timer_chg_fast[TIMER_MAX] * 1000;
+
+		alarm_start_relative(&chip->esr_fast_cal_timer,
+					ms_to_ktime(esr_fast_cal_ms));
+	} else {
+		alarm_cancel(&chip->esr_fast_cal_timer);
+	}
+
+out:
+	fg_dbg(fg, FG_STATUS, "%sabling ESR fast calibration\n",
+		en ? "En" : "Dis");
+	return 0;
+}
+
+#define IBATT_TAU_MASK	GENMASK(3, 0)
+static int fg_gen4_set_vbatt_tau(struct fg_gen4_chip *chip, u8 vbatt_tau)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	u8 buf;
+
+	rc = fg_sram_read(fg, fg->sp[FG_SRAM_VBAT_TAU].addr_word,
+			fg->sp[FG_SRAM_VBAT_TAU].addr_byte,
+			&buf, fg->sp[FG_SRAM_VBAT_TAU].len,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading Vbatt_tau, rc=%d\n", rc);
+		return rc;
+	}
+
+	buf &= IBATT_TAU_MASK;
+	buf |= vbatt_tau << 4;
+	rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_VBAT_TAU].addr_word,
+			fg->sp[FG_SRAM_VBAT_TAU].addr_byte,
+			&buf, fg->sp[FG_SRAM_VBAT_TAU].len,
+			FG_IMA_DEFAULT);
+	if (rc < 0)
+		pr_err("Error in writing Vbatt_tau, rc=%d\n", rc);
+
+	return rc;
+}
+
+static int fg_gen4_enter_soc_scale(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, soc;
+
+	rc = fg_gen4_get_prop_capacity(fg, &soc);
+	if (rc < 0) {
+		pr_err("Failed to get capacity, rc =%d\n", rc);
+		return rc;
+	}
+
+	/* Set entry FVS SOC equal to current H/W reported SOC */
+	chip->soc_scale_msoc = chip->prev_soc_scale_msoc = soc;
+	chip->scale_timer = chip->dt.scale_timer_ms;
+	/*
+	 * Calculate the FVS slope to linearly calculate SOC
+	 * based on filtered battery voltage.
+	 */
+	chip->soc_scale_slope =
+			DIV_ROUND_CLOSEST(chip->vbatt_res,
+					chip->soc_scale_msoc);
+	if (chip->soc_scale_slope <= 0) {
+		pr_err("Error in slope calculated = %d\n",
+			chip->soc_scale_slope);
+		return -EINVAL;
+	}
+
+	chip->soc_scale_mode = true;
+	fg_dbg(fg, FG_FVSS, "Enter FVSS mode, SOC=%d slope=%d timer=%d\n", soc,
+		chip->soc_scale_slope, chip->scale_timer);
+	alarm_start_relative(&chip->soc_scale_alarm_timer,
+				ms_to_ktime(chip->scale_timer));
+
+	return 0;
+}
+
+static void fg_gen4_write_scale_msoc(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int soc_raw, rc;
+
+	if (!fg->charge_full) {
+		soc_raw = DIV_ROUND_CLOSEST(chip->soc_scale_msoc * 0xFFFF,
+						100);
+		rc = fg_sram_write(fg, fg->sp[FG_SRAM_MONOTONIC_SOC].addr_word,
+				fg->sp[FG_SRAM_MONOTONIC_SOC].addr_byte,
+				(u8 *)&soc_raw,
+				fg->sp[FG_SRAM_MONOTONIC_SOC].len,
+				FG_IMA_ATOMIC);
+		if (rc < 0) {
+			pr_err("failed to write monotonic_soc rc=%d\n", rc);
+			chip->soc_scale_mode = false;
+		}
+	}
+}
+
+static void fg_gen4_exit_soc_scale(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+
+	if (chip->soc_scale_mode) {
+		alarm_cancel(&chip->soc_scale_alarm_timer);
+		if (work_busy(&chip->soc_scale_work) != WORK_BUSY_RUNNING)
+			cancel_work_sync(&chip->soc_scale_work);
+
+		/* While exiting soc_scale_mode, Update MSOC register */
+		fg_gen4_write_scale_msoc(chip);
+	}
+
+	chip->soc_scale_mode = false;
+	fg_dbg(fg, FG_FVSS, "Exit FVSS mode, work_status=%d\n",
+				work_busy(&chip->soc_scale_work));
+}
+
+static int fg_gen4_validate_soc_scale_mode(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+
+	if (!chip->dt.soc_scale_mode)
+		return 0;
+
+	rc = fg_gen4_get_prop_soc_scale(chip);
+	if (rc < 0) {
+		pr_err("Failed to get soc scale props\n");
+		goto fail_soc_scale;
+	}
+
+	rc = fg_get_msoc(fg, &chip->msoc_actual);
+	if (rc < 0) {
+		pr_err("Failed to get msoc rc=%d\n", rc);
+		goto fail_soc_scale;
+	}
+
+	if (!chip->soc_scale_mode && fg->charge_status ==
+		POWER_SUPPLY_STATUS_DISCHARGING &&
+		chip->vbatt_avg < chip->dt.vbatt_scale_thr_mv) {
+		rc = fg_gen4_enter_soc_scale(chip);
+		if (rc < 0) {
+			pr_err("Failed to enter SOC scale mode\n");
+			goto fail_soc_scale;
+		}
+	} else if (chip->soc_scale_mode && chip->current_now < 0) {
+		/*
+		 * Stay in SOC scale mode till H/W SOC catch scaled SOC
+		 * while charging.
+		 */
+		if (chip->msoc_actual >= chip->soc_scale_msoc)
+			fg_gen4_exit_soc_scale(chip);
+	}
+
+	return 0;
+fail_soc_scale:
+	fg_gen4_exit_soc_scale(chip);
+	return rc;
+}
+
+static int fg_gen4_set_vbatt_low(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, vbatt_flt;
+
+	if (chip->soc_scale_mode) {
+		rc = fg_get_sram_prop(fg, FG_SRAM_VBAT_FLT,
+					&vbatt_flt);
+		if (rc < 0) {
+			pr_err("failed to get filtered battery voltage, rc=%d\n",
+				rc);
+			/*
+			 * If we fail here, exit FVSS mode
+			 * and set Vbatt low flag true to report
+			 * 0 SOC
+			 */
+			fg_gen4_exit_soc_scale(chip);
+			chip->vbatt_low = true;
+			return 0;
+		}
+
+		vbatt_flt /= 1000;
+		if (vbatt_flt < chip->dt.empty_volt_mv ||
+		    vbatt_flt > (fg->bp.float_volt_uv/1000)) {
+			pr_err("Filtered Vbatt is not in range %d\n",
+			       vbatt_flt);
+			/*
+			 * If we fail here, exit FVSS mode
+			 * and set Vbatt low flag true to report
+			 * 0 SOC
+			 */
+			fg_gen4_exit_soc_scale(chip);
+			chip->vbatt_low = true;
+			return 0;
+		}
+
+		if (vbatt_flt <= chip->dt.cutoff_volt_mv)
+			chip->vbatt_low = true;
+	} else {
+		/* Set the flag to show 0% */
+		chip->vbatt_low = true;
+	}
+
+	return 0;
+}
+
+/* All irq handlers below this */
+
+static irqreturn_t fg_mem_attn_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	complete_all(&chip->mem_attn);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_mem_xcp_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	u8 status;
+	int rc;
+
+	rc = fg_read(fg, MEM_IF_INT_RT_STS(fg), &status, 1);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			MEM_IF_INT_RT_STS(fg), rc);
+		return IRQ_HANDLED;
+	}
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered, status:%d\n", irq, status);
+
+	mutex_lock(&fg->sram_rw_lock);
+	rc = fg_clear_dma_errors_if_any(fg);
+	if (rc < 0)
+		pr_err("Error in clearing DMA error, rc=%d\n", rc);
+
+	if (status & MEM_XCP_BIT) {
+		rc = fg_clear_ima_errors_if_any(fg, true);
+		if (rc < 0 && rc != -EAGAIN)
+			pr_err("Error in checking IMA errors rc:%d\n", rc);
+	}
+
+	mutex_unlock(&fg->sram_rw_lock);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_delta_esr_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int esr_uohms, rc;
+
+	rc = fg_get_battery_resistance(fg, &esr_uohms);
+	if (rc < 0)
+		return IRQ_HANDLED;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered esr_uohms: %d\n", irq, esr_uohms);
+
+	if (chip->esr_fast_calib) {
+		vote(fg->awake_votable, ESR_CALIB, true, 0);
+		schedule_work(&chip->esr_calib_work);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_vbatt_low_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, vbatt_mv, msoc_raw;
+	s64 time_us;
+
+	schedule_work(&chip->vbat_sync_work);
+	rc = fg_get_battery_voltage(fg, &vbatt_mv);
+	if (rc < 0)
+		return IRQ_HANDLED;
+
+	vbatt_mv /= 1000;
+	rc = fg_get_msoc_raw(fg, &msoc_raw);
+	if (rc < 0)
+		return IRQ_HANDLED;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered vbatt_mv: %d msoc_raw:%d\n", irq,
+		vbatt_mv, msoc_raw);
+
+	if (!fg->soc_reporting_ready) {
+		fg_dbg(fg, FG_IRQ, "SOC reporting is not ready\n");
+		return IRQ_HANDLED;
+	}
+
+	if (chip->last_restart_time) {
+		time_us = ktime_us_delta(ktime_get(), chip->last_restart_time);
+		if (time_us < 10000000) {
+			fg_dbg(fg, FG_IRQ, "FG restarted before %lld us\n",
+				time_us);
+			return IRQ_HANDLED;
+		}
+	}
+
+	if (vbatt_mv < chip->dt.cutoff_volt_mv) {
+		if (chip->dt.rapid_soc_dec_en) {
+			/*
+			 * Set vbat_low debounce window to avoid shutdown in low temperature and high
+			 * current scene, we set the counter to maxium 5, if fg_vbatt_low_irq trigger
+			 * exceed 5 times, decrease soc to 0% very rapidly.
+			 */
+			fg->vbat_critical_low_count++;
+			if (fg->vbat_critical_low_count < EMPTY_DEBOUNCE_TIME_COUNT_MAX
+					&& vbatt_mv > VBAT_CRITICAL_LOW_THR) {
+				pr_info("fg->vbat_critical_low_count:%d\n",
+						fg->vbat_critical_low_count);
+				if (batt_psy_initialized(fg))
+					power_supply_changed(fg->batt_psy);
+				return IRQ_HANDLED;
+			}
+			/*
+			 * Set this flag so that slope limiter coefficient
+			 * cannot be configured during rapid SOC decrease.
+			 */
+			chip->rapid_soc_dec_en = true;
+
+			rc = fg_gen4_rapid_soc_config(chip, true);
+			if (rc < 0)
+				pr_err("Error in configuring for rapid SOC reduction rc:%d\n",
+					rc);
+		} else {
+			fg_gen4_set_vbatt_low(chip);
+		}
+	}
+
+	if (batt_psy_initialized(fg))
+		power_supply_changed(fg->batt_psy);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_batt_missing_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	u8 status;
+	int rc;
+
+	rc = fg_read(fg, ADC_RR_INT_RT_STS(fg), &status, 1);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			ADC_RR_INT_RT_STS(fg), rc);
+		return IRQ_HANDLED;
+	}
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered sts:%d\n", irq, status);
+	fg->battery_missing = (status & ADC_RR_BT_MISS_BIT);
+
+	if (fg->battery_missing) {
+		fg->profile_available = false;
+		fg->profile_load_status = PROFILE_NOT_LOADED;
+		fg->soc_reporting_ready = false;
+		fg->batt_id_ohms = -EINVAL;
+
+		cancel_delayed_work_sync(&chip->pl_enable_work);
+		vote(fg->awake_votable, ESR_FCC_VOTER, false, 0);
+		if (chip->pl_disable_votable)
+			vote(chip->pl_disable_votable, ESR_FCC_VOTER, true, 0);
+		if (chip->cp_disable_votable)
+			vote(chip->cp_disable_votable, ESR_FCC_VOTER, true, 0);
+		return IRQ_HANDLED;
+	}
+
+	clear_battery_profile(fg);
+	schedule_delayed_work(&fg->profile_load_work, 0);
+
+	if (fg->fg_psy)
+		power_supply_changed(fg->fg_psy);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_batt_temp_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_delta_batt_temp_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, batt_temp;
+
+	rc = fg_gen4_get_battery_temp(fg, &batt_temp);
+	if (rc < 0) {
+		pr_err("Error in getting batt_temp\n");
+		return IRQ_HANDLED;
+	}
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered batt_temp:%d\n", irq, batt_temp);
+
+	rc = fg_gen4_slope_limit_config(chip, batt_temp);
+	if (rc < 0)
+		pr_err("Error in configuring slope limiter rc:%d\n", rc);
+
+	rc = fg_gen4_adjust_ki_coeff_full_soc(chip, batt_temp);
+	if (rc < 0)
+		pr_err("Error in configuring ki_coeff_full_soc rc:%d\n", rc);
+
+	if (abs(fg->last_batt_temp - batt_temp) > 30)
+		pr_warn("Battery temperature last:%d current: %d\n",
+			fg->last_batt_temp, batt_temp);
+
+	if (fg->last_batt_temp != batt_temp)
+		fg->last_batt_temp = batt_temp;
+
+	if (batt_psy_initialized(fg))
+		power_supply_changed(fg->batt_psy);
+
+	fg_gen4_update_rslow_coeff(fg, batt_temp);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_soc_ready_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	complete_all(&fg->soc_ready);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_soc_update_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	complete_all(&fg->soc_update);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_delta_bsoc_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+
+	return IRQ_HANDLED;
+}
+
+#define CENTI_FULL_SOC		10000
+
+static irqreturn_t fg_delta_msoc_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, batt_soc, batt_temp, msoc_raw;
+	bool input_present = is_input_present(fg);
+	u32 batt_soc_cp;
+
+	rc = fg_get_msoc_raw(fg, &msoc_raw);
+	if (!rc)
+		fg_dbg(fg, FG_IRQ, "irq %d triggered msoc_raw: %d\n", irq,
+			msoc_raw);
+
+	get_batt_psy_props(fg);
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_BATT_SOC, &batt_soc);
+	if (rc < 0)
+		pr_err("Failed to read battery soc rc: %d\n", rc);
+	else
+		cycle_count_update(chip->counter, (u32)batt_soc >> 24,
+			fg->charge_status, fg->charge_done,
+				input_present);
+
+	rc = fg_gen4_get_battery_temp(fg, &batt_temp);
+	if (rc < 0) {
+		pr_err("Failed to read battery temp rc: %d\n", rc);
+	} else {
+		if (chip->cl->active) {
+			batt_soc_cp = div64_u64(
+					(u64)(u32)batt_soc * CENTI_FULL_SOC,
+					BATT_SOC_32BIT);
+			cap_learning_update(chip->cl, batt_temp, batt_soc_cp,
+				fg->charge_status, fg->charge_done,
+				input_present, 0);
+		}
+
+		rc = fg_gen4_slope_limit_config(chip, batt_temp);
+		if (rc < 0)
+			pr_err("Error in configuring slope limiter rc:%d\n",
+				rc);
+	}
+
+	rc = fg_gen4_adjust_ki_coeff_dischg(fg);
+	if (rc < 0)
+		pr_err("Error in adjusting ki_coeff_dischg, rc=%d\n", rc);
+
+	/*
+	 * If ESR fast calibration is done even before 3 delta ESR interrupts
+	 * had fired, then it is possibly a failed attempt. In such cases,
+	 * retry ESR fast calibration once again. This will get restored to
+	 * normal config once the timer expires or delta ESR interrupt count
+	 * reaches the threshold.
+	 */
+	if (chip->esr_fast_calib && chip->esr_fast_calib_done &&
+		(chip->delta_esr_count < 3) && !chip->esr_fast_calib_retry) {
+		rc = fg_gen4_esr_fast_calib_config(chip, true);
+		if (rc < 0)
+			pr_err("Error in configuring esr_fast_calib, rc=%d\n",
+				rc);
+		else
+			chip->esr_fast_calib_retry = true;
+	}
+
+	rc = fg_gen4_validate_soc_scale_mode(chip);
+	if (rc < 0)
+		pr_err("Failed to validate SOC scale mode, rc=%d\n", rc);
+
+	if (batt_psy_initialized(fg))
+		power_supply_changed(fg->batt_psy);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_empty_soc_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	if (batt_psy_initialized(fg))
+		power_supply_changed(fg->batt_psy);
+
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_soc_irq_handler(int irq, void *data)
+{
+	struct fg_dev *fg = data;
+
+	fg_dbg(fg, FG_IRQ, "irq %d triggered\n", irq);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t fg_dummy_irq_handler(int irq, void *data)
+{
+	pr_debug("irq %d triggered\n", irq);
+	return IRQ_HANDLED;
+}
+
+static struct fg_irq_info fg_irqs[FG_GEN4_IRQ_MAX] = {
+	/* BATT_SOC irqs */
+	[MSOC_FULL_IRQ] = {
+		.name		= "msoc-full",
+		.handler	= fg_soc_irq_handler,
+	},
+	[MSOC_HIGH_IRQ] = {
+		.name		= "msoc-high",
+		.handler	= fg_soc_irq_handler,
+		.wakeable	= true,
+	},
+	[MSOC_EMPTY_IRQ] = {
+		.name		= "msoc-empty",
+		.handler	= fg_empty_soc_irq_handler,
+		.wakeable	= true,
+	},
+	[MSOC_LOW_IRQ] = {
+		.name		= "msoc-low",
+		.handler	= fg_soc_irq_handler,
+		.wakeable	= true,
+	},
+	[MSOC_DELTA_IRQ] = {
+		.name		= "msoc-delta",
+		.handler	= fg_delta_msoc_irq_handler,
+		.wakeable	= true,
+	},
+	[BSOC_DELTA_IRQ] = {
+		.name		= "bsoc-delta",
+		.handler	= fg_delta_bsoc_irq_handler,
+		.wakeable	= true,
+	},
+	[SOC_READY_IRQ] = {
+		.name		= "soc-ready",
+		.handler	= fg_soc_ready_irq_handler,
+		.wakeable	= true,
+	},
+	[SOC_UPDATE_IRQ] = {
+		.name		= "soc-update",
+		.handler	= fg_soc_update_irq_handler,
+	},
+	/* BATT_INFO irqs */
+	[ESR_DELTA_IRQ] = {
+		.name		= "esr-delta",
+		.handler	= fg_delta_esr_irq_handler,
+		.wakeable	= true,
+	},
+	[VBATT_LOW_IRQ] = {
+		.name		= "vbatt-low",
+		.handler	= fg_vbatt_low_irq_handler,
+		.wakeable	= true,
+	},
+	[VBATT_PRED_DELTA_IRQ] = {
+		.name		= "vbatt-pred-delta",
+		.handler	= fg_dummy_irq_handler,
+	},
+	/* MEM_IF irqs */
+	[MEM_ATTN_IRQ] = {
+		.name		= "mem-attn",
+		.handler	= fg_mem_attn_irq_handler,
+		.wakeable	= true,
+	},
+	[DMA_GRANT_IRQ] = {
+		.name		= "dma-grant",
+		.handler	= fg_dummy_irq_handler,
+		.wakeable	= true,
+	},
+	[MEM_XCP_IRQ] = {
+		.name		= "ima-xcp",
+		.handler	= fg_mem_xcp_irq_handler,
+		.wakeable	= true,
+	},
+	[DMA_XCP_IRQ] = {
+		.name		= "dma-xcp",
+		.handler	= fg_dummy_irq_handler,
+		.wakeable	= true,
+	},
+	[IMA_RDY_IRQ] = {
+		.name		= "ima-rdy",
+		.handler	= fg_dummy_irq_handler,
+	},
+	/* ADC_RR irqs */
+	[BATT_TEMP_COLD_IRQ] = {
+		.name		= "batt-temp-cold",
+		.handler	= fg_batt_temp_irq_handler,
+		.wakeable	= true,
+	},
+	[BATT_TEMP_HOT_IRQ] = {
+		.name		= "batt-temp-hot",
+		.handler	= fg_batt_temp_irq_handler,
+		.wakeable	= true,
+	},
+	[BATT_TEMP_DELTA_IRQ] = {
+		.name		= "batt-temp-delta",
+		.handler	= fg_delta_batt_temp_irq_handler,
+		.wakeable	= true,
+	},
+	[BATT_ID_IRQ] = {
+		.name		= "batt-id",
+		.handler	= fg_dummy_irq_handler,
+	},
+	[BATT_MISSING_IRQ] = {
+		.name		= "batt-missing",
+		.handler	= fg_batt_missing_irq_handler,
+		.wakeable	= true,
+	},
+};
+
+static enum alarmtimer_restart fg_esr_fast_cal_timer(struct alarm *alarm,
+							ktime_t time)
+{
+	struct fg_gen4_chip *chip = container_of(alarm, struct fg_gen4_chip,
+					esr_fast_cal_timer);
+	struct fg_dev *fg = &chip->fg;
+
+	if (!chip->esr_fast_calib_done) {
+		fg_dbg(fg, FG_STATUS, "ESR fast calibration timer expired\n");
+
+		/*
+		 * We cannot vote for awake votable here as that takes
+		 * a mutex lock and this is executed in an atomic context.
+		 */
+		pm_stay_awake(fg->dev);
+		chip->esr_fast_cal_timer_expired = true;
+		schedule_work(&chip->esr_calib_work);
+	}
+
+	return ALARMTIMER_NORESTART;
+}
+
+static void esr_calib_work(struct work_struct *work)
+{
+	struct fg_gen4_chip *chip = container_of(work, struct fg_gen4_chip,
+				    esr_calib_work);
+	struct fg_dev *fg = &chip->fg;
+	int rc, fg_esr_meas_diff;
+	s16 esr_raw, esr_char_raw, esr_delta, esr_meas_diff, esr_filtered;
+	u8 buf[2];
+
+	mutex_lock(&chip->esr_calib_lock);
+
+	if (chip->delta_esr_count > chip->dt.delta_esr_disable_count ||
+		chip->esr_fast_calib_done) {
+		fg_dbg(fg, FG_STATUS, "delta_esr_count: %d esr_fast_calib_done:%d\n",
+			chip->delta_esr_count, chip->esr_fast_calib_done);
+		goto out;
+	}
+
+	/*
+	 * If the number of delta ESR interrupts fired is more than the count
+	 * to disable the interrupt OR ESR fast calibration timer is expired
+	 * OR after one retry, disable ESR fast calibration.
+	 */
+	if (chip->delta_esr_count >= chip->dt.delta_esr_disable_count ||
+		chip->esr_fast_cal_timer_expired) {
+		rc = fg_gen4_esr_fast_calib_config(chip, false);
+		if (rc < 0)
+			pr_err("Error in configuring esr_fast_calib, rc=%d\n",
+				rc);
+
+		if (chip->esr_fast_cal_timer_expired) {
+			pm_relax(fg->dev);
+			chip->esr_fast_cal_timer_expired = false;
+		}
+
+		if (chip->esr_fast_calib_retry)
+			chip->esr_fast_calib_retry = false;
+
+		goto out;
+	}
+
+	rc = fg_sram_read(fg, ESR_WORD, ESR_OFFSET, buf, 2,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading ESR, rc=%d\n", rc);
+		goto out;
+	}
+	esr_raw = buf[1] << 8 | buf[0];
+
+	rc = fg_sram_read(fg, ESR_CHAR_WORD, ESR_CHAR_OFFSET, buf, 2,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading ESR_CHAR, rc=%d\n", rc);
+		goto out;
+	}
+	esr_char_raw = buf[1] << 8 | buf[0];
+
+	esr_meas_diff = esr_raw - esr_char_raw;
+
+	rc = fg_sram_read(fg, ESR_DELTA_DISCHG_WORD, ESR_DELTA_DISCHG_OFFSET,
+			buf, 2, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading ESR_DELTA_DISCHG, rc=%d\n", rc);
+		goto out;
+	}
+	esr_delta = buf[1] << 8 | buf[0];
+	fg_dbg(fg, FG_STATUS, "esr_raw: 0x%x esr_char_raw: 0x%x esr_meas_diff: 0x%x esr_delta: 0x%x\n",
+		esr_raw, esr_char_raw, esr_meas_diff, esr_delta);
+
+	fg_esr_meas_diff = esr_meas_diff - (esr_delta / 32);
+
+	/* Don't filter for the first attempt so that ESR can converge faster */
+	if (!chip->delta_esr_count)
+		esr_filtered = fg_esr_meas_diff;
+	else
+		esr_filtered = fg_esr_meas_diff >> chip->dt.esr_filter_factor;
+
+	esr_delta = esr_delta + (esr_filtered * 32);
+
+	/* Bound the limits */
+	if (esr_delta > SHRT_MAX)
+		esr_delta = SHRT_MAX;
+	else if (esr_delta < SHRT_MIN)
+		esr_delta = SHRT_MIN;
+
+	fg_dbg(fg, FG_STATUS, "fg_esr_meas_diff: 0x%x esr_filt: 0x%x esr_delta_new: 0x%x\n",
+		fg_esr_meas_diff, esr_filtered, esr_delta);
+
+	buf[0] = esr_delta & 0xff;
+	buf[1] = (esr_delta >> 8) & 0xff;
+	rc = fg_sram_write(fg, ESR_DELTA_DISCHG_WORD, ESR_DELTA_DISCHG_OFFSET,
+			buf, 2, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_DELTA_DISCHG, rc=%d\n", rc);
+		goto out;
+	}
+
+	rc = fg_sram_write(fg, ESR_DELTA_CHG_WORD, ESR_DELTA_CHG_OFFSET,
+			buf, 2, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing ESR_DELTA_CHG, rc=%d\n", rc);
+		goto out;
+	}
+
+	chip->delta_esr_count++;
+	fg_dbg(fg, FG_STATUS, "Wrote ESR delta [0x%x 0x%x]\n", buf[0], buf[1]);
+out:
+	mutex_unlock(&chip->esr_calib_lock);
+	vote(fg->awake_votable, ESR_CALIB, false, 0);
+}
+
+static enum alarmtimer_restart fg_soc_scale_timer(struct alarm *alarm,
+							ktime_t time)
+{
+	struct fg_gen4_chip *chip = container_of(alarm, struct fg_gen4_chip,
+							soc_scale_alarm_timer);
+
+	schedule_work(&chip->soc_scale_work);
+	return ALARMTIMER_NORESTART;
+}
+
+static void soc_scale_work(struct work_struct *work)
+{
+	struct fg_gen4_chip *chip = container_of(work, struct fg_gen4_chip,
+						soc_scale_work);
+	struct fg_dev *fg = &chip->fg;
+	int soc, soc_thr_percent, rc;
+
+	if (!chip->soc_scale_mode)
+		return;
+
+	soc_thr_percent = chip->dt.delta_soc_thr / 10;
+	if (soc_thr_percent == 0) {
+		/* Set minimum SOC change that can be reported = 1% */
+		soc_thr_percent = 1;
+	}
+
+	rc = fg_gen4_validate_soc_scale_mode(chip);
+	if (rc < 0)
+		pr_err("Failed to validate SOC scale mode, rc=%d\n", rc);
+
+	/* re-validate soc scale mode as we may have exited FVSS */
+	if (!chip->soc_scale_mode) {
+		fg_dbg(fg, FG_FVSS, "exit soc scale mode\n");
+		return;
+	}
+
+	if (chip->vbatt_res <= 0)
+		chip->vbatt_res = 0;
+
+	mutex_lock(&chip->soc_scale_lock);
+	soc = DIV_ROUND_CLOSEST(chip->vbatt_res,
+				chip->soc_scale_slope);
+	chip->soc_scale_msoc = soc;
+	chip->scale_timer = chip->dt.scale_timer_ms;
+
+	fg_dbg(fg, FG_FVSS, "soc: %d last soc: %d msoc_actual: %d\n", soc,
+			chip->prev_soc_scale_msoc, chip->msoc_actual);
+	if ((chip->prev_soc_scale_msoc - chip->msoc_actual) > soc_thr_percent) {
+		/*
+		 * If difference between previous SW calculated SOC and HW SOC
+		 * is higher than SOC threshold, then handle this by
+		 * showing previous SW SOC - SOC threshold.
+		 */
+		chip->soc_scale_msoc = chip->prev_soc_scale_msoc -
+					soc_thr_percent;
+	} else if (soc > chip->prev_soc_scale_msoc) {
+		/*
+		 * If calculated SOC is higher than current SOC, report current
+		 * SOC
+		 */
+		chip->soc_scale_msoc = chip->prev_soc_scale_msoc;
+		chip->scale_timer = chip->dt.scale_timer_ms;
+	} else if ((chip->prev_soc_scale_msoc - soc) > soc_thr_percent) {
+		/*
+		 * If difference b/w current SOC and calculated SOC
+		 * is higher than SOC threshold then handle this by
+		 * showing current SOC - SOC threshold and decrease
+		 * timer resolution to catch up the rate of decrement
+		 * of SOC.
+		 */
+		chip->soc_scale_msoc = chip->prev_soc_scale_msoc -
+					soc_thr_percent;
+		chip->scale_timer = chip->dt.scale_timer_ms /
+				(chip->prev_soc_scale_msoc - soc);
+	}
+
+	if (chip->soc_scale_msoc < 0)
+		chip->soc_scale_msoc = 0;
+
+	mutex_unlock(&chip->soc_scale_lock);
+	if (chip->prev_soc_scale_msoc != chip->soc_scale_msoc) {
+		if (batt_psy_initialized(fg))
+			power_supply_changed(fg->batt_psy);
+	}
+
+	chip->prev_soc_scale_msoc = chip->soc_scale_msoc;
+	fg_dbg(fg, FG_FVSS, "Calculated SOC=%d SOC reported=%d timer resolution=%d\n",
+		soc, chip->soc_scale_msoc, chip->scale_timer);
+	alarm_start_relative(&chip->soc_scale_alarm_timer,
+				ms_to_ktime(chip->scale_timer));
+}
+
+static void pl_current_en_work(struct work_struct *work)
+{
+	struct fg_gen4_chip *chip = container_of(work,
+				struct fg_gen4_chip,
+				pl_current_en_work);
+	struct fg_dev *fg = &chip->fg;
+	bool input_present = is_input_present(fg), en;
+
+	en = fg->charge_done ? false : input_present;
+
+	if (get_effective_result(chip->parallel_current_en_votable) == en)
+		return;
+
+	vote(chip->parallel_current_en_votable, FG_PARALLEL_EN_VOTER, en, 0);
+	/* qcom patch to fix pm8150b ADC EOC bit not set issue */
+	vote(chip->mem_attn_irq_en_votable, MEM_ATTN_IRQ_VOTER, false, 0);
+}
+
+static void pl_enable_work(struct work_struct *work)
+{
+	struct fg_gen4_chip *chip = container_of(work,
+				struct fg_gen4_chip,
+				pl_enable_work.work);
+	struct fg_dev *fg = &chip->fg;
+
+	if (chip->pl_disable_votable)
+		vote(chip->pl_disable_votable, ESR_FCC_VOTER, false, 0);
+	if (chip->cp_disable_votable)
+		vote(chip->cp_disable_votable, ESR_FCC_VOTER, false, 0);
+	vote(fg->awake_votable, ESR_FCC_VOTER, false, 0);
+}
+
+static void vbat_sync_work(struct work_struct *work)
+{
+	pr_err("sys_sync:vbat_sync_work\n");
+	ksys_sync();
+}
+
+static void status_change_work(struct work_struct *work)
+{
+	struct fg_dev *fg = container_of(work,
+			struct fg_dev, status_change_work);
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc, batt_soc, batt_temp, msoc_raw;
+	bool input_present;
+	u32 batt_soc_cp;
+
+	if (fg->battery_missing) {
+		pm_relax(fg->dev);
+		return;
+	}
+
+	if (!chip->pl_disable_votable)
+		chip->pl_disable_votable = find_votable("PL_DISABLE");
+
+	if (!chip->cp_disable_votable)
+		chip->cp_disable_votable = find_votable("CP_DISABLE");
+
+	if (!batt_psy_initialized(fg)) {
+		fg_dbg(fg, FG_STATUS, "Charger not available?!\n");
+		goto out;
+	}
+
+	if (!fg->soc_reporting_ready) {
+		fg_dbg(fg, FG_STATUS, "Profile load is not complete yet\n");
+		goto out;
+	}
+
+	get_batt_psy_props(fg);
+
+	if (fg->charge_done && !fg->report_full) {
+		fg->report_full = true;
+	} else if (!fg->charge_done && fg->report_full) {
+		rc = fg_get_msoc_raw(fg, &msoc_raw);
+		if (rc < 0)
+			pr_err("Error in getting msoc, rc=%d\n", rc);
+		if (msoc_raw < FULL_SOC_REPORT_THR - 4)
+			fg->report_full = false;
+	}
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_BATT_SOC, &batt_soc);
+	if (rc < 0) {
+		pr_err("Failed to read battery soc rc: %d\n", rc);
+		goto out;
+	}
+
+	rc = fg_gen4_get_battery_temp(fg, &batt_temp);
+	if (rc < 0) {
+		pr_err("Failed to read battery temp rc: %d\n", rc);
+		goto out;
+	}
+
+	input_present = is_input_present(fg);
+	fg->input_present = input_present;
+
+	cycle_count_update(chip->counter, (u32)batt_soc >> 24,
+		fg->charge_status, fg->charge_done,
+		(input_present));
+
+	batt_soc_cp = div64_u64((u64)(u32)batt_soc * CENTI_FULL_SOC,
+				BATT_SOC_32BIT);
+	cap_learning_update(chip->cl, batt_temp, batt_soc_cp,
+			fg->charge_status, fg->charge_done, input_present,
+			0);
+
+	rc = fg_gen4_slope_limit_config(chip, batt_temp);
+	if (rc < 0)
+		pr_err("Error in configuring slope limiter rc:%d\n", rc);
+
+	rc = fg_gen4_adjust_ki_coeff_dischg(fg);
+	if (rc < 0)
+		pr_err("Error in adjusting ki_coeff_dischg, rc=%d\n", rc);
+
+	rc = fg_gen4_adjust_ki_coeff_full_soc(chip, batt_temp);
+	if (rc < 0)
+		pr_err("Error in configuring ki_coeff_full_soc rc:%d\n", rc);
+
+	rc = fg_gen4_esr_fcc_config(chip);
+	if (rc < 0)
+		pr_err("Error in adjusting FCC for ESR, rc=%d\n", rc);
+
+	if (is_parallel_charger_available(fg)) {
+		cancel_work_sync(&chip->pl_current_en_work);
+		schedule_work(&chip->pl_current_en_work);
+	}
+
+	rc = fg_gen4_validate_soc_scale_mode(chip);
+	if (rc < 0)
+		pr_err("Failed to validate SOC scale mode, rc=%d\n", rc);
+
+out:
+	fg_dbg(fg, FG_STATUS, "charge_status:%d charge_done:%d\n",
+		fg->charge_status, fg->charge_done);
+	pm_relax(fg->dev);
+}
+
+static void sram_dump_work(struct work_struct *work)
+{
+	struct fg_dev *fg = container_of(work, struct fg_dev,
+				    sram_dump_work.work);
+	u8 *buf;
+	int rc;
+	s64 timestamp_ms, quotient;
+	s32 remainder;
+
+	buf = kcalloc(FG_SRAM_LEN, sizeof(u8), GFP_KERNEL);
+	if (!buf)
+		goto resched;
+
+	rc = fg_sram_read(fg, 0, 0, buf, FG_SRAM_LEN, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading FG SRAM, rc:%d\n", rc);
+		kfree(buf);
+		goto resched;
+	}
+
+	timestamp_ms = ktime_to_ms(ktime_get_boottime());
+	quotient = div_s64_rem(timestamp_ms, 1000, &remainder);
+	fg_dbg(fg, FG_STATUS, "SRAM Dump Started at %lld.%d\n",
+		quotient, remainder);
+	dump_sram(fg, buf, 0, FG_SRAM_LEN);
+	kfree(buf);
+	timestamp_ms = ktime_to_ms(ktime_get_boottime());
+	quotient = div_s64_rem(timestamp_ms, 1000, &remainder);
+	fg_dbg(fg, FG_STATUS, "SRAM Dump done at %lld.%d\n",
+		quotient, remainder);
+resched:
+	schedule_delayed_work(&fg->sram_dump_work,
+			msecs_to_jiffies(fg_sram_dump_period_ms));
+}
+
+static int fg_sram_dump_sysfs(const char *val, const struct kernel_param *kp)
+{
+	int rc;
+	struct power_supply *bms_psy;
+	struct fg_gen4_chip *chip;
+	struct fg_dev *fg;
+	bool old_val = fg_sram_dump;
+
+	rc = param_set_bool(val, kp);
+	if (rc) {
+		pr_err("Unable to set fg_sram_dump: %d\n", rc);
+		return rc;
+	}
+
+	if (fg_sram_dump == old_val)
+		return 0;
+
+	bms_psy = power_supply_get_by_name("bms");
+	if (!bms_psy) {
+		pr_err("bms psy not found\n");
+		return -ENODEV;
+	}
+
+	chip = power_supply_get_drvdata(bms_psy);
+	fg = &chip->fg;
+
+	power_supply_put(bms_psy);
+	if (fg->battery_missing) {
+		pr_warn("Battery is missing\n");
+		return 0;
+	}
+
+	if (fg_sram_dump)
+		schedule_delayed_work(&fg->sram_dump_work,
+				msecs_to_jiffies(fg_sram_dump_period_ms));
+	else
+		cancel_delayed_work_sync(&fg->sram_dump_work);
+
+	return 0;
+}
+
+static struct kernel_param_ops fg_sram_dump_ops = {
+	.set = fg_sram_dump_sysfs,
+	.get = param_get_bool,
+};
+
+module_param_cb(sram_dump_en, &fg_sram_dump_ops, &fg_sram_dump, 0644);
+
+static int fg_restart_sysfs(const char *val, const struct kernel_param *kp)
+{
+	int rc;
+	struct power_supply *bms_psy;
+	struct fg_gen4_chip *chip;
+	struct fg_dev *fg;
+
+	rc = param_set_int(val, kp);
+	if (rc) {
+		pr_err("Unable to set fg_restart_mp: %d\n", rc);
+		return rc;
+	}
+
+	if (fg_restart_mp != 1) {
+		pr_err("Bad value %d\n", fg_restart_mp);
+		return -EINVAL;
+	}
+
+	bms_psy = power_supply_get_by_name("bms");
+	if (!bms_psy) {
+		pr_err("bms psy not found\n");
+		return 0;
+	}
+
+	chip = power_supply_get_drvdata(bms_psy);
+	fg = &chip->fg;
+	power_supply_put(bms_psy);
+	rc = fg_restart(fg, SOC_READY_WAIT_TIME_MS);
+	if (rc < 0) {
+		pr_err("Error in restarting FG, rc=%d\n", rc);
+		return rc;
+	}
+
+	pr_info("FG restart done\n");
+	return rc;
+}
+
+static struct kernel_param_ops fg_restart_ops = {
+	.set = fg_restart_sysfs,
+	.get = param_get_int,
+};
+
+module_param_cb(restart, &fg_restart_ops, &fg_restart_mp, 0644);
+
+static int fg_esr_fast_cal_sysfs(const char *val, const struct kernel_param *kp)
+{
+	int rc;
+	struct power_supply *bms_psy;
+	struct fg_gen4_chip *chip;
+	bool old_val = fg_esr_fast_cal_en;
+
+	rc = param_set_bool(val, kp);
+	if (rc) {
+		pr_err("Unable to set fg_sram_dump: %d\n", rc);
+		return rc;
+	}
+
+	if (fg_esr_fast_cal_en == old_val)
+		return 0;
+
+	bms_psy = power_supply_get_by_name("bms");
+	if (!bms_psy) {
+		pr_err("bms psy not found\n");
+		return -ENODEV;
+	}
+
+	chip = power_supply_get_drvdata(bms_psy);
+	power_supply_put(bms_psy);
+
+	if (!chip)
+		return -ENODEV;
+
+	if (fg_esr_fast_cal_en)
+		chip->delta_esr_count = 0;
+
+	rc = fg_gen4_esr_fast_calib_config(chip, fg_esr_fast_cal_en);
+	if (rc < 0)
+		return rc;
+
+	return 0;
+}
+
+static struct kernel_param_ops fg_esr_cal_ops = {
+	.set = fg_esr_fast_cal_sysfs,
+	.get = param_get_bool,
+};
+
+module_param_cb(esr_fast_cal_en, &fg_esr_cal_ops, &fg_esr_fast_cal_en, 0644);
+
+int smblib_get_prop_from_charger(struct fg_dev *fg,
+				enum power_supply_property psp,
+				union power_supply_propval *val)
+{
+	int rc;
+
+	if (!batt_psy_initialized(fg))
+		return -EINVAL;
+
+	rc = power_supply_get_property(fg->batt_psy, psp, val);
+
+	return rc;
+}
+
+/* All power supply functions here */
+static int fg_psy_get_property(struct power_supply *psy,
+				       enum power_supply_property psp,
+				       union power_supply_propval *pval)
+{
+	struct fg_gen4_chip *chip = power_supply_get_drvdata(psy);
+	struct fg_dev *fg = &chip->fg;
+	int rc = 0;
+	int64_t temp;
+
+	switch (psp) {
+	case POWER_SUPPLY_PROP_PRESENT:
+		rc = smblib_get_prop_from_charger(fg,
+					POWER_SUPPLY_PROP_PRESENT, pval);
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_TYPE:
+		rc = smblib_get_prop_from_charger(fg,
+					POWER_SUPPLY_PROP_CHARGE_TYPE, pval);
+		break;
+	case POWER_SUPPLY_PROP_CAPACITY:
+		rc = fg_gen4_get_prop_capacity(fg, &pval->intval);
+		//Using smooth battery capacity.
+		if (fg->param.batt_soc >= 0 && !chip->rapid_soc_dec_en)
+			pval->intval = fg->param.batt_soc;
+		break;
+	case POWER_SUPPLY_PROP_VOLTAGE_NOW:
+		if (fg->battery_missing)
+			pval->intval = 3700000;
+		else
+			rc = fg_get_battery_voltage(fg, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_CURRENT_NOW:
+		rc = fg_get_battery_current(fg, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_CURRENT_AVG:
+		rc = fg_get_sram_prop(fg, FG_SRAM_IBAT_FLT, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_TEMP:
+		rc = fg_gen4_get_battery_temp(fg, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_VOLTAGE_OCV:
+		rc = fg_get_sram_prop(fg, FG_SRAM_OCV, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_VOLTAGE_AVG:
+		rc = fg_get_sram_prop(fg, FG_SRAM_VBAT_FLT, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_VOLTAGE_MAX_DESIGN:
+		pval->intval = fg->bp.float_volt_uv;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_NOW:
+		pval->intval = chip->cl->init_cap_uah;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_FULL:
+		rc = fg_gen4_get_learned_capacity(chip, &temp);
+		if (!rc)
+			pval->intval = (int)temp;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_FULL_DESIGN:
+		if (-EINVAL != fg->bp.nom_cap_uah) {
+			pval->intval = fg->bp.nom_cap_uah * 1000;
+		} else {
+			rc = fg_gen4_get_nominal_capacity(chip, &temp);
+			if (!rc)
+				pval->intval = (int)temp;
+		}
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_COUNTER:
+		rc = fg_gen4_get_charge_counter(chip, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_CYCLE_COUNT:
+		rc = get_cycle_count(chip->counter, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE:
+		rc = fg_get_sram_prop(fg, FG_SRAM_VBATT_FULL, &pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_POWER_NOW:
+		rc = fg_gen4_get_power(chip, &pval->intval, false);
+		break;
+	case POWER_SUPPLY_PROP_POWER_AVG:
+		rc = fg_gen4_get_power(chip, &pval->intval, true);
+		break;
+	case POWER_SUPPLY_PROP_CALIBRATE:
+		pval->intval = chip->calib_level;
+		break;
+	default:
+		pr_err("unsupported property %d\n", psp);
+		rc = -EINVAL;
+		break;
+	}
+
+	if (rc < 0)
+		return -ENODATA;
+
+	return 0;
+}
+
+static int fg_psy_set_property(struct power_supply *psy,
+				  enum power_supply_property psp,
+				  const union power_supply_propval *pval)
+{
+	struct fg_gen4_chip *chip = power_supply_get_drvdata(psy);
+	struct fg_dev *fg = &chip->fg;
+	int rc = 0;
+
+	switch (psp) {
+	case POWER_SUPPLY_PROP_CHARGE_FULL:
+		if (chip->cl->active) {
+			pr_warn("Capacity learning active!\n");
+			return 0;
+		}
+		if (pval->intval <= 0 || pval->intval > chip->cl->nom_cap_uah) {
+			pr_err("charge_full is out of bounds\n");
+			return -EINVAL;
+		}
+		mutex_lock(&chip->cl->lock);
+		rc = fg_gen4_store_learned_capacity(chip, pval->intval);
+		if (!rc)
+			chip->cl->learned_cap_uah = pval->intval;
+		mutex_unlock(&chip->cl->lock);
+		break;
+	case POWER_SUPPLY_PROP_CYCLE_COUNT:
+		rc = set_cycle_count(chip->counter, pval->intval);
+		pr_info("Cycle count is modified to %d by userspace\n", pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE:
+		if (fg->vbatt_full_volt_uv != pval->intval)
+			rc = fg_set_constant_chg_voltage(fg, pval->intval);
+		fg->vbatt_full_volt_uv = pval->intval;
+		break;
+	case POWER_SUPPLY_PROP_CALIBRATE:
+		rc = fg_gen4_set_calibrate_level(chip, pval->intval);
+		break;
+	case POWER_SUPPLY_PROP_TEMP:
+		fg->batt_fake_temp = pval->intval;
+		break;
+	default:
+		break;
+	}
+
+	return rc;
+}
+
+static int fg_property_is_writeable(struct power_supply *psy,
+						enum power_supply_property psp)
+{
+	switch (psp) {
+	case POWER_SUPPLY_PROP_CHARGE_FULL:
+	case POWER_SUPPLY_PROP_CYCLE_COUNT:
+	case POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE:
+	case POWER_SUPPLY_PROP_CALIBRATE:
+	case POWER_SUPPLY_PROP_TEMP:
+		return 1;
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static enum power_supply_property fg_psy_props[] = {
+	/* from charger */
+	POWER_SUPPLY_PROP_PRESENT,
+	POWER_SUPPLY_PROP_CHARGE_TYPE,
+	/* from fg */
+	POWER_SUPPLY_PROP_CAPACITY,
+	POWER_SUPPLY_PROP_TEMP,
+	POWER_SUPPLY_PROP_VOLTAGE_NOW,
+	POWER_SUPPLY_PROP_VOLTAGE_OCV,
+	POWER_SUPPLY_PROP_VOLTAGE_AVG,
+	POWER_SUPPLY_PROP_CURRENT_NOW,
+	POWER_SUPPLY_PROP_CURRENT_AVG,
+	POWER_SUPPLY_PROP_CHARGE_FULL_DESIGN,
+	POWER_SUPPLY_PROP_VOLTAGE_MAX_DESIGN,
+	POWER_SUPPLY_PROP_CHARGE_NOW,
+	POWER_SUPPLY_PROP_CHARGE_FULL,
+	POWER_SUPPLY_PROP_CHARGE_COUNTER,
+	POWER_SUPPLY_PROP_CYCLE_COUNT,
+	POWER_SUPPLY_PROP_CONSTANT_CHARGE_VOLTAGE,
+	POWER_SUPPLY_PROP_POWER_NOW,
+	POWER_SUPPLY_PROP_POWER_AVG,
+	POWER_SUPPLY_PROP_CALIBRATE,
+};
+
+static const struct power_supply_desc fg_psy_desc = {
+	.name = "bms",
+	.type = POWER_SUPPLY_TYPE_BATTERY,
+	.properties = fg_psy_props,
+	.num_properties = ARRAY_SIZE(fg_psy_props),
+	.get_property = fg_psy_get_property,
+	.set_property = fg_psy_set_property,
+	.property_is_writeable = fg_property_is_writeable,
+};
+
+/* All callback functions below */
+
+static int fg_notifier_cb(struct notifier_block *nb,
+		unsigned long event, void *data)
+{
+	struct power_supply *psy = data;
+	struct fg_dev *fg = container_of(nb, struct fg_dev, nb);
+
+	if (event != PSY_EVENT_PROP_CHANGED)
+		return NOTIFY_OK;
+
+	if (work_pending(&fg->status_change_work))
+		return NOTIFY_OK;
+
+	if ((strcmp(psy->desc->name, "battery") == 0)
+		|| (strcmp(psy->desc->name, "parallel") == 0)
+		|| (strcmp(psy->desc->name, "usb") == 0)) {
+		/*
+		 * We cannot vote for awake votable here as that takes
+		 * a mutex lock and this is executed in an atomic context.
+		 */
+		pm_stay_awake(fg->dev);
+		schedule_work(&fg->status_change_work);
+	}
+
+	return NOTIFY_OK;
+}
+
+static int fg_awake_cb(struct votable *votable, void *data, int awake,
+			const char *client)
+{
+	struct fg_dev *fg = data;
+
+	if (awake)
+		pm_stay_awake(fg->dev);
+	else
+		pm_relax(fg->dev);
+
+	pr_debug("client: %s awake: %d\n", client, awake);
+	return 0;
+}
+
+static int fg_wait_for_mem_attn(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc, retries = 2;
+	ktime_t now;
+	s64 time_us;
+
+	reinit_completion(&chip->mem_attn);
+	now = ktime_get();
+
+	while (retries--) {
+		/* Wait for MEM_ATTN completion */
+		rc = wait_for_completion_interruptible_timeout(
+			&chip->mem_attn, msecs_to_jiffies(1000));
+		if (rc > 0) {
+			rc = 0;
+			break;
+		} else if (!rc) {
+			rc = -ETIMEDOUT;
+		}
+	}
+
+	time_us = ktime_us_delta(ktime_get(), now);
+	if (rc < 0)
+		pr_err("wait for mem_attn timed out rc=%d\n", rc);
+
+	fg_dbg(fg, FG_STATUS, "mem_attn wait time: %lld us\n", time_us);
+	return rc;
+}
+
+static int fg_parallel_current_en_cb(struct votable *votable, void *data,
+					int enable, const char *client)
+{
+	struct fg_dev *fg = data;
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	int rc;
+	/* u8 val, mask; */
+
+	vote(chip->mem_attn_irq_en_votable, MEM_ATTN_IRQ_VOTER, true, 0);
+
+	/* Wait for MEM_ATTN interrupt */
+	rc = fg_wait_for_mem_attn(chip);
+	if (rc < 0)
+		return rc;
+
+	/* qcom new patch to fix pm8150b ADC EOC bit not set issue */
+	/* val = enable ? SMB_MEASURE_EN_BIT : 0;
+	mask = SMB_MEASURE_EN_BIT;
+	rc = fg_masked_write(fg, BATT_INFO_FG_CNV_CHAR_CFG(fg), mask, val);
+	if (rc < 0)
+		pr_err("Error in writing to 0x%04x, rc=%d\n",
+			BATT_INFO_FG_CNV_CHAR_CFG(fg), rc);
+
+	vote(chip->mem_attn_irq_en_votable, MEM_ATTN_IRQ_VOTER, false, 0);
+	fg_dbg(fg, FG_STATUS, "Parallel current summing: %d\n", enable); */
+
+	/* qcom patch to fix pm8150b ADC EOC bit not set issue */
+	/*vote(chip->mem_attn_irq_en_votable, MEM_ATTN_IRQ_VOTER, false, 0);*/
+
+	return rc;
+}
+
+static int fg_delta_bsoc_irq_en_cb(struct votable *votable, void *data,
+					int enable, const char *client)
+{
+	struct fg_dev *fg = data;
+
+	if (!fg->irqs[BSOC_DELTA_IRQ].irq)
+		return 0;
+
+	if (enable) {
+		enable_irq(fg->irqs[BSOC_DELTA_IRQ].irq);
+		enable_irq_wake(fg->irqs[BSOC_DELTA_IRQ].irq);
+	} else {
+		disable_irq_wake(fg->irqs[BSOC_DELTA_IRQ].irq);
+		disable_irq_nosync(fg->irqs[BSOC_DELTA_IRQ].irq);
+	}
+
+	return 0;
+}
+
+static int fg_gen4_delta_esr_irq_en_cb(struct votable *votable, void *data,
+					int enable, const char *client)
+{
+	struct fg_dev *fg = data;
+
+	if (!fg->irqs[ESR_DELTA_IRQ].irq)
+		return 0;
+
+	if (enable) {
+		enable_irq(fg->irqs[ESR_DELTA_IRQ].irq);
+		enable_irq_wake(fg->irqs[ESR_DELTA_IRQ].irq);
+	} else {
+		disable_irq_wake(fg->irqs[ESR_DELTA_IRQ].irq);
+		disable_irq_nosync(fg->irqs[ESR_DELTA_IRQ].irq);
+	}
+
+	return 0;
+}
+
+static int fg_gen4_mem_attn_irq_en_cb(struct votable *votable, void *data,
+					int enable, const char *client)
+{
+	struct fg_dev *fg = data;
+
+	if (!fg->irqs[MEM_ATTN_IRQ].irq)
+		return 0;
+
+	if (enable) {
+		enable_irq(fg->irqs[MEM_ATTN_IRQ].irq);
+		enable_irq_wake(fg->irqs[MEM_ATTN_IRQ].irq);
+	} else {
+		disable_irq_wake(fg->irqs[MEM_ATTN_IRQ].irq);
+		disable_irq_nosync(fg->irqs[MEM_ATTN_IRQ].irq);
+	}
+
+	fg_dbg(fg, FG_STATUS, "%sabled mem_attn irq\n", enable ? "en" : "dis");
+	return 0;
+}
+
+/* All init functions below this */
+
+static int fg_alg_init(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	struct cycle_counter *counter;
+	struct cap_learning *cl;
+	int rc;
+
+	counter = devm_kzalloc(fg->dev, sizeof(*counter), GFP_KERNEL);
+	if (!counter)
+		return -ENOMEM;
+
+	counter->restore_count = fg_gen4_restore_count;
+	counter->store_count = fg_gen4_store_count;
+	counter->data = chip;
+
+	rc = cycle_count_init(counter);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in initializing cycle counter, rc:%d\n",
+			rc);
+		counter->data = NULL;
+		devm_kfree(fg->dev, counter);
+		return rc;
+	}
+
+	chip->counter = counter;
+
+	cl = devm_kzalloc(fg->dev, sizeof(*cl), GFP_KERNEL);
+	if (!cl)
+		return -ENOMEM;
+
+	cl->cc_soc_max = CC_SOC_30BIT;
+	cl->get_cc_soc = fg_gen4_get_cc_soc_sw;
+	cl->prime_cc_soc = fg_gen4_prime_cc_soc_sw;
+	cl->get_learned_capacity = fg_gen4_get_learned_capacity;
+	cl->store_learned_capacity = fg_gen4_store_learned_capacity;
+	cl->ok_to_begin = fg_gen4_cl_ok_to_begin;
+	cl->data = chip;
+
+	rc = cap_learning_init(cl);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in initializing capacity learning, rc:%d\n",
+			rc);
+		counter->data = NULL;
+		cl->data = NULL;
+		devm_kfree(fg->dev, counter);
+		devm_kfree(fg->dev, cl);
+		return rc;
+	}
+
+	chip->cl = cl;
+
+	return 0;
+}
+
+static int fg_gen4_esr_calib_config(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	u8 buf[2], val, mask;
+	int rc;
+
+	if (chip->esr_fast_calib) {
+		rc = fg_gen4_esr_fast_calib_config(chip, true);
+		if (rc < 0)
+			return rc;
+	} else {
+		if (chip->dt.esr_timer_chg_slow[TIMER_RETRY] >= 0 &&
+			chip->dt.esr_timer_chg_slow[TIMER_MAX] >= 0) {
+			rc = fg_set_esr_timer(fg,
+				chip->dt.esr_timer_chg_slow[TIMER_RETRY],
+				chip->dt.esr_timer_chg_slow[TIMER_MAX], true,
+				FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error in setting ESR charge timer, rc=%d\n",
+					rc);
+				return rc;
+			}
+		}
+
+		if (chip->dt.esr_timer_dischg_slow[TIMER_RETRY] >= 0 &&
+			chip->dt.esr_timer_dischg_slow[TIMER_MAX] >= 0) {
+			rc = fg_set_esr_timer(fg,
+				chip->dt.esr_timer_dischg_slow[TIMER_RETRY],
+				chip->dt.esr_timer_dischg_slow[TIMER_MAX],
+				false, FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error in setting ESR discharge timer, rc=%d\n",
+					rc);
+				return rc;
+			}
+		}
+
+		if (chip->dt.esr_calib_dischg) {
+			/* Allow ESR calibration only during discharging */
+			val = BIT(6) | BIT(7);
+			mask = BIT(1) | BIT(6) | BIT(7);
+			rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+					SYS_CONFIG_OFFSET, mask, val,
+					FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error in writing SYS_CONFIG_WORD, rc=%d\n",
+					rc);
+				return rc;
+			}
+
+			/* Disable ESR charging timer */
+			val = 0;
+			mask = BIT(0);
+			rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+					SYS_CONFIG2_OFFSET, mask, val,
+					FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error in writing SYS_CONFIG2_OFFSET, rc=%d\n",
+					rc);
+				return rc;
+			}
+		} else {
+			/*
+			 * Disable ESR discharging timer and ESR pulsing during
+			 * discharging when ESR fast calibration is disabled.
+			 */
+			val = 0;
+			mask = BIT(6) | BIT(7);
+			rc = fg_sram_masked_write(fg, SYS_CONFIG_WORD,
+					SYS_CONFIG_OFFSET, mask, val,
+					FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error in writing SYS_CONFIG_WORD, rc=%d\n",
+					rc);
+				return rc;
+			}
+		}
+	}
+
+	/*
+	 * Delta ESR interrupt threshold should be configured as specified if
+	 * ESR fast calibration is disabled. Else, set it to max (4000 mOhms).
+	 */
+	fg_encode(fg->sp, FG_SRAM_DELTA_ESR_THR,
+		chip->esr_fast_calib ? 4000000 : chip->dt.delta_esr_thr_uohms,
+		buf);
+	rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_DELTA_ESR_THR].addr_word,
+			fg->sp[FG_SRAM_DELTA_ESR_THR].addr_byte, buf,
+			fg->sp[FG_SRAM_DELTA_ESR_THR].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing DELTA_ESR_THR, rc=%d\n", rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+static int fg_gen4_init_ki_coeffts(struct fg_gen4_chip *chip)
+{
+	int rc;
+	u8 val;
+	struct fg_dev *fg = &chip->fg;
+
+	if (chip->dt.ki_coeff_low_chg != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_LOW_CHG,
+			chip->dt.ki_coeff_low_chg, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_CHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_CHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_LOW_CHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_low_chg, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_med_chg != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_MED_CHG,
+			chip->dt.ki_coeff_med_chg, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_MED_CHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_MED_CHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_MED_CHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_med_chg, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_hi_chg != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_HI_CHG,
+			chip->dt.ki_coeff_hi_chg, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_HI_CHG].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_HI_CHG].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_HI_CHG].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_hi_chg, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_lo_med_chg_thr_ma != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_LO_MED_CHG_THR,
+			chip->dt.ki_coeff_lo_med_chg_thr_ma, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_LO_MED_CHG_THR].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_LO_MED_CHG_THR].addr_byte,
+			&val, fg->sp[FG_SRAM_KI_COEFF_LO_MED_CHG_THR].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_lo_med_chg_thr_ma, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_med_hi_chg_thr_ma != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_MED_HI_CHG_THR,
+			chip->dt.ki_coeff_med_hi_chg_thr_ma, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_MED_HI_CHG_THR].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_MED_HI_CHG_THR].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_MED_HI_CHG_THR].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_med_hi_chg_thr_ma, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_lo_med_dchg_thr_ma != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_LO_MED_DCHG_THR,
+			chip->dt.ki_coeff_lo_med_dchg_thr_ma, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_LO_MED_DCHG_THR].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_LO_MED_DCHG_THR].addr_byte,
+			&val, fg->sp[FG_SRAM_KI_COEFF_LO_MED_DCHG_THR].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_lo_med_dchg_thr_ma, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_med_hi_dchg_thr_ma != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_MED_HI_DCHG_THR,
+			chip->dt.ki_coeff_med_hi_dchg_thr_ma, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_MED_HI_DCHG_THR].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_MED_HI_DCHG_THR].addr_byte,
+			&val, fg->sp[FG_SRAM_KI_COEFF_MED_HI_DCHG_THR].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_med_hi_dchg_thr_ma, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.ki_coeff_cutoff_gain != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_KI_COEFF_CUTOFF,
+			  chip->dt.ki_coeff_cutoff_gain, &val);
+		rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_KI_COEFF_CUTOFF].addr_word,
+			fg->sp[FG_SRAM_KI_COEFF_CUTOFF].addr_byte, &val,
+			fg->sp[FG_SRAM_KI_COEFF_CUTOFF].len,
+			FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing ki_coeff_cutoff_gain, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	rc = fg_gen4_set_ki_coeff_dischg(fg, KI_COEFF_LOW_DISCHG_DEFAULT,
+		KI_COEFF_MED_DISCHG_DEFAULT, KI_COEFF_HI_DISCHG_DEFAULT);
+	if (rc < 0)
+		return rc;
+
+	return 0;
+}
+
+#define BATT_TEMP_HYST_MASK	GENMASK(3, 0)
+#define BATT_TEMP_DELTA_MASK	GENMASK(7, 4)
+#define BATT_TEMP_DELTA_SHIFT	4
+#define VBATT_TAU_DEFAULT	3
+static int fg_gen4_hw_init(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+	u8 buf[4], val, mask;
+
+	rc = fg_read(fg, ADC_RR_INT_RT_STS(fg), &val, 1);
+	if (rc < 0) {
+		pr_err("failed to read addr=0x%04x, rc=%d\n",
+			ADC_RR_INT_RT_STS(fg), rc);
+		return rc;
+	}
+	fg->battery_missing = (val & ADC_RR_BT_MISS_BIT);
+
+	if (fg->battery_missing) {
+		pr_warn("Not initializing FG because of battery missing\n");
+		return 0;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_CUTOFF_VOLT, chip->dt.cutoff_volt_mv, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_CUTOFF_VOLT].addr_word,
+			fg->sp[FG_SRAM_CUTOFF_VOLT].addr_byte, buf,
+			fg->sp[FG_SRAM_CUTOFF_VOLT].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing cutoff_volt, rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_gen4_configure_cutoff_current(fg, chip->dt.cutoff_curr_ma);
+	if (rc < 0)
+		return rc;
+
+	fg_encode(fg->sp, FG_SRAM_SYS_TERM_CURR, chip->dt.sys_term_curr_ma,
+		buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_SYS_TERM_CURR].addr_word,
+			fg->sp[FG_SRAM_SYS_TERM_CURR].addr_byte, buf,
+			fg->sp[FG_SRAM_SYS_TERM_CURR].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing sys_term_curr, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (chip->dt.empty_volt_mv > 0) {
+		fg_encode(fg->sp, FG_SRAM_VBATT_LOW,
+			chip->dt.empty_volt_mv, buf);
+		rc = fg_sram_write(fg, fg->sp[FG_SRAM_VBATT_LOW].addr_word,
+				fg->sp[FG_SRAM_VBATT_LOW].addr_byte, buf,
+				fg->sp[FG_SRAM_VBATT_LOW].len,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing empty_volt_mv, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	fg_encode(fg->sp, FG_SRAM_DELTA_MSOC_THR,
+		chip->dt.delta_soc_thr, buf);
+	rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_DELTA_MSOC_THR].addr_word,
+			fg->sp[FG_SRAM_DELTA_MSOC_THR].addr_byte,
+			buf, fg->sp[FG_SRAM_DELTA_MSOC_THR].len,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing delta_msoc_thr, rc=%d\n", rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_DELTA_BSOC_THR,
+		chip->dt.delta_soc_thr, buf);
+	rc = fg_sram_write(fg,
+			fg->sp[FG_SRAM_DELTA_BSOC_THR].addr_word,
+			fg->sp[FG_SRAM_DELTA_BSOC_THR].addr_byte,
+			buf, fg->sp[FG_SRAM_DELTA_BSOC_THR].len,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing delta_bsoc_thr, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (chip->dt.batt_temp_cold_thresh != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_BATT_TEMP_COLD,
+			chip->dt.batt_temp_cold_thresh, buf);
+		rc = fg_sram_write(fg, fg->sp[FG_SRAM_BATT_TEMP_COLD].addr_word,
+				fg->sp[FG_SRAM_BATT_TEMP_COLD].addr_byte, buf,
+				fg->sp[FG_SRAM_BATT_TEMP_COLD].len,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing batt_temp_cold_thresh, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.batt_temp_hot_thresh != -EINVAL) {
+		fg_encode(fg->sp, FG_SRAM_BATT_TEMP_HOT,
+			chip->dt.batt_temp_hot_thresh, buf);
+		rc = fg_sram_write(fg, fg->sp[FG_SRAM_BATT_TEMP_HOT].addr_word,
+				fg->sp[FG_SRAM_BATT_TEMP_HOT].addr_byte, buf,
+				fg->sp[FG_SRAM_BATT_TEMP_HOT].len,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing batt_temp_hot_thresh, rc=%d\n",
+				rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.batt_temp_hyst != -EINVAL) {
+		val = chip->dt.batt_temp_hyst & BATT_TEMP_HYST_MASK;
+		mask = BATT_TEMP_HYST_MASK;
+		rc = fg_sram_masked_write(fg, BATT_TEMP_CONFIG2_WORD,
+				BATT_TEMP_HYST_DELTA_OFFSET, mask, val,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing batt_temp_hyst, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.batt_temp_delta != -EINVAL) {
+		val = (chip->dt.batt_temp_delta << BATT_TEMP_DELTA_SHIFT)
+				& BATT_TEMP_DELTA_MASK;
+		mask = BATT_TEMP_DELTA_MASK;
+		rc = fg_sram_masked_write(fg, BATT_TEMP_CONFIG2_WORD,
+				BATT_TEMP_HYST_DELTA_OFFSET, mask, val,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error in writing batt_temp_delta, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	val = (u8)chip->dt.batt_therm_freq;
+	rc = fg_write(fg, ADC_RR_BATT_THERM_FREQ(fg), &val, 1);
+	if (rc < 0) {
+		pr_err("failed to write to 0x%04X, rc=%d\n",
+			 ADC_RR_BATT_THERM_FREQ(fg), rc);
+		return rc;
+	}
+
+	fg_encode(fg->sp, FG_SRAM_ESR_PULSE_THRESH,
+		chip->dt.esr_pulse_thresh_ma, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_ESR_PULSE_THRESH].addr_word,
+			fg->sp[FG_SRAM_ESR_PULSE_THRESH].addr_byte, buf,
+			fg->sp[FG_SRAM_ESR_PULSE_THRESH].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing esr_pulse_thresh_ma, rc=%d\n", rc);
+		return rc;
+	}
+
+	get_esr_meas_current(chip->dt.esr_meas_curr_ma, &val);
+	rc = fg_masked_write(fg, BATT_INFO_ESR_PULL_DN_CFG(fg),
+			ESR_PULL_DOWN_IVAL_MASK, val);
+	if (rc < 0) {
+		pr_err("Error in writing esr_meas_curr_ma, rc=%d\n", rc);
+		return rc;
+	}
+
+	if (is_debug_batt_id(fg)) {
+		val = ESR_NO_PULL_DOWN;
+		rc = fg_masked_write(fg, BATT_INFO_ESR_PULL_DN_CFG(fg),
+			ESR_PULL_DOWN_MODE_MASK, val);
+		if (rc < 0) {
+			pr_err("Error in writing esr_pull_down, rc=%d\n", rc);
+			return rc;
+		}
+	}
+
+	if (chip->dt.rconn_uohms) {
+		/*
+		 * Read back Rconn to see if it's already configured. If it is
+		 * a non-zero value, then skip configuring it.
+		 */
+		rc = fg_sram_read(fg, RCONN_WORD, RCONN_OFFSET, buf, 2,
+				FG_IMA_DEFAULT);
+		if (rc < 0) {
+			pr_err("Error reading Rconn, rc=%d\n", rc);
+			return rc;
+		}
+
+		if (!buf[0] && !buf[1]) {
+			/* Rconn has same encoding as ESR */
+			fg_encode(fg->sp, FG_SRAM_ESR, chip->dt.rconn_uohms,
+				buf);
+			rc = fg_sram_write(fg, RCONN_WORD, RCONN_OFFSET, buf, 2,
+					FG_IMA_DEFAULT);
+			if (rc < 0) {
+				pr_err("Error writing Rconn, rc=%d\n", rc);
+				return rc;
+			}
+		} else {
+			pr_debug("Skipping configuring Rconn [0x%x 0x%x]\n",
+				buf[0], buf[1]);
+		}
+	}
+
+	rc = fg_gen4_init_ki_coeffts(chip);
+	if (rc < 0)
+		return rc;
+
+	rc = fg_gen4_esr_calib_config(chip);
+	if (rc < 0)
+		return rc;
+
+	if (chip->dt.soc_scale_mode) {
+		rc = fg_gen4_set_vbatt_tau(chip, VBATT_TAU_DEFAULT);
+		if (rc < 0) {
+			fg_gen4_exit_soc_scale(chip);
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+static int fg_parse_slope_limit_coefficients(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	struct device_node *node = fg->dev->of_node;
+	int rc, i;
+
+	if (!of_find_property(node, "qcom,slope-limit-coeffs", NULL))
+		return 0;
+
+	rc = of_property_read_u32(node, "qcom,slope-limit-temp-threshold",
+			&chip->dt.slope_limit_temp);
+	if (rc < 0)
+		return 0;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,slope-limit-coeffs",
+		chip->dt.slope_limit_coeffs, SLOPE_LIMIT_NUM_COEFFS);
+	if (rc < 0)
+		return rc;
+
+	for (i = 0; i < SLOPE_LIMIT_NUM_COEFFS; i++) {
+		if (chip->dt.slope_limit_coeffs[i] > SLOPE_LIMIT_COEFF_MAX ||
+			chip->dt.slope_limit_coeffs[i] < 0) {
+			pr_err("Incorrect slope limit coefficient\n");
+			return -EINVAL;
+		}
+	}
+
+	chip->slope_limit_en = true;
+	return 0;
+}
+
+static int fg_parse_ki_coefficients(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	struct device_node *node = fg->dev->of_node;
+	int rc, i;
+
+	chip->dt.ki_coeff_full_soc_dischg[0] = KI_COEFF_FULL_SOC_NORM_DEFAULT;
+	chip->dt.ki_coeff_full_soc_dischg[1] = KI_COEFF_FULL_SOC_LOW_DEFAULT;
+
+	if (of_find_property(node, "qcom,ki-coeff-full-dischg", NULL)) {
+		rc = fg_parse_dt_property_u32_array(node,
+			"qcom,ki-coeff-full-dischg",
+			chip->dt.ki_coeff_full_soc_dischg, 2);
+		if (rc < 0)
+			return rc;
+
+		if (chip->dt.ki_coeff_full_soc_dischg[0] < 62 ||
+			chip->dt.ki_coeff_full_soc_dischg[0] > 15564 ||
+			chip->dt.ki_coeff_full_soc_dischg[1] < 62 ||
+			chip->dt.ki_coeff_full_soc_dischg[1] > 15564) {
+			pr_err("Error in ki_coeff_full_soc_dischg values\n");
+			return -EINVAL;
+		}
+	}
+
+	chip->dt.ki_coeff_low_chg = 184;
+	of_property_read_u32(node, "qcom,ki-coeff-low-chg",
+		&chip->dt.ki_coeff_low_chg);
+
+	chip->dt.ki_coeff_med_chg = 62;
+	of_property_read_u32(node, "qcom,ki-coeff-med-chg",
+		&chip->dt.ki_coeff_med_chg);
+
+	chip->dt.ki_coeff_hi_chg = 0;
+	of_property_read_u32(node, "qcom,ki-coeff-hi-chg",
+		&chip->dt.ki_coeff_hi_chg);
+
+	chip->dt.ki_coeff_lo_med_chg_thr_ma = 500;
+	of_property_read_u32(node, "qcom,ki-coeff-chg-low-med-thresh-ma",
+		&chip->dt.ki_coeff_lo_med_chg_thr_ma);
+
+	chip->dt.ki_coeff_med_hi_chg_thr_ma = 1000;
+	of_property_read_u32(node, "qcom,ki-coeff-chg-med-hi-thresh-ma",
+		&chip->dt.ki_coeff_med_hi_chg_thr_ma);
+
+	chip->dt.ffc_ki_coeff_lo_med_chg_thr_ma = -EINVAL;
+	of_property_read_u32(node, "qcom,ffc-ki-coeff-chg-low-med-thresh-ma",
+		&chip->dt.ffc_ki_coeff_lo_med_chg_thr_ma);
+
+	chip->dt.ffc_ki_coeff_med_hi_chg_thr_ma = -EINVAL;
+	of_property_read_u32(node, "qcom,ffc-ki-coeff-chg-med-hi-thresh-ma",
+		&chip->dt.ffc_ki_coeff_med_hi_chg_thr_ma);
+
+	chip->dt.ki_coeff_lo_med_dchg_thr_ma = 50;
+	of_property_read_u32(node, "qcom,ki-coeff-dischg-low-med-thresh-ma",
+		&chip->dt.ki_coeff_lo_med_dchg_thr_ma);
+
+	chip->dt.ki_coeff_med_hi_dchg_thr_ma = 100;
+	of_property_read_u32(node, "qcom,ki-coeff-dischg-med-hi-thresh-ma",
+		&chip->dt.ki_coeff_med_hi_dchg_thr_ma);
+
+	chip->dt.ki_coeff_cutoff_gain = -EINVAL;
+	of_property_read_u32(node, "qcom,ki-coeff-cutoff",
+		&chip->dt.ki_coeff_cutoff_gain);
+
+	for (i = 0; i < KI_COEFF_SOC_LEVELS; i++) {
+		chip->dt.ki_coeff_low_dischg[i] = KI_COEFF_LOW_DISCHG_DEFAULT;
+		chip->dt.ki_coeff_med_dischg[i] = KI_COEFF_MED_DISCHG_DEFAULT;
+		chip->dt.ki_coeff_hi_dischg[i] = KI_COEFF_HI_DISCHG_DEFAULT;
+	}
+
+	if (!of_find_property(node, "qcom,ki-coeff-soc-dischg", NULL) ||
+		(!of_find_property(node, "qcom,ki-coeff-low-dischg", NULL) &&
+		!of_find_property(node, "qcom,ki-coeff-med-dischg", NULL) &&
+		!of_find_property(node, "qcom,ki-coeff-hi-dischg", NULL)))
+		return 0;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,ki-coeff-soc-dischg",
+		chip->dt.ki_coeff_soc, KI_COEFF_SOC_LEVELS);
+	if (rc < 0)
+		return rc;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,ki-coeff-low-dischg",
+		chip->dt.ki_coeff_low_dischg, KI_COEFF_SOC_LEVELS);
+	if (rc < 0)
+		return rc;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,ki-coeff-med-dischg",
+		chip->dt.ki_coeff_med_dischg, KI_COEFF_SOC_LEVELS);
+	if (rc < 0)
+		return rc;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,ki-coeff-hi-dischg",
+		chip->dt.ki_coeff_hi_dischg, KI_COEFF_SOC_LEVELS);
+	if (rc < 0)
+		return rc;
+
+	for (i = 0; i < KI_COEFF_SOC_LEVELS; i++) {
+		if (chip->dt.ki_coeff_soc[i] < 0 ||
+			chip->dt.ki_coeff_soc[i] > FULL_CAPACITY) {
+			pr_err("Error in ki_coeff_soc_dischg values\n");
+			return -EINVAL;
+		}
+
+		if (chip->dt.ki_coeff_low_dischg[i] < 0 ||
+			chip->dt.ki_coeff_low_dischg[i] > KI_COEFF_MAX) {
+			pr_err("Error in ki_coeff_low_dischg values\n");
+			return -EINVAL;
+		}
+
+		if (chip->dt.ki_coeff_med_dischg[i] < 0 ||
+			chip->dt.ki_coeff_med_dischg[i] > KI_COEFF_MAX) {
+			pr_err("Error in ki_coeff_med_dischg values\n");
+			return -EINVAL;
+		}
+
+		if (chip->dt.ki_coeff_hi_dischg[i] < 0 ||
+			chip->dt.ki_coeff_hi_dischg[i] > KI_COEFF_MAX) {
+			pr_err("Error in ki_coeff_hi_dischg values\n");
+			return -EINVAL;
+		}
+	}
+	chip->ki_coeff_dischg_en = true;
+	return 0;
+}
+
+#define DEFAULT_ESR_DISABLE_COUNT	5
+#define DEFAULT_ESR_FILTER_FACTOR	2
+#define DEFAULT_DELTA_ESR_THR		1832
+static int fg_parse_esr_cal_params(struct fg_dev *fg)
+{
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+	struct device_node *node = fg->dev->of_node;
+	int rc, i, temp;
+
+	if (chip->dt.esr_timer_dischg_slow[TIMER_RETRY] >= 0 &&
+			chip->dt.esr_timer_dischg_slow[TIMER_MAX] >= 0) {
+		/* ESR calibration only during discharging */
+		chip->dt.esr_calib_dischg = of_property_read_bool(node,
+						"qcom,fg-esr-calib-dischg");
+		if (chip->dt.esr_calib_dischg)
+			return 0;
+	}
+
+	if (!of_find_property(node, "qcom,fg-esr-cal-soc-thresh", NULL) ||
+		!of_find_property(node, "qcom,fg-esr-cal-temp-thresh", NULL))
+		return 0;
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,fg-esr-cal-soc-thresh",
+		chip->dt.esr_cal_soc_thresh, ESR_CAL_LEVELS);
+	if (rc < 0) {
+		pr_err("Invalid SOC thresholds for ESR fast cal, rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = fg_parse_dt_property_u32_array(node, "qcom,fg-esr-cal-temp-thresh",
+		chip->dt.esr_cal_temp_thresh, ESR_CAL_LEVELS);
+	if (rc < 0) {
+		pr_err("Invalid temperature thresholds for ESR fast cal, rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	for (i = 0; i < ESR_CAL_LEVELS; i++) {
+		if (chip->dt.esr_cal_soc_thresh[i] > FULL_SOC_RAW) {
+			pr_err("esr_cal_soc_thresh value shouldn't exceed %d\n",
+				FULL_SOC_RAW);
+			return -EINVAL;
+		}
+
+		if (chip->dt.esr_cal_temp_thresh[i] < ESR_CAL_TEMP_MIN ||
+			chip->dt.esr_cal_temp_thresh[i] > ESR_CAL_TEMP_MAX) {
+			pr_err("esr_cal_temp_thresh value should be within [%d %d]\n",
+				ESR_CAL_TEMP_MIN, ESR_CAL_TEMP_MAX);
+			return -EINVAL;
+		}
+	}
+
+	chip->dt.delta_esr_disable_count = DEFAULT_ESR_DISABLE_COUNT;
+	rc = of_property_read_u32(node, "qcom,fg-delta-esr-disable-count",
+		&temp);
+	if (!rc)
+		chip->dt.delta_esr_disable_count = temp;
+
+	chip->dt.esr_filter_factor = DEFAULT_ESR_FILTER_FACTOR;
+	rc = of_property_read_u32(node, "qcom,fg-esr-filter-factor",
+		&temp);
+	if (!rc)
+		chip->dt.esr_filter_factor = temp;
+
+	chip->dt.delta_esr_thr_uohms = DEFAULT_DELTA_ESR_THR;
+	rc = of_property_read_u32(node, "qcom,fg-delta-esr-thr", &temp);
+	if (!rc)
+		chip->dt.delta_esr_thr_uohms = temp;
+
+	chip->esr_fast_calib = true;
+	return 0;
+}
+
+static int fg_gen4_parse_nvmem_dt(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int rc;
+
+	if (of_find_property(fg->dev->of_node, "nvmem", NULL)) {
+		chip->fg_nvmem = devm_nvmem_device_get(fg->dev, "fg_sdam");
+		if (IS_ERR_OR_NULL(chip->fg_nvmem)) {
+			rc = PTR_ERR(chip->fg_nvmem);
+			if (rc != -EPROBE_DEFER) {
+				dev_err(fg->dev, "Couldn't get nvmem device, rc=%d\n",
+					rc);
+				return -ENODEV;
+			}
+			chip->fg_nvmem = NULL;
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+#define DEFAULT_CUTOFF_VOLT_MV		3100
+#define DEFAULT_EMPTY_VOLT_MV		2812
+#define DEFAULT_SYS_MIN_VOLT_MV		2800
+#define DEFAULT_SYS_TERM_CURR_MA	-125
+#define DEFAULT_FFC_SYS_TERM_CURR_MA        -1125
+#define DEFAULT_CUTOFF_CURR_MA		200
+#define DEFAULT_DELTA_SOC_THR		5	/* 0.5 % */
+#define DEFAULT_CL_START_SOC		15
+#define DEFAULT_CL_MIN_TEMP_DECIDEGC	150
+#define DEFAULT_CL_MAX_TEMP_DECIDEGC	500
+#define DEFAULT_CL_MAX_INC_DECIPERC	5
+#define DEFAULT_CL_MAX_DEC_DECIPERC	100
+#define DEFAULT_CL_MIN_LIM_DECIPERC	0
+#define DEFAULT_CL_MAX_LIM_DECIPERC	0
+#define DEFAULT_CL_DELTA_BATT_SOC	10
+#define BTEMP_DELTA_LOW			0
+/* set BTEMP_DELTA_HIGH to 10 to avoid batt-temp-delta irq wakeup frequently */
+#define BTEMP_DELTA_HIGH		10
+#define DEFAULT_ESR_PULSE_THRESH_MA	47
+#define DEFAULT_ESR_MEAS_CURR_MA	120
+#define DEFAULT_SCALE_VBATT_THR_MV	3400
+#define DEFAULT_SCALE_ALARM_TIMER_MS	10000
+static int fg_gen4_parse_dt(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	struct device_node *child, *revid_node, *node = fg->dev->of_node;
+	u32 base, temp;
+	u8 subtype;
+	int rc;
+	int size;
+
+	if (!node)  {
+		dev_err(fg->dev, "device tree node missing\n");
+		return -ENXIO;
+	}
+
+	revid_node = of_parse_phandle(node, "qcom,pmic-revid", 0);
+	if (!revid_node) {
+		pr_err("Missing qcom,pmic-revid property - driver failed\n");
+		return -EINVAL;
+	}
+
+	fg->pmic_rev_id = get_revid_data(revid_node);
+	of_node_put(revid_node);
+	if (IS_ERR_OR_NULL(fg->pmic_rev_id)) {
+		pr_err("Unable to get pmic_revid rc=%ld\n",
+			PTR_ERR(fg->pmic_rev_id));
+		/*
+		 * the revid peripheral must be registered, any failure
+		 * here only indicates that the rev-id module has not
+		 * probed yet.
+		 */
+		return -EPROBE_DEFER;
+	}
+
+	pr_debug("PMIC subtype %d Digital major %d\n",
+		fg->pmic_rev_id->pmic_subtype, fg->pmic_rev_id->rev4);
+
+	switch (fg->pmic_rev_id->pmic_subtype) {
+	case PM8150B_SUBTYPE:
+		fg->version = GEN4_FG;
+		fg->use_dma = true;
+		fg->sp = pm8150b_v2_sram_params;
+		if (fg->pmic_rev_id->rev4 == PM8150B_V1P0_REV4) {
+			fg->sp = pm8150b_v1_sram_params;
+			fg->wa_flags |= PM8150B_V1_DMA_WA;
+			fg->wa_flags |= PM8150B_V1_RSLOW_COMP_WA;
+		} else if (fg->pmic_rev_id->rev4 == PM8150B_V2P0_REV4) {
+			fg->wa_flags |= PM8150B_V2_RSLOW_SCALE_FN_WA;
+		}
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (of_find_property(node, "qcom,pmic-pbs", NULL)) {
+		chip->pbs_dev = of_parse_phandle(node, "qcom,pmic-pbs", 0);
+		if (!chip->pbs_dev) {
+			pr_err("Missing qcom,pmic-pbs property\n");
+			return -ENODEV;
+		}
+	}
+
+	rc = fg_gen4_parse_nvmem_dt(chip);
+	if (rc < 0)
+		return rc;
+
+	if (of_get_available_child_count(node) == 0) {
+		dev_err(fg->dev, "No child nodes specified!\n");
+		return -ENXIO;
+	}
+
+	for_each_available_child_of_node(node, child) {
+		rc = of_property_read_u32(child, "reg", &base);
+		if (rc < 0) {
+			dev_err(fg->dev, "reg not specified in node %s, rc=%d\n",
+				child->full_name, rc);
+			return rc;
+		}
+
+		rc = fg_read(fg, base + PERPH_SUBTYPE_REG, &subtype, 1);
+		if (rc < 0) {
+			dev_err(fg->dev, "Couldn't read subtype for base %d, rc=%d\n",
+				base, rc);
+			return rc;
+		}
+
+		switch (subtype) {
+		case FG_BATT_SOC_PM8150B:
+			fg->batt_soc_base = base;
+			break;
+		case FG_BATT_INFO_PM8150B:
+			fg->batt_info_base = base;
+			break;
+		case FG_MEM_IF_PM8150B:
+			fg->mem_if_base = base;
+			break;
+		case FG_ADC_RR_PM8150B:
+			fg->rradc_base = base;
+			break;
+		default:
+			dev_err(fg->dev, "Invalid peripheral subtype 0x%x\n",
+				subtype);
+			return -ENXIO;
+		}
+	}
+
+	/* Read all the optional properties below */
+	rc = of_property_read_u32(node, "qcom,fg-cutoff-voltage", &temp);
+	if (rc < 0)
+		chip->dt.cutoff_volt_mv = DEFAULT_CUTOFF_VOLT_MV;
+	else
+		chip->dt.cutoff_volt_mv = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-cutoff-current", &temp);
+	if (rc < 0)
+		chip->dt.cutoff_curr_ma = DEFAULT_CUTOFF_CURR_MA;
+	else
+		chip->dt.cutoff_curr_ma = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-empty-voltage", &temp);
+	if (rc < 0)
+		chip->dt.empty_volt_mv = DEFAULT_EMPTY_VOLT_MV;
+	else
+		chip->dt.empty_volt_mv = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-sys-term-current", &temp);
+	if (rc < 0)
+		chip->dt.sys_term_curr_ma = DEFAULT_SYS_TERM_CURR_MA;
+	else
+		chip->dt.sys_term_curr_ma = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-ffc-sys-term-current", &temp);
+        if (rc < 0)
+                chip->dt.ffc_sys_term_curr_ma = DEFAULT_FFC_SYS_TERM_CURR_MA;
+        else
+                chip->dt.ffc_sys_term_curr_ma = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-delta-soc-thr", &temp);
+	if (rc < 0)
+		chip->dt.delta_soc_thr = DEFAULT_DELTA_SOC_THR;
+	else
+		chip->dt.delta_soc_thr = temp;
+
+	if (chip->dt.delta_soc_thr < 0 || chip->dt.delta_soc_thr >= 125) {
+		pr_err("Invalid delta SOC threshold=%d\n",
+		       chip->dt.delta_soc_thr);
+		return -EINVAL;
+	}
+
+	size = 0;
+	of_get_property(node, "qcom,soc_decimal_rate", &size);
+	if (size) {
+		chip->dt.dec_rate_seq = devm_kzalloc(fg->dev,
+				size, GFP_KERNEL);
+		if (chip->dt.dec_rate_seq) {
+			chip->dt.dec_rate_len =
+				(size / sizeof(*chip->dt.dec_rate_seq));
+			if (chip->dt.dec_rate_len % 2) {
+				pr_err("invalid soc decimal rate seq\n");
+				return -EINVAL;
+			}
+			of_property_read_u32_array(node,
+					"qcom,soc_decimal_rate",
+					chip->dt.dec_rate_seq,
+					chip->dt.dec_rate_len);
+		} else {
+			pr_err("error allocating memory for dec_rate_seq\n");
+		}
+	}
+
+	chip->dt.esr_timer_chg_fast[TIMER_RETRY] = -EINVAL;
+	chip->dt.esr_timer_chg_fast[TIMER_MAX] = -EINVAL;
+	rc = fg_parse_dt_property_u32_array(node, "qcom,fg-esr-timer-chg-fast",
+		chip->dt.esr_timer_chg_fast, NUM_ESR_TIMERS);
+	if (rc < 0)
+		return rc;
+
+	chip->dt.esr_timer_dischg_fast[TIMER_RETRY] = -EINVAL;
+	chip->dt.esr_timer_dischg_fast[TIMER_MAX] = -EINVAL;
+	rc = fg_parse_dt_property_u32_array(node,
+		"qcom,fg-esr-timer-dischg-fast", chip->dt.esr_timer_dischg_fast,
+		NUM_ESR_TIMERS);
+	if (rc < 0)
+		return rc;
+
+	chip->dt.esr_timer_chg_slow[TIMER_RETRY] = -EINVAL;
+	chip->dt.esr_timer_chg_slow[TIMER_MAX] = -EINVAL;
+	rc = fg_parse_dt_property_u32_array(node, "qcom,fg-esr-timer-chg-slow",
+		chip->dt.esr_timer_chg_slow, NUM_ESR_TIMERS);
+	if (rc < 0)
+		return rc;
+
+	chip->dt.esr_timer_dischg_slow[TIMER_RETRY] = -EINVAL;
+	chip->dt.esr_timer_dischg_slow[TIMER_MAX] = -EINVAL;
+	rc = fg_parse_dt_property_u32_array(node,
+		"qcom,fg-esr-timer-dischg-slow", chip->dt.esr_timer_dischg_slow,
+		NUM_ESR_TIMERS);
+	if (rc < 0)
+		return rc;
+
+	chip->dt.force_load_profile = of_property_read_bool(node,
+					"qcom,fg-force-load-profile");
+
+	rc = of_property_read_u32(node, "qcom,cl-start-capacity", &temp);
+	if (rc < 0)
+		chip->cl->dt.max_start_soc = DEFAULT_CL_START_SOC;
+	else
+		chip->cl->dt.max_start_soc = temp;
+
+	chip->cl->dt.min_delta_batt_soc = DEFAULT_CL_DELTA_BATT_SOC;
+	/* read from DT property and update, if value exists */
+	of_property_read_u32(node, "qcom,cl-min-delta-batt-soc",
+					&chip->cl->dt.min_delta_batt_soc);
+
+	rc = of_property_read_u32(node, "qcom,cl-min-temp", &temp);
+	if (rc < 0)
+		chip->cl->dt.min_temp = DEFAULT_CL_MIN_TEMP_DECIDEGC;
+	else
+		chip->cl->dt.min_temp = temp;
+
+	rc = of_property_read_u32(node, "qcom,cl-max-temp", &temp);
+	if (rc < 0)
+		chip->cl->dt.max_temp = DEFAULT_CL_MAX_TEMP_DECIDEGC;
+	else
+		chip->cl->dt.max_temp = temp;
+
+	rc = of_property_read_u32(node, "qcom,cl-max-increment", &temp);
+	if (rc < 0)
+		chip->cl->dt.max_cap_inc = DEFAULT_CL_MAX_INC_DECIPERC;
+	else
+		chip->cl->dt.max_cap_inc = temp;
+
+	rc = of_property_read_u32(node, "qcom,cl-max-decrement", &temp);
+	if (rc < 0)
+		chip->cl->dt.max_cap_dec = DEFAULT_CL_MAX_DEC_DECIPERC;
+	else
+		chip->cl->dt.max_cap_dec = temp;
+
+	rc = of_property_read_u32(node, "qcom,cl-min-limit", &temp);
+	if (rc < 0)
+		chip->cl->dt.min_cap_limit = DEFAULT_CL_MIN_LIM_DECIPERC;
+	else
+		chip->cl->dt.min_cap_limit = temp;
+
+	rc = of_property_read_u32(node, "qcom,cl-max-limit", &temp);
+	if (rc < 0)
+		chip->cl->dt.max_cap_limit = DEFAULT_CL_MAX_LIM_DECIPERC;
+	else
+		chip->cl->dt.max_cap_limit = temp;
+
+	of_property_read_u32(node, "qcom,cl-skew", &chip->cl->dt.skew_decipct);
+
+	if (of_property_read_bool(node, "qcom,cl-wt-enable")) {
+		chip->cl->dt.cl_wt_enable = true;
+		chip->cl->dt.max_start_soc = -EINVAL;
+		chip->cl->dt.min_start_soc = -EINVAL;
+	}
+
+	chip->cl->dt.ibat_flt_thr_ma = 100;
+	of_property_read_u32(node, "qcom,cl-ibat-flt-thresh-ma",
+		&chip->cl->dt.ibat_flt_thr_ma);
+
+	rc = of_property_read_u32(node, "qcom,fg-batt-temp-hot", &temp);
+	if (rc < 0)
+		chip->dt.batt_temp_hot_thresh = -EINVAL;
+	else
+		chip->dt.batt_temp_hot_thresh = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-batt-temp-cold", &temp);
+	if (rc < 0)
+		chip->dt.batt_temp_cold_thresh = -EINVAL;
+	else
+		chip->dt.batt_temp_cold_thresh = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-batt-temp-hyst", &temp);
+	if (rc < 0)
+		chip->dt.batt_temp_hyst = -EINVAL;
+	else if (temp >= BTEMP_DELTA_LOW && temp <= BTEMP_DELTA_HIGH)
+		chip->dt.batt_temp_hyst = temp;
+
+	rc = of_property_read_u32(node, "qcom,fg-batt-temp-delta", &temp);
+	if (rc < 0)
+		chip->dt.batt_temp_delta = -EINVAL;
+	else if (temp >= BTEMP_DELTA_LOW && temp <= BTEMP_DELTA_HIGH)
+		chip->dt.batt_temp_delta = temp;
+
+	chip->dt.batt_therm_freq = 8;
+	rc = of_property_read_u32(node, "qcom,fg-batt-therm-freq", &temp);
+	if (temp > 0 && temp <= 255)
+		chip->dt.batt_therm_freq = temp;
+
+	chip->dt.soc_scale_mode = of_property_read_bool(node,
+						"qcom,soc-scale-mode-en");
+	if (chip->dt.soc_scale_mode) {
+		chip->dt.vbatt_scale_thr_mv = DEFAULT_SCALE_VBATT_THR_MV;
+		of_property_read_u32(node, "qcom,soc-scale-vbatt-mv",
+					&chip->dt.vbatt_scale_thr_mv);
+		chip->dt.scale_timer_ms = DEFAULT_SCALE_ALARM_TIMER_MS;
+		of_property_read_u32(node, "qcom,soc-scale-time-ms",
+					&chip->dt.scale_timer_ms);
+	}
+
+	chip->dt.force_calib_level = -EINVAL;
+	of_property_read_u32(node, "qcom,force-calib-level",
+					&chip->dt.force_calib_level);
+
+	rc = fg_parse_ki_coefficients(fg);
+	if (rc < 0)
+		pr_err("Error in parsing Ki coefficients, rc=%d\n", rc);
+
+	rc = of_property_read_u32(node, "qcom,fg-rconn-uohms", &temp);
+	if (!rc)
+		chip->dt.rconn_uohms = temp;
+
+	rc = fg_parse_slope_limit_coefficients(fg);
+	if (rc < 0)
+		pr_err("Error in parsing slope limit coeffs, rc=%d\n", rc);
+
+	chip->dt.esr_pulse_thresh_ma = DEFAULT_ESR_PULSE_THRESH_MA;
+	rc = of_property_read_u32(node, "qcom,fg-esr-pulse-thresh-ma", &temp);
+	if (!rc) {
+		if (temp > 0 && temp < 1000)
+			chip->dt.esr_pulse_thresh_ma = temp;
+	}
+
+	chip->dt.esr_meas_curr_ma = DEFAULT_ESR_MEAS_CURR_MA;
+	rc = of_property_read_u32(node, "qcom,fg-esr-meas-curr-ma", &temp);
+	if (!rc) {
+		/* ESR measurement current range is 60-240 mA */
+		if (temp >= 60 || temp <= 240)
+			chip->dt.esr_meas_curr_ma = temp;
+	}
+
+	rc = fg_parse_esr_cal_params(fg);
+	if (rc < 0)
+		return rc;
+
+	chip->dt.rapid_soc_dec_en = of_property_read_bool(node,
+					"qcom,rapid-soc-dec-en");
+
+	chip->dt.five_pin_battery = of_property_read_bool(node,
+					"qcom,five-pin-battery");
+	chip->dt.soc_hi_res = of_property_read_bool(node, "qcom,soc-hi-res");
+
+	chip->dt.sys_min_volt_mv = DEFAULT_SYS_MIN_VOLT_MV;
+	of_property_read_u32(node, "qcom,fg-sys-min-voltage",
+				&chip->dt.sys_min_volt_mv);
+
+	chip->cold_thermal_support = of_property_read_bool(node,
+			"qcom,cold-thermal-support");
+
+	size = 0;
+	of_get_property(node, "mi,cold_thermal_seq", &size);
+	if (size) {
+		fg->cold_thermal_seq = devm_kzalloc(fg->dev,
+				size, GFP_KERNEL);
+		if (fg->cold_thermal_seq) {
+			fg->cold_thermal_len =
+				(size / sizeof(int));
+			if (fg->cold_thermal_len % 4) {
+				pr_err("invalid cold thermal seq\n");
+				return -EINVAL;
+			}
+			of_property_read_u32_array(node,
+					"mi,cold_thermal_seq",
+					(int *)fg->cold_thermal_seq,
+					fg->cold_thermal_len);
+			fg->cold_thermal_len = fg->cold_thermal_len / 4;
+		} else {
+			pr_err("error allocating memory for cold thermal seq\n");
+		}
+	}
+
+	return 0;
+}
+
+#define SOC_WORK_MS     20000
+static void soc_work_fn(struct work_struct *work)
+{
+	struct fg_dev *fg = container_of(work,
+				struct fg_dev, soc_work.work);
+	struct fg_gen4_chip *chip = container_of(fg,
+				struct fg_gen4_chip, fg);
+	int msoc = 0, soc = 0, curr_ua = 0, volt_uv = 0, temp = 0;
+	int esr_uohms = 0;
+	int cycle_count;
+	int rc;
+	static int prev_soc = -EINVAL;
+
+	rc = fg_gen4_get_prop_capacity(fg, &soc);
+	if (rc < 0)
+		pr_err("Error in getting capacity, rc=%d\n", rc);
+
+	rc = fg_get_msoc_raw(fg, &msoc);
+	if (rc < 0)
+		pr_err("Error in getting msoc, rc=%d\n", rc);
+
+	rc = fg_get_battery_resistance(fg, &esr_uohms);
+	if (rc < 0)
+		pr_err("Error in getting esr_uohms, rc=%d\n", rc);
+
+	fg_get_battery_current(fg, &curr_ua);
+	if (rc < 0)
+		pr_err("failed to get current, rc=%d\n", rc);
+
+	rc = fg_get_battery_voltage(fg, &volt_uv);
+	if (rc < 0)
+		pr_err("failed to get voltage, rc=%d\n", rc);
+
+	rc = fg_gen4_get_battery_temp(fg, &temp);
+	if (rc < 0)
+		pr_err("Error in getting batt_temp, rc=%d\n", rc);
+
+	rc = get_cycle_count(chip->counter, &cycle_count);
+	if (rc < 0)
+		pr_err("failed to get cycle count, rc=%d\n", rc);
+
+	pr_info("adjust_soc: s %d r %d i %d v %d t %d cc %d m 0x%02x\n",
+			soc,
+			esr_uohms,
+			curr_ua/1000,
+			volt_uv/1000,
+			temp,
+			cycle_count,
+			msoc);
+
+	if (temp < 450 && fg->last_batt_temp >= 450) {
+		/* follow the way that fg_notifier_cb use wake lock */
+		pm_stay_awake(fg->dev);
+		schedule_work(&fg->status_change_work);
+	}
+
+	fg->last_batt_temp = temp;
+
+	/* if soc changes, report power supply changed uevent */
+	if (soc != prev_soc) {
+		if (fg->batt_psy)
+			power_supply_changed(fg->batt_psy);
+		prev_soc = soc;
+	}
+
+	schedule_delayed_work(
+		&fg->soc_work,
+		msecs_to_jiffies(SOC_WORK_MS));
+}
+
+static void empty_restart_fg_work(struct work_struct *work)
+{
+	struct fg_dev *fg = container_of(work, struct fg_dev,
+				    empty_restart_fg_work.work);
+	union power_supply_propval prop = {0, };
+	int usb_present = 0;
+	int rc;
+
+	if (usb_psy_initialized(fg)) {
+		rc = power_supply_get_property(fg->usb_psy,
+			POWER_SUPPLY_PROP_PRESENT, &prop);
+		if (rc < 0) {
+			pr_err("Couldn't read usb present prop rc=%d\n", rc);
+			return;
+		}
+		usb_present = prop.intval;
+	}
+
+	/* only when usb is absent, restart fg */
+	if (!usb_present) {
+		if (fg->profile_load_status == PROFILE_LOADED) {
+			pr_info("soc empty after cold to warm, need to restart fg\n");
+			fg->empty_restart_fg = true;
+			rc = fg_restart(fg, SOC_READY_WAIT_TIME_MS);
+			if (rc < 0) {
+				pr_err("Error in restarting FG, rc=%d\n", rc);
+				fg->empty_restart_fg = false;
+				return;
+			}
+			pr_info("FG restart done\n");
+			if (batt_psy_initialized(fg))
+				power_supply_changed(fg->batt_psy);
+		} else {
+			schedule_delayed_work(
+					&fg->empty_restart_fg_work,
+					msecs_to_jiffies(RESTART_FG_WORK_MS));
+		}
+	}
+}
+
+static int calculate_delta_time(struct timespec64 *time_stamp, int *delta_time_s)
+{
+	struct timespec64 now_time;
+
+	/* default to delta time = 0 if anything fails */
+	*delta_time_s = 0;
+
+	ktime_get_boottime_ts64(&now_time);
+	*delta_time_s = (now_time.tv_sec - time_stamp->tv_sec);
+
+	/* remember this time */
+	*time_stamp = now_time;
+	return 0;
+}
+
+static int calculate_average_current(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int i;
+	int iavg_ma = fg->param.batt_ma;
+
+	/* only continue if ibat has changed */
+	if (fg->param.batt_ma == fg->param.batt_ma_prev)
+		goto unchanged;
+	else
+		fg->param.batt_ma_prev = fg->param.batt_ma;
+
+	fg->param.batt_ma_avg_samples[fg->param.samples_index] = iavg_ma;
+	fg->param.samples_index = (fg->param.samples_index + 1) % BATT_MA_AVG_SAMPLES;
+	fg->param.samples_num++;
+
+	if (fg->param.samples_num >= BATT_MA_AVG_SAMPLES)
+		fg->param.samples_num = BATT_MA_AVG_SAMPLES;
+
+	if (fg->param.samples_num) {
+		iavg_ma = 0;
+		/* maintain a AVG_SAMPLES sample average of ibat */
+		for (i = 0; i < fg->param.samples_num; i++) {
+			pr_debug("iavg_samples_ma[%d] = %d\n", i, fg->param.batt_ma_avg_samples[i]);
+			iavg_ma += fg->param.batt_ma_avg_samples[i];
+		}
+		fg->param.batt_ma_avg = DIV_ROUND_CLOSEST(iavg_ma, fg->param.samples_num);
+	}
+
+unchanged:
+	pr_info("current_now_ma=%d averaged_iavg_ma=%d\n",
+				fg->param.batt_ma, fg->param.batt_ma_avg);
+	return fg->param.batt_ma_avg;
+}
+
+static void fg_battery_soc_smooth_tracking(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+	int delta_time = 0;
+	int soc_changed;
+	int last_batt_soc = fg->param.batt_soc;
+	int time_since_last_change_sec;
+
+	struct timespec64 last_change_time = fg->param.last_soc_change_time;
+
+	calculate_delta_time(&last_change_time, &time_since_last_change_sec);
+
+	if (fg->param.batt_temp > 150) {
+		/* Battery in normal temperture */
+		if (fg->param.batt_ma < 0 ||
+				(abs(fg->param.batt_raw_soc - fg->param.batt_soc) > 2))
+			delta_time = time_since_last_change_sec / 20;
+		else
+			delta_time = time_since_last_change_sec / 60;
+	} else {
+		/* Battery in low temperture */
+		calculate_average_current(chip);
+		/* Calculated average current > 1000mA */
+		if ((fg->param.batt_ma_avg > 1000000) ||
+				(abs(fg->param.batt_raw_soc - fg->param.batt_soc) > 2))
+			/* Heavy loading current, ignore battery soc limit*/
+			delta_time = time_since_last_change_sec / 10;
+		else
+			delta_time = time_since_last_change_sec / 20;
+	}
+
+	if (delta_time < 0)
+		delta_time = 0;
+
+	soc_changed = min(1, delta_time);
+
+	if (last_batt_soc >= 0) {
+		if (last_batt_soc != 100
+				&& fg->param.batt_raw_soc >= 95
+				&& fg->charge_status == POWER_SUPPLY_STATUS_FULL)
+			// Unlikely status
+			last_batt_soc = fg->param.update_now ?
+				100 : last_batt_soc + soc_changed;
+		else if (last_batt_soc < fg->param.batt_raw_soc &&
+			fg->param.batt_ma < 0)
+			/* Battery in charging status
+			* update the soc when resuming device
+			*/
+			last_batt_soc = fg->param.update_now ?
+				fg->param.batt_raw_soc : last_batt_soc + soc_changed;
+		else if (last_batt_soc > fg->param.batt_raw_soc
+					&& fg->param.batt_ma > 0
+					&& fg->charge_status != POWER_SUPPLY_STATUS_FULL)
+			/* Battery in discharging status
+			* update the soc when resuming device
+			*/
+			last_batt_soc = fg->param.update_now ?
+				fg->param.batt_raw_soc : last_batt_soc - soc_changed;
+
+		fg->param.update_now = false;
+	} else {
+		last_batt_soc = fg->param.batt_raw_soc;
+	}
+
+	if (fg->param.batt_soc != last_batt_soc) {
+		fg->param.batt_soc = last_batt_soc;
+		fg->param.last_soc_change_time = last_change_time;
+		if (batt_psy_initialized(fg))
+			power_supply_changed(fg->batt_psy);
+	}
+
+	pr_info("soc:%d, last_soc:%d, raw_soc:%d, soc_changed:%d.\n",
+				fg->param.batt_soc, last_batt_soc,
+				fg->param.batt_raw_soc, soc_changed);
+}
+
+static int fg_dynamic_set_cutoff_voltage(struct fg_dev *fg,
+			int cut_off_mv)
+{
+	int rc;
+	u8 buf[4];
+
+	pr_err("set dynamic cutoff voltage to: %d\n", cut_off_mv);
+
+	fg_encode(fg->sp, FG_SRAM_CUTOFF_VOLT, cut_off_mv, buf);
+	rc = fg_sram_write(fg, fg->sp[FG_SRAM_CUTOFF_VOLT].addr_word,
+			fg->sp[FG_SRAM_CUTOFF_VOLT].addr_byte, buf,
+			fg->sp[FG_SRAM_CUTOFF_VOLT].len, FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in writing cutoff_volt, rc=%d\n", rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+#define LOW_DISCHARGE_TEMP_TRH			150
+#define LOW_DISCHARGE_TEMP_HYS			20
+#define LOW_TEMP_CUTOFF_VOL_MV			3200
+#define MONITOR_SOC_WAIT_MS	1000
+#define MONITOR_SOC_WAIT_PER_MS	10000
+static void soc_monitor_work(struct work_struct *work)
+{
+	int rc;
+	struct fg_dev *fg = container_of(work,
+				struct fg_dev,
+				soc_monitor_work.work);
+	struct fg_gen4_chip *chip = container_of(fg, struct fg_gen4_chip, fg);
+
+	// Update battery information
+	rc = fg_get_battery_current(fg, &fg->param.batt_ma);
+	if (rc < 0)
+		pr_err("failded to get battery current, rc=%d\n", rc);
+
+	rc = fg_gen4_get_prop_capacity(fg, &fg->param.batt_raw_soc);
+	if (rc < 0)
+		pr_err("failed to get battery capacity, rc=%d\n", rc);
+
+	rc = fg_gen4_get_battery_temp(fg, &fg->param.batt_temp);
+	if (rc < 0)
+		pr_err("failed to get battery temperature, rc=%d\n", rc);
+
+	if (fg->soc_reporting_ready)
+		fg_battery_soc_smooth_tracking(chip);
+
+	pr_info("soc:%d, raw_soc:%d, c:%d, s:%d\n",
+			fg->param.batt_soc, fg->param.batt_raw_soc,
+			fg->param.batt_ma, fg->charge_status);
+
+	if (chip->cold_thermal_support) {
+		if (!fg->batt_temp_low
+				&& fg->param.batt_temp <= LOW_DISCHARGE_TEMP_TRH) {
+			rc = fg_dynamic_set_cutoff_voltage(fg, LOW_TEMP_CUTOFF_VOL_MV);
+			if (rc < 0)
+				pr_err("fg_dynamic_set_cutoff_voltage set failed\n");
+			fg->batt_temp_low = true;
+		} else if (fg->batt_temp_low && (fg->param.batt_temp
+				> LOW_DISCHARGE_TEMP_TRH + LOW_DISCHARGE_TEMP_HYS)) {
+			fg_dynamic_set_cutoff_voltage(fg, chip->dt.cutoff_volt_mv);
+			fg->batt_temp_low = false;
+		}
+	}
+
+	schedule_delayed_work(&fg->soc_monitor_work,
+			msecs_to_jiffies(MONITOR_SOC_WAIT_PER_MS));
+}
+
+static void fg_gen4_cleanup(struct fg_gen4_chip *chip)
+{
+	struct fg_dev *fg = &chip->fg;
+
+	fg_unregister_interrupts(fg, chip, FG_GEN4_IRQ_MAX);
+
+	cancel_work(&fg->status_change_work);
+	if (chip->soc_scale_mode)
+		fg_gen4_exit_soc_scale(chip);
+
+	cancel_delayed_work_sync(&fg->profile_load_work);
+	cancel_delayed_work_sync(&fg->empty_restart_fg_work);
+	cancel_delayed_work_sync(&fg->sram_dump_work);
+	cancel_delayed_work_sync(&fg->soc_work);
+	cancel_work_sync(&chip->pl_current_en_work);
+
+	power_supply_unreg_notifier(&fg->nb);
+	debugfs_remove_recursive(fg->dfs_root);
+
+	if (fg->awake_votable)
+		destroy_votable(fg->awake_votable);
+
+	if (fg->delta_bsoc_irq_en_votable)
+		destroy_votable(fg->delta_bsoc_irq_en_votable);
+
+	if (chip->delta_esr_irq_en_votable)
+		destroy_votable(chip->delta_esr_irq_en_votable);
+
+	if (chip->parallel_current_en_votable)
+		destroy_votable(chip->parallel_current_en_votable);
+
+	if (chip->mem_attn_irq_en_votable)
+		destroy_votable(chip->mem_attn_irq_en_votable);
+
+	dev_set_drvdata(fg->dev, NULL);
+}
+
+static void fg_gen4_post_init(struct fg_gen4_chip *chip)
+{
+	int i;
+	struct fg_dev *fg = &chip->fg;
+
+	if (!is_debug_batt_id(fg))
+		return;
+
+	/* Disable all wakeable IRQs for a debug battery */
+	vote(fg->delta_bsoc_irq_en_votable, DEBUG_BOARD_VOTER, false, 0);
+	vote(chip->delta_esr_irq_en_votable, DEBUG_BOARD_VOTER, false, 0);
+	vote(chip->mem_attn_irq_en_votable, DEBUG_BOARD_VOTER, false, 0);
+
+	for (i = 0; i < FG_GEN4_IRQ_MAX; i++) {
+		if (fg->irqs[i].irq && fg->irqs[i].wakeable) {
+			if (i == BSOC_DELTA_IRQ || i == ESR_DELTA_IRQ ||
+					i == MEM_ATTN_IRQ) {
+				continue;
+			} else {
+				disable_irq_wake(fg->irqs[i].irq);
+				disable_irq_nosync(fg->irqs[i].irq);
+			}
+		}
+	}
+
+	fg_dbg(fg, FG_STATUS, "Disabled wakeable irqs for debug board\n");
+}
+
+#define IBAT_OLD_WORD		317
+#define IBAT_OLD_OFFSET		0
+#define BATT_CURRENT_NUMR		488281
+#define BATT_CURRENT_DENR		1000
+int fg_get_batt_isense(struct fg_dev *fg, int *val)
+{
+	int rc;
+	u8 buf[2];
+	int64_t temp = 0;
+
+	rc = fg_sram_read(fg, IBAT_OLD_WORD, IBAT_OLD_OFFSET, buf, 2,
+			FG_IMA_DEFAULT);
+	if (rc < 0) {
+		pr_err("Error in reading %04x[%d] rc=%d\n", IBAT_OLD_WORD,
+				IBAT_OLD_OFFSET, rc);
+		return rc;
+	}
+
+	temp = buf[0] | buf[1] << 8;
+
+	/* Sign bit is bit 15 */
+	temp = sign_extend32(temp, 15);
+	*val = div_s64((s64)temp * BATT_CURRENT_NUMR, BATT_CURRENT_DENR);
+	pr_info("read batt isense: %d[%d]%d\n",
+			(*val)/10, *val, (*val)/1000);
+
+	return 0;
+}
+
+static int fg_gen4_probe(struct platform_device *pdev)
+{
+	struct fg_gen4_chip *chip;
+	struct fg_dev *fg;
+	struct power_supply_config fg_psy_cfg;
+	int rc, msoc, volt_uv, batt_temp;
+
+	chip = devm_kzalloc(&pdev->dev, sizeof(*chip), GFP_KERNEL);
+	if (!chip)
+		return -ENOMEM;
+
+	fg = &chip->fg;
+	fg->dev = &pdev->dev;
+	fg->debug_mask = &fg_gen4_debug_mask;
+	fg->irqs = fg_irqs;
+	fg->charge_status = -EINVAL;
+	fg->online_status = -EINVAL;
+	fg->batt_id_ohms = -EINVAL;
+	chip->ki_coeff_full_soc[0] = -EINVAL;
+	chip->ki_coeff_full_soc[1] = -EINVAL;
+	chip->esr_soh_cycle_count = -EINVAL;
+	fg->vbat_critical_low_count = 0;
+	fg->vbatt_full_volt_uv = 0;
+	fg->curr_cold_thermal_level = 1;
+	chip->calib_level = -EINVAL;
+	fg->fake_authentic = -EINVAL;
+	fg->fake_chip_ok = -EINVAL;
+	fg->batt_fake_temp = -EINVAL;
+	fg->regmap = dev_get_regmap(fg->dev->parent, NULL);
+	if (!fg->regmap) {
+		dev_err(fg->dev, "Parent regmap is unavailable\n");
+		return -ENXIO;
+	}
+
+	mutex_init(&fg->bus_lock);
+	mutex_init(&fg->sram_rw_lock);
+	mutex_init(&fg->charge_full_lock);
+	mutex_init(&chip->soc_scale_lock);
+	mutex_init(&chip->esr_calib_lock);
+	init_completion(&fg->soc_update);
+	init_completion(&fg->soc_ready);
+	init_completion(&chip->mem_attn);
+	INIT_WORK(&fg->status_change_work, status_change_work);
+	INIT_WORK(&chip->esr_calib_work, esr_calib_work);
+        INIT_WORK(&chip->vbat_sync_work, vbat_sync_work);
+	INIT_WORK(&chip->soc_scale_work, soc_scale_work);
+	INIT_DELAYED_WORK(&fg->profile_load_work, profile_load_work);
+	INIT_DELAYED_WORK(&fg->sram_dump_work, sram_dump_work);
+	INIT_DELAYED_WORK(&fg->soc_work, soc_work_fn);
+	INIT_DELAYED_WORK(&fg->empty_restart_fg_work, empty_restart_fg_work);
+	INIT_DELAYED_WORK(&chip->pl_enable_work, pl_enable_work);
+	INIT_WORK(&chip->pl_current_en_work, pl_current_en_work);
+	INIT_DELAYED_WORK(&fg->soc_monitor_work, soc_monitor_work);
+
+	fg->awake_votable = create_votable("FG_WS", VOTE_SET_ANY,
+					fg_awake_cb, fg);
+	if (IS_ERR(fg->awake_votable)) {
+		rc = PTR_ERR(fg->awake_votable);
+		fg->awake_votable = NULL;
+		goto exit;
+	}
+
+	fg->delta_bsoc_irq_en_votable = create_votable("FG_DELTA_BSOC_IRQ",
+						VOTE_SET_ANY,
+						fg_delta_bsoc_irq_en_cb, fg);
+	if (IS_ERR(fg->delta_bsoc_irq_en_votable)) {
+		rc = PTR_ERR(fg->delta_bsoc_irq_en_votable);
+		fg->delta_bsoc_irq_en_votable = NULL;
+		goto exit;
+	}
+
+	chip->delta_esr_irq_en_votable = create_votable("FG_DELTA_ESR_IRQ",
+						VOTE_SET_ANY,
+						fg_gen4_delta_esr_irq_en_cb,
+						chip);
+	if (IS_ERR(chip->delta_esr_irq_en_votable)) {
+		rc = PTR_ERR(chip->delta_esr_irq_en_votable);
+		chip->delta_esr_irq_en_votable = NULL;
+		goto exit;
+	}
+
+	chip->mem_attn_irq_en_votable = create_votable("FG_MEM_ATTN_IRQ",
+						VOTE_SET_ANY,
+						fg_gen4_mem_attn_irq_en_cb, fg);
+	if (IS_ERR(chip->mem_attn_irq_en_votable)) {
+		rc = PTR_ERR(chip->mem_attn_irq_en_votable);
+		chip->mem_attn_irq_en_votable = NULL;
+		goto exit;
+	}
+
+	chip->parallel_current_en_votable = create_votable("FG_SMB_MEAS_EN",
+						VOTE_SET_ANY,
+						fg_parallel_current_en_cb, fg);
+	if (IS_ERR(chip->parallel_current_en_votable)) {
+		rc = PTR_ERR(chip->parallel_current_en_votable);
+		chip->parallel_current_en_votable = NULL;
+		goto exit;
+	}
+
+	rc = fg_alg_init(chip);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in alg_init, rc:%d\n",
+			rc);
+		goto exit;
+	}
+
+	rc = fg_gen4_parse_dt(chip);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in reading DT parameters, rc:%d\n",
+			rc);
+		goto exit;
+	}
+
+	if (chip->esr_fast_calib) {
+		if (alarmtimer_get_rtcdev()) {
+			alarm_init(&chip->esr_fast_cal_timer, ALARM_BOOTTIME,
+				fg_esr_fast_cal_timer);
+		} else {
+			dev_err(fg->dev, "Failed to initialize esr_fast_cal timer\n");
+			rc = -EPROBE_DEFER;
+			goto exit;
+		}
+	}
+
+	if (chip->dt.soc_scale_mode) {
+		if (alarmtimer_get_rtcdev()) {
+			alarm_init(&chip->soc_scale_alarm_timer,
+				ALARM_BOOTTIME, fg_soc_scale_timer);
+		} else {
+			dev_err(fg->dev, "Failed to initialize SOC scale timer\n");
+			rc = -EPROBE_DEFER;
+			goto exit;
+		}
+	}
+
+	rc = fg_memif_init(fg);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in initializing FG_MEMIF, rc:%d\n",
+			rc);
+		goto exit;
+	}
+
+	platform_set_drvdata(pdev, chip);
+	rc = fg_gen4_hw_init(chip);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in initializing FG hardware, rc:%d\n",
+			rc);
+		goto exit;
+	}
+
+	/* Register the power supply */
+	fg_psy_cfg.drv_data = fg;
+	fg_psy_cfg.of_node = NULL;
+	fg_psy_cfg.supplied_to = NULL;
+	fg_psy_cfg.num_supplicants = 0;
+	fg->fg_psy = devm_power_supply_register(fg->dev, &fg_psy_desc,
+			&fg_psy_cfg);
+	if (IS_ERR(fg->fg_psy)) {
+		pr_err("failed to register fg_psy rc = %ld\n",
+				PTR_ERR(fg->fg_psy));
+		goto exit;
+	}
+
+	fg->nb.notifier_call = fg_notifier_cb;
+	rc = power_supply_reg_notifier(&fg->nb);
+	if (rc < 0) {
+		pr_err("Couldn't register psy notifier rc = %d\n", rc);
+		goto exit;
+	}
+
+	rc = fg_register_interrupts(&chip->fg, FG_GEN4_IRQ_MAX);
+	if (rc < 0) {
+		dev_err(fg->dev, "Error in registering interrupts, rc:%d\n",
+			rc);
+		goto exit;
+	}
+
+	if (fg->irqs[MEM_ATTN_IRQ].irq)
+		irq_set_status_flags(fg->irqs[MEM_ATTN_IRQ].irq,
+					IRQ_DISABLE_UNLAZY);
+
+	/* Keep SOC_UPDATE irq disabled until we require it */
+	if (fg->irqs[SOC_UPDATE_IRQ].irq)
+		disable_irq_nosync(fg->irqs[SOC_UPDATE_IRQ].irq);
+
+	/* Keep BSOC_DELTA_IRQ disabled until we require it */
+	vote(fg->delta_bsoc_irq_en_votable, DELTA_BSOC_IRQ_VOTER, false, 0);
+
+	/* Keep MEM_ATTN_IRQ disabled until we require it */
+	vote(chip->mem_attn_irq_en_votable, MEM_ATTN_IRQ_VOTER, false, 0);
+
+	fg_debugfs_create(fg);
+
+	rc = fg_get_battery_voltage(fg, &volt_uv);
+	if (!rc)
+		rc = fg_get_msoc(fg, &msoc);
+
+	if (!rc)
+		rc = fg_gen4_get_battery_temp(fg, &batt_temp);
+
+	if (!rc)
+		rc = fg_gen4_get_batt_id(chip);
+
+	if (!rc) {
+		fg->last_batt_temp = batt_temp;
+		pr_info("battery SOC:%d voltage: %duV temp: %d id: %d ohms\n",
+			msoc, volt_uv, batt_temp, fg->batt_id_ohms);
+	}
+
+	fg->tz_dev = devm_thermal_of_zone_register(fg->dev, 0, fg,
+							&fg_gen4_tz_ops);
+	if (IS_ERR_OR_NULL(fg->tz_dev)) {
+		rc = PTR_ERR(fg->tz_dev);
+		fg->tz_dev = NULL;
+		dev_dbg(fg->dev, "Couldn't register with thermal framework rc:%d\n",
+			rc);
+	}
+
+	device_init_wakeup(fg->dev, true);
+	if (!fg->battery_missing)
+		schedule_delayed_work(&fg->profile_load_work, 0);
+
+	fg_gen4_post_init(chip);
+	schedule_delayed_work(&fg->soc_work, 0);
+
+	fg->param.batt_soc = -EINVAL;
+	schedule_delayed_work(&fg->soc_monitor_work,
+				msecs_to_jiffies(MONITOR_SOC_WAIT_MS));
+
+	/*
+	 * if vbat is above 3.7V and msoc is 0% and battery temperature is
+	 * above 15 degree, we restart fg to do new first soc calculate to
+	 * improve user experience when device is shutdown in cold then
+	 * try to power on in normal temperature room.
+	 */
+	if ((volt_uv >= VBAT_RESTART_FG_EMPTY_UV)
+			&& (msoc == 0) && (batt_temp >= TEMP_THR_RESTART_FG))
+		schedule_delayed_work(&fg->empty_restart_fg_work,
+				msecs_to_jiffies(RESTART_FG_START_WORK_MS));
+
+	pr_debug("FG GEN4 driver probed successfully\n");
+	return 0;
+exit:
+	fg_gen4_cleanup(chip);
+	return rc;
+}
+
+static int fg_gen4_remove(struct platform_device *pdev)
+{
+	struct fg_gen4_chip *chip = dev_get_drvdata(&pdev->dev);
+
+	fg_gen4_cleanup(chip);
+	return 0;
+}
+
+static void fg_gen4_shutdown(struct platform_device *pdev)
+{
+	struct fg_gen4_chip *chip = dev_get_drvdata(&pdev->dev);
+	struct fg_dev *fg = &chip->fg;
+	int rc, bsoc, msoc;
+
+	fg_unregister_interrupts(fg, chip, FG_GEN4_IRQ_MAX);
+
+	if (chip->soc_scale_mode)
+		fg_gen4_exit_soc_scale(chip);
+
+	if (chip->rapid_soc_dec_en) {
+		rc = fg_gen4_rapid_soc_config(chip, false);
+		if (rc < 0)
+			pr_err("Error in reverting rapid SOC decrease config rc:%d\n",
+				rc);
+	}
+
+	rc = fg_gen4_get_prop_capacity(fg, &msoc);
+	if (rc < 0) {
+		pr_err("Error in getting capacity, rc=%d\n", rc);
+		return;
+	}
+
+	rc = fg_get_sram_prop(fg, FG_SRAM_BATT_SOC, &bsoc);
+	if (rc < 0) {
+		pr_err("Error in getting BATT_SOC, rc=%d\n", rc);
+		return;
+	}
+
+	/* if msoc is 100% when shutdown, write full soc for next reboot */
+	if (fg->charge_full || (msoc == 100)) {
+		/* We need 2 most significant bytes here */
+		bsoc = (u32)bsoc >> 16;
+
+		rc = fg_gen4_configure_full_soc(fg, bsoc);
+		if (rc < 0) {
+			pr_err("Error in configuring full_soc, rc=%d\n", rc);
+			return;
+		}
+	}
+
+	/*
+	 * Charging status doesn't matter when the device shuts down and we
+	 * have to treat this as charge done. Hence pass charge_done as true.
+	 */
+	cycle_count_update(chip->counter, (u32)bsoc >> 24,
+		POWER_SUPPLY_STATUS_NOT_CHARGING, true, is_input_present(fg));
+}
+
+static int fg_gen4_suspend(struct device *dev)
+{
+	struct fg_gen4_chip *chip = dev_get_drvdata(dev);
+	struct fg_dev *fg = &chip->fg;
+
+	cancel_delayed_work_sync(&fg->soc_work);
+	if (fg_sram_dump)
+		cancel_delayed_work_sync(&fg->sram_dump_work);
+	return 0;
+}
+
+static int fg_gen4_resume(struct device *dev)
+{
+	struct fg_gen4_chip *chip = dev_get_drvdata(dev);
+	struct fg_dev *fg = &chip->fg;
+	int val = 0;
+
+	if (!fg->input_present)
+		fg_get_batt_isense(fg, &val);
+
+	schedule_delayed_work(
+			&fg->soc_work, msecs_to_jiffies(SOC_WORK_MS));
+	if (fg_sram_dump)
+		schedule_delayed_work(&fg->sram_dump_work,
+				msecs_to_jiffies(fg_sram_dump_period_ms));
+
+	fg->param.update_now = true;
+	schedule_delayed_work(&fg->soc_monitor_work,
+				msecs_to_jiffies(MONITOR_SOC_WAIT_MS));
+	return 0;
+}
+
+static const struct dev_pm_ops fg_gen4_pm_ops = {
+	.suspend	= fg_gen4_suspend,
+	.resume		= fg_gen4_resume,
+};
+
+static const struct of_device_id fg_gen4_match_table[] = {
+	{.compatible = FG_GEN4_DEV_NAME},
+	{},
+};
+
+static struct platform_driver fg_gen4_driver = {
+	.driver = {
+		.name = FG_GEN4_DEV_NAME,
+		.owner = THIS_MODULE,
+		.of_match_table = fg_gen4_match_table,
+		.pm		= &fg_gen4_pm_ops,
+	},
+	.probe		= fg_gen4_probe,
+	.remove		= fg_gen4_remove,
+	.shutdown	= fg_gen4_shutdown,
+};
+
+module_platform_driver(fg_gen4_driver);
+
+MODULE_DESCRIPTION("QPNP Fuel gauge GEN4 driver");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:" FG_GEN4_DEV_NAME);
diff --git a/drivers/power/supply/qcom/qpnp-smb5.c b/drivers/power/supply/qcom/qpnp-smb5.c
new file mode 100644
index 000000000..e69de29bb
diff --git a/drivers/power/supply/qcom/smb5-lib.c b/drivers/power/supply/qcom/smb5-lib.c
new file mode 100644
index 000000000..b9355d7db
--- /dev/null
+++ b/drivers/power/supply/qcom/smb5-lib.c
@@ -0,0 +1,553 @@
+#include <linux/device.h>
+#include <linux/regmap.h>
+#include <linux/delay.h>
+#include <linux/power_supply.h>
+#include <linux/regulator/driver.h>
+#include <linux/irq.h>
+#include "smb5-lib.h"
+#include "smb5-reg.h"
+
+#define smblib_err(chg, fmt, ...)		\
+	pr_err("%s: %s: " fmt, chg->name,	\
+		__func__, ##__VA_ARGS__)	\
+
+#define smblib_dbg(chg, reason, fmt, ...)			\
+	do {							\
+		if (*chg->debug_mask & (reason))		\
+			pr_info("%s: %s: " fmt, chg->name,	\
+				__func__, ##__VA_ARGS__);	\
+		else						\
+			pr_debug("%s: %s: " fmt, chg->name,	\
+				__func__, ##__VA_ARGS__);	\
+	} while (0)
+
+int smblib_read(struct smb_charger *chg, u16 addr, u8 *val)
+{
+	unsigned int value;
+	int rc = 0;
+
+	rc = regmap_read(chg->regmap, addr, &value);
+	if (rc >= 0)
+		*val = (u8)value;
+
+	return rc;
+}
+
+int smblib_write(struct smb_charger *chg, u16 addr, u8 val)
+{
+	return regmap_write(chg->regmap, addr, val);
+}
+
+int smblib_masked_write(struct smb_charger *chg, u16 addr, u8 mask, u8 val)
+{
+	if (addr == TYPE_C_MODE_CFG_REG) {
+		smblib_dbg(chg, PR_MISC, "set 0x1544 mask:0x%x,val:0x%x\n",
+			mask, val);
+	}
+	return regmap_update_bits(chg->regmap, addr, mask, val);
+}
+
+int smblib_icl_override(struct smb_charger *chg, enum icl_override_mode  mode)
+{
+	int rc;
+	u8 usb51_mode, icl_override, apsd_override;
+
+	switch (mode) {
+	case SW_OVERRIDE_USB51_MODE:
+		usb51_mode = 0;
+		icl_override = ICL_OVERRIDE_BIT;
+		apsd_override = 0;
+		break;
+	case SW_OVERRIDE_HC_MODE:
+		usb51_mode = USBIN_MODE_CHG_BIT;
+		icl_override = 0;
+		apsd_override = ICL_OVERRIDE_AFTER_APSD_BIT;
+		break;
+	case HW_AUTO_MODE:
+	default:
+		usb51_mode = USBIN_MODE_CHG_BIT;
+		icl_override = 0;
+		apsd_override = 0;
+		break;
+	}
+
+	rc = smblib_masked_write(chg, USBIN_ICL_OPTIONS_REG,
+				USBIN_MODE_CHG_BIT, usb51_mode);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't set USBIN_ICL_OPTIONS rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, CMD_ICL_OVERRIDE_REG,
+				ICL_OVERRIDE_BIT, icl_override);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't override ICL rc=%d\n", rc);
+		return rc;
+	}
+
+	rc = smblib_masked_write(chg, USBIN_LOAD_CFG_REG,
+				ICL_OVERRIDE_AFTER_APSD_BIT, apsd_override);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't override ICL_AFTER_APSD rc=%d\n", rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+#define INPUT_NOT_PRESENT	0
+#define INPUT_PRESENT_USB	BIT(1)
+#define INPUT_PRESENT_DC	BIT(2)
+static int smblib_is_input_present(struct smb_charger *chg,
+				   int *present)
+{
+	int rc;
+	union power_supply_propval pval = {0, };
+
+	*present = INPUT_NOT_PRESENT;
+
+	rc = smblib_get_prop_usb_present(chg, &pval);
+	if (rc < 0) {
+		pr_err("Couldn't get usb presence status rc=%d\n", rc);
+		return rc;
+	}
+	*present |= pval.intval ? INPUT_PRESENT_USB : INPUT_NOT_PRESENT;
+
+	rc = smblib_get_prop_dc_present(chg, &pval);
+	if (rc < 0) {
+		pr_err("Couldn't get dc presence status rc=%d\n", rc);
+		return rc;
+	}
+	*present |= pval.intval ? INPUT_PRESENT_DC : INPUT_NOT_PRESENT;
+
+	return 0;
+}
+
+int smblib_set_charge_param(struct smb_charger *chg,
+			    struct smb_chg_param *param, int val_u)
+{
+	int rc = 0;
+	u8 val_raw;
+
+	if (param->set_proc) {
+		rc = param->set_proc(param, val_u, &val_raw);
+		if (rc < 0)
+			return -EINVAL;
+	} else {
+		if (val_u > param->max_u || val_u < param->min_u)
+			smblib_dbg(chg, PR_MISC,
+				"%s: %d is out of range [%d, %d]\n",
+				param->name, val_u, param->min_u, param->max_u);
+
+		if (val_u > param->max_u)
+			val_u = param->max_u;
+		if (val_u < param->min_u)
+			val_u = param->min_u;
+
+		val_raw = (val_u - param->min_u) / param->step_u;
+	}
+
+	rc = smblib_write(chg, param->reg, val_raw);
+	if (rc < 0) {
+		smblib_err(chg, "%s: Couldn't write 0x%02x to 0x%04x rc=%d\n",
+			param->name, val_raw, param->reg, rc);
+		return rc;
+	}
+
+	smblib_dbg(chg, PR_REGISTER, "%s = %d (0x%02x)\n",
+		   param->name, val_u, val_raw);
+
+	return rc;
+}
+
+int smblib_get_prop_from_bms(struct smb_charger *chg,
+				enum power_supply_property psp,
+				union power_supply_propval *val)
+{
+	int rc;
+
+	if (!chg->bms_psy)
+		return -EINVAL;
+
+	rc = power_supply_get_property(chg->bms_psy, psp, val);
+
+	return rc;
+}
+
+int smblib_get_prop_batt_present(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	int rc;
+	u8 stat;
+
+	rc = smblib_read(chg, BATIF_BASE + INT_RT_STS_OFFSET, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read BATIF_INT_RT_STS rc=%d\n", rc);
+		return rc;
+	}
+
+	val->intval = !(stat & (BAT_THERM_OR_ID_MISSING_RT_STS_BIT
+					| BAT_TERMINAL_MISSING_RT_STS_BIT));
+
+	return rc;
+}
+
+static bool is_charging_paused(struct smb_charger *chg)
+{
+	int rc;
+	u8 val;
+
+	rc = smblib_read(chg, CHARGING_PAUSE_CMD_REG, &val);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read CHARGING_PAUSE_CMD rc=%d\n", rc);
+		return false;
+	}
+
+	return val & CHARGING_PAUSE_CMD_BIT;
+}
+
+int smblib_get_prop_batt_status(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	union power_supply_propval pval = {0, };
+	bool usb_online, dc_online;
+	u8 stat;
+	int rc;
+
+	rc = smblib_get_prop_usb_online(chg, &pval);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't get usb online property rc=%d\n",
+			rc);
+		return rc;
+	}
+	usb_online = (bool)pval.intval;
+
+	rc = smblib_get_prop_dc_online(chg, &pval);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't get dc online property rc=%d\n",
+			rc);
+		return rc;
+	}
+	dc_online = (bool)pval.intval;
+
+	rc = smblib_read(chg, BATTERY_CHARGER_STATUS_1_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read BATTERY_CHARGER_STATUS_1 rc=%d\n",
+			rc);
+		return rc;
+	}
+	stat = stat & BATTERY_CHARGER_STATUS_MASK;
+
+	if (!usb_online && !dc_online) {
+			val->intval = POWER_SUPPLY_STATUS_DISCHARGING;
+		return rc;
+	}
+
+	rc = smblib_get_prop_batt_health(chg, &pval);
+	if (rc < 0)
+		smblib_err(chg, "Couldn't get batt health rc=%d\n", rc);
+
+
+	switch (stat) {
+	case TRICKLE_CHARGE:
+	case PRE_CHARGE:
+	case FULLON_CHARGE:
+	case TAPER_CHARGE:
+		val->intval = POWER_SUPPLY_STATUS_CHARGING;
+		break;
+	case TERMINATE_CHARGE:
+	case INHIBIT_CHARGE:
+		if (POWER_SUPPLY_HEALTH_WARM == pval.intval
+			|| POWER_SUPPLY_HEALTH_OVERHEAT == pval.intval)
+			val->intval = POWER_SUPPLY_STATUS_CHARGING;
+		else
+			val->intval = POWER_SUPPLY_STATUS_FULL;
+		break;
+	case DISABLE_CHARGE:
+	case PAUSE_CHARGE:
+		val->intval = POWER_SUPPLY_STATUS_NOT_CHARGING;
+		break;
+	default:
+		val->intval = POWER_SUPPLY_STATUS_UNKNOWN;
+		break;
+	}
+
+	if (is_charging_paused(chg)) {
+		val->intval = POWER_SUPPLY_STATUS_CHARGING;
+		return 0;
+	}
+
+	return 0;
+}
+
+int smblib_get_prop_batt_charge_type(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	int rc;
+	u8 stat;
+
+	rc = smblib_read(chg, BATTERY_CHARGER_STATUS_1_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read BATTERY_CHARGER_STATUS_1 rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	switch (stat & BATTERY_CHARGER_STATUS_MASK) {
+	case TRICKLE_CHARGE:
+	case PRE_CHARGE:
+		val->intval = POWER_SUPPLY_CHARGE_TYPE_TRICKLE;
+		break;
+	case FULLON_CHARGE:
+		val->intval = POWER_SUPPLY_CHARGE_TYPE_FAST;
+		break;
+	case TAPER_CHARGE:
+		val->intval = POWER_SUPPLY_CHARGE_TYPE_STANDARD;
+		break;
+	default:
+		val->intval = POWER_SUPPLY_CHARGE_TYPE_NONE;
+	}
+
+	return rc;
+}
+
+int smblib_get_prop_batt_health(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	int rc;
+	u8 stat;
+
+	rc = smblib_read(chg, BATTERY_CHARGER_STATUS_2_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read BATTERY_CHARGER_STATUS_2 rc=%d\n",
+			rc);
+		return rc;
+	}
+	smblib_dbg(chg, PR_REGISTER, "BATTERY_CHARGER_STATUS_2 = 0x%02x\n",
+		   stat);
+
+	if (stat & CHARGER_ERROR_STATUS_BAT_OV_BIT) {
+		val->intval = POWER_SUPPLY_HEALTH_OVERVOLTAGE;
+		goto done;
+	}
+
+	rc = smblib_read(chg, BATTERY_CHARGER_STATUS_7_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read BATTERY_CHARGER_STATUS_2 rc=%d\n",
+			rc);
+		return rc;
+	}
+	if (stat & BAT_TEMP_STATUS_TOO_COLD_BIT)
+		val->intval = POWER_SUPPLY_HEALTH_COLD;
+	else if (stat & BAT_TEMP_STATUS_TOO_HOT_BIT)
+		val->intval = POWER_SUPPLY_HEALTH_OVERHEAT;
+	else if (stat & BAT_TEMP_STATUS_COLD_SOFT_BIT)
+		val->intval = POWER_SUPPLY_HEALTH_COOL;
+	else if (stat & BAT_TEMP_STATUS_HOT_SOFT_BIT)
+		val->intval = POWER_SUPPLY_HEALTH_WARM;
+	else
+		val->intval = POWER_SUPPLY_HEALTH_GOOD;
+
+done:
+	return rc;
+}
+
+int smblib_set_prop_rechg_soc_thresh(struct smb_charger *chg,
+				const union power_supply_propval *val)
+{
+	int rc;
+	u8 new_thr = DIV_ROUND_CLOSEST(val->intval * 255, 100);
+
+	/*
+	 * As DIV_ROUND_CLOSEST cal cause new_thr to 252, we add 1 more to
+	 * improve recharging UI soc still to 100% to improve user experience.
+	 */
+	if (val->intval == RECHARGE_SOC_THR)
+		new_thr += 1;
+
+	rc = smblib_write(chg, CHARGE_RCHG_SOC_THRESHOLD_CFG_REG,
+			new_thr);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't write to RCHG_SOC_THRESHOLD_CFG_REG rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	return rc;
+}
+
+int smblib_disable_hw_jeita(struct smb_charger *chg, bool disable)
+{
+	int rc;
+	u8 mask;
+
+	/*
+	 * Disable h/w base JEITA compensation if s/w JEITA is enabled
+	 */
+	mask = JEITA_EN_COLD_SL_FCV_BIT
+		| JEITA_EN_HOT_SL_FCV_BIT
+		| JEITA_EN_HOT_SL_CCC_BIT
+		| JEITA_EN_COLD_SL_CCC_BIT,
+	rc = smblib_masked_write(chg, JEITA_EN_CFG_REG, mask,
+			disable ? 0 : mask);
+	if (rc < 0) {
+		dev_err(chg->dev, "Couldn't configure s/w jeita rc=%d\n",
+				rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+int smblib_get_prop_dc_present(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	int rc;
+	u8 stat;
+
+	rc = smblib_read(chg, DCIN_BASE + INT_RT_STS_OFFSET, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read DCIN_RT_STS rc=%d\n", rc);
+		return rc;
+	}
+
+	val->intval = (bool)(stat & DCIN_PLUGIN_RT_STS_BIT);
+	return 0;
+}
+
+int smblib_get_prop_dc_online(struct smb_charger *chg,
+			       union power_supply_propval *val)
+{
+	int dc_present, rc = 0;
+	u8 stat;
+	union power_supply_propval pval = {0, };
+
+	rc = smblib_get_prop_dc_present(chg, &pval);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't get usb present rc = %d\n", rc);
+		return rc;
+	}
+
+	dc_present = pval.intval;
+
+	if (dc_present) {
+		val->intval = true;
+		return rc;
+	}
+
+	rc = smblib_read(chg, POWER_PATH_STATUS_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read POWER_PATH_STATUS rc=%d\n",
+			rc);
+		return rc;
+	}
+
+	val->intval = (stat & USE_DCIN_BIT) &&
+		      (stat & VALID_INPUT_POWER_SOURCE_STS_BIT);
+
+	return rc;
+}
+
+/*******************
+ * USB PSY GETTERS *
+ *******************/
+
+int smblib_get_prop_usb_present(struct smb_charger *chg,
+				union power_supply_propval *val)
+{
+	int rc;
+	u8 stat;
+
+	rc = smblib_read(chg, USBIN_BASE + INT_RT_STS_OFFSET, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read USBIN_RT_STS rc=%d\n", rc);
+		return rc;
+	}
+
+	val->intval = (bool)(stat & USBIN_PLUGIN_RT_STS_BIT);
+	return 0;
+}
+
+int smblib_get_prop_usb_online(struct smb_charger *chg,
+			       union power_supply_propval *val)
+{
+	int rc = 0;
+	u8 stat;
+
+	rc = smblib_read(chg, POWER_PATH_STATUS_REG, &stat);
+	if (rc < 0) {
+		smblib_err(chg, "Couldn't read POWER_PATH_STATUS rc=%d\n",
+			rc);
+		return rc;
+	}
+	smblib_dbg(chg, PR_REGISTER, "POWER_PATH_STATUS = 0x%02x\n",
+		   stat);
+
+	val->intval = (stat & USE_USBIN_BIT) &&
+		      (stat & VALID_INPUT_POWER_SOURCE_STS_BIT);
+	return rc;
+}
+
+/**********************
+ * INTERRUPT HANDLERS *
+ **********************/
+
+irqreturn_t default_irq_handler(int irq, void *data)
+{
+	struct smb_irq_data *irq_data = data;
+	struct smb_charger *chg = irq_data->parent_data;
+
+	smblib_dbg(chg, PR_INTERRUPT, "IRQ: %s\n", irq_data->name);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t chg_state_change_irq_handler(int irq, void *data)
+{
+	struct smb_irq_data *irq_data = data;
+	struct smb_charger *chg = irq_data->parent_data;
+
+	smblib_dbg(chg, PR_INTERRUPT, "IRQ: %s\n", irq_data->name);
+
+	power_supply_changed(chg->dc_psy);
+	return IRQ_HANDLED;
+}
+
+irqreturn_t usb_plugin_irq_handler(int irq, void *data)
+{
+	struct smb_irq_data *irq_data = data;
+	struct smb_charger *chg = irq_data->parent_data;
+
+	power_supply_changed(chg->dc_psy);
+
+	return IRQ_HANDLED;
+}
+
+irqreturn_t dc_plugin_irq_handler(int irq, void *data)
+{
+	struct smb_irq_data *irq_data = data;
+	struct smb_charger *chg = irq_data->parent_data;
+	int input_present;
+	bool dcin_present, vbus_present;
+	int rc;
+
+	rc = smblib_is_input_present(chg, &input_present);
+	if (rc < 0)
+		return IRQ_HANDLED;
+
+	smblib_dbg(chg, (PR_WLS | PR_INTERRUPT), "dcin_present= %d, usbin_present= %d\n",
+			dcin_present, vbus_present);
+
+	return IRQ_HANDLED;
+}
+
+int smblib_init(struct smb_charger *chg)
+{
+	chg->bms_psy = power_supply_get_by_name("bms");
+
+	return 0;
+}
+
+int smblib_deinit(struct smb_charger *chg)
+{
+	return 0;
+}
diff --git a/drivers/power/supply/qcom/smb5-lib.h b/drivers/power/supply/qcom/smb5-lib.h
new file mode 100644
index 000000000..75a2a82c3
--- /dev/null
+++ b/drivers/power/supply/qcom/smb5-lib.h
@@ -0,0 +1,201 @@
+#ifndef __SMB5_CHARGER_H
+#define __SMB5_CHARGER_H
+
+#define ITERM_LIMITS_PM8150B_MA		10000
+#define ADC_CHG_ITERM_MASK		32767
+
+#define DCIN_ICL_MIN_UA			100000
+#define DCIN_ICL_MAX_UA			1500000
+#define DCIN_ICL_STEP_UA		100000
+
+#define RECHARGE_SOC_THR		99
+
+enum print_reason {
+	PR_INTERRUPT	= BIT(0),
+	PR_REGISTER	= BIT(1),
+	PR_MISC		= BIT(2),
+	PR_PARALLEL	= BIT(3),
+	PR_OTG		= BIT(4),
+	PR_WLS		= BIT(5),
+	PR_OEM		= BIT(6),
+};
+
+enum smb_irq_index {
+	/* CHGR */
+	CHGR_ERROR_IRQ = 0,
+	CHG_STATE_CHANGE_IRQ,
+	STEP_CHG_STATE_CHANGE_IRQ,
+	STEP_CHG_SOC_UPDATE_FAIL_IRQ,
+	STEP_CHG_SOC_UPDATE_REQ_IRQ,
+	FG_FVCAL_QUALIFIED_IRQ,
+	VPH_ALARM_IRQ,
+	VPH_DROP_PRECHG_IRQ,
+	/* DCDC */
+	OTG_FAIL_IRQ,
+	OTG_OC_DISABLE_SW_IRQ,
+	OTG_OC_HICCUP_IRQ,
+	BSM_ACTIVE_IRQ,
+	HIGH_DUTY_CYCLE_IRQ,
+	INPUT_CURRENT_LIMITING_IRQ,
+	CONCURRENT_MODE_DISABLE_IRQ,
+	SWITCHER_POWER_OK_IRQ,
+	/* BATIF */
+	BAT_TEMP_IRQ,
+	ALL_CHNL_CONV_DONE_IRQ,
+	BAT_OV_IRQ,
+	BAT_LOW_IRQ,
+	BAT_THERM_OR_ID_MISSING_IRQ,
+	BAT_TERMINAL_MISSING_IRQ,
+	BUCK_OC_IRQ,
+	VPH_OV_IRQ,
+	/* USB */
+	USBIN_COLLAPSE_IRQ,
+	USBIN_VASHDN_IRQ,
+	USBIN_UV_IRQ,
+	USBIN_OV_IRQ,
+	USBIN_PLUGIN_IRQ,
+	USBIN_REVI_CHANGE_IRQ,
+	USBIN_SRC_CHANGE_IRQ,
+	USBIN_ICL_CHANGE_IRQ,
+	/* DC */
+	DCIN_VASHDN_IRQ,
+	DCIN_UV_IRQ,
+	DCIN_OV_IRQ,
+	DCIN_PLUGIN_IRQ,
+	DCIN_REVI_IRQ,
+	DCIN_PON_IRQ,
+	DCIN_EN_IRQ,
+	/* TYPEC */
+	TYPEC_OR_RID_DETECTION_CHANGE_IRQ,
+	TYPEC_VPD_DETECT_IRQ,
+	TYPEC_CC_STATE_CHANGE_IRQ,
+	TYPEC_VCONN_OC_IRQ,
+	TYPEC_VBUS_CHANGE_IRQ,
+	TYPEC_ATTACH_DETACH_IRQ,
+	TYPEC_LEGACY_CABLE_DETECT_IRQ,
+	TYPEC_TRY_SNK_SRC_DETECT_IRQ,
+	/* MISC */
+	WDOG_SNARL_IRQ,
+	WDOG_BARK_IRQ,
+	AICL_FAIL_IRQ,
+	AICL_DONE_IRQ,
+	SMB_EN_IRQ,
+	IMP_TRIGGER_IRQ,
+	TEMP_CHANGE_IRQ,
+	TEMP_CHANGE_SMB_IRQ,
+	/* FLASH */
+	VREG_OK_IRQ,
+	ILIM_S2_IRQ,
+	ILIM_S1_IRQ,
+	VOUT_DOWN_IRQ,
+	VOUT_UP_IRQ,
+	FLASH_STATE_CHANGE_IRQ,
+	TORCH_REQ_IRQ,
+	FLASH_EN_IRQ,
+	SDAM_STS_IRQ,
+	/* END */
+	SMB_IRQ_MAX,
+};
+
+struct smb_irq_info {
+	const char			*name;
+	const irq_handler_t		handler;
+	const bool			wake;
+	struct smb_irq_data		*irq_data;
+	int				irq;
+	bool				enabled;
+};
+
+enum icl_override_mode {
+	/* APSD/Type-C/QC auto */
+	HW_AUTO_MODE,
+	/* 100/150/500/900mA */
+	SW_OVERRIDE_USB51_MODE,
+	/* ICL other than USB51 */
+	SW_OVERRIDE_HC_MODE,
+	/* ICL in cc float mode */
+	SW_OVERRIDE_NO_CC_MODE,
+};
+
+struct smb_irq_data {
+	void			*parent_data;
+	const char		*name;
+};
+
+struct smb_chg_param {
+	const char	*name;
+	u16		reg;
+	int		min_u;
+	int		max_u;
+	int		step_u;
+	int		(*get_proc)(struct smb_chg_param *param,
+				    u8 val_raw);
+	int		(*set_proc)(struct smb_chg_param *param,
+				    int val_u,
+				    u8 *val_raw);
+};
+
+struct buck_boost_freq {
+	int freq_khz;
+	u8 val;
+};
+
+struct smb_params {
+	struct smb_chg_param	otg_cl;
+	struct smb_chg_param	dc_icl;
+};
+
+struct smb_charger {
+	struct device		*dev;
+	char			*name;
+	struct regmap		*regmap;
+	struct smb_irq_info	*irq_info;
+	struct smb_params	param;
+	int			*debug_mask;
+
+	/* power supplies */
+//	struct power_supply		*batt_psy;
+	struct power_supply		*dc_psy;
+	struct power_supply		*bms_psy;
+};
+
+int smblib_read(struct smb_charger *chg, u16 addr, u8 *val);
+int smblib_write(struct smb_charger *chg, u16 addr, u8 val);
+int smblib_masked_write(struct smb_charger *chg, u16 addr, u8 mask, u8 val);
+
+int smblib_set_charge_param(struct smb_charger *chg,
+			    struct smb_chg_param *param, int val_u);
+
+irqreturn_t default_irq_handler(int irq, void *data);
+irqreturn_t chg_state_change_irq_handler(int irq, void *data);
+irqreturn_t usb_plugin_irq_handler(int irq, void *data);
+irqreturn_t dc_plugin_irq_handler(int irq, void *data);
+int smblib_get_prop_batt_present(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_batt_status(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_batt_charge_type(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_batt_health(struct smb_charger *chg,
+	union power_supply_propval *val);
+
+int smblib_get_prop_dc_present(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_dc_online(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_usb_online(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_get_prop_usb_present(struct smb_charger *chg,
+				union power_supply_propval *val);
+int smblib_set_prop_rechg_soc_thresh(struct smb_charger *chg,
+				const union power_supply_propval *val);
+int smblib_disable_hw_jeita(struct smb_charger *chg, bool disable);
+int smblib_get_prop_from_bms(struct smb_charger *chg,
+				enum power_supply_property psp,
+				union power_supply_propval *val);
+int smblib_icl_override(struct smb_charger *chg, enum icl_override_mode mode);
+
+int smblib_init(struct smb_charger *chg);
+int smblib_deinit(struct smb_charger *chg);
+
+#endif /* __SMB5_CHARGER_H */
diff --git a/drivers/power/supply/qcom/smb5-reg.h b/drivers/power/supply/qcom/smb5-reg.h
new file mode 100644
index 000000000..6d8473a82
--- /dev/null
+++ b/drivers/power/supply/qcom/smb5-reg.h
@@ -0,0 +1,592 @@
+/* Copyright (c) 2018-2019 The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __SMB5_CHARGER_REG_H
+#define __SMB5_CHARGER_REG_H
+
+#include <linux/bitops.h>
+
+#define CHGR_BASE	0x1000
+#define DCDC_BASE	0x1100
+#define BATIF_BASE	0x1200
+#define USBIN_BASE	0x1300
+#define DCIN_BASE	0x1400
+#define TYPEC_BASE	0X1500
+#define MISC_BASE	0x1600
+#define MISC_PBS_BASE	0x7500
+
+#define PERPH_TYPE_OFFSET	0x04
+#define TYPE_MASK		GENMASK(7, 0)
+#define PERPH_SUBTYPE_OFFSET	0x05
+#define SUBTYPE_MASK		GENMASK(7, 0)
+#define INT_RT_STS_OFFSET	0x10
+
+/********************************
+ *  CHGR Peripheral Registers  *
+ ********************************/
+#define BATTERY_CHARGER_STATUS_1_REG		(CHGR_BASE + 0x06)
+#define BATTERY_CHARGER_STATUS_MASK		GENMASK(2, 0)
+enum {
+	INHIBIT_CHARGE = 0,
+	TRICKLE_CHARGE,
+	PRE_CHARGE,
+	FULLON_CHARGE,
+	TAPER_CHARGE,
+	TERMINATE_CHARGE,
+	PAUSE_CHARGE,
+	DISABLE_CHARGE,
+};
+
+#define BATTERY_CHARGER_STATUS_2_REG		(CHGR_BASE + 0x07)
+#define CHARGER_ERROR_STATUS_BAT_OV_BIT		BIT(1)
+
+#define BATTERY_CHARGER_STATUS_5_REG		(CHGR_BASE + 0x0B)
+#define ENABLE_TRICKLE_BIT			BIT(2)
+#define ENABLE_PRE_CHARGING_BIT			BIT(1)
+#define ENABLE_FULLON_MODE_BIT			BIT(0)
+
+#define BATTERY_CHARGER_STATUS_7_REG		(CHGR_BASE + 0x0D)
+#define BAT_TEMP_STATUS_SOFT_LIMIT_MASK		GENMASK(5, 4)
+#define BAT_TEMP_STATUS_HOT_SOFT_BIT		BIT(5)
+#define BAT_TEMP_STATUS_COLD_SOFT_BIT		BIT(4)
+#define BAT_TEMP_STATUS_HARD_LIMIT_MASK		GENMASK(3, 2)
+#define BAT_TEMP_STATUS_TOO_HOT_BIT		BIT(3)
+#define BAT_TEMP_STATUS_TOO_COLD_BIT		BIT(2)
+#define BAT_TEMP_STATUS_TOO_HOT_AFP_BIT		BIT(1)
+#define BAT_TEMP_STATUS_TOO_COLD_AFP_BIT	BIT(0)
+
+#define CHARGING_ENABLE_CMD_REG			(CHGR_BASE + 0x42)
+#define CHARGING_ENABLE_CMD_BIT			BIT(0)
+
+#define CHARGING_PAUSE_CMD_REG			(CHGR_BASE + 0x43)
+#define CHARGING_PAUSE_CMD_BIT			BIT(0)
+
+#define CHGR_CFG2_REG				(CHGR_BASE + 0x51)
+#define RECHG_MASK				GENMASK(2, 1)
+#define VBAT_BASED_RECHG_BIT			BIT(2)
+#define SOC_BASED_RECHG_BIT			GENMASK(2, 1)
+#define CHARGER_INHIBIT_BIT			BIT(0)
+
+#define CHGR_FAST_CHARGE_CURRENT_CFG_REG	(CHGR_BASE + 0x61)
+
+#define CHGR_ADC_ITERM_UP_THD_MSB_REG		(CHGR_BASE + 0x67)
+#define CHGR_ADC_ITERM_UP_THD_LSB_REG		(CHGR_BASE + 0x68)
+#define CHGR_ADC_ITERM_LO_THD_MSB_REG		(CHGR_BASE + 0x69)
+#define CHGR_ADC_ITERM_LO_THD_LSB_REG		(CHGR_BASE + 0x6A)
+
+#define CHGR_NO_SAMPLE_TERM_RCHG_CFG_REG	(CHGR_BASE + 0x6B)
+#define NO_OF_SAMPLE_FOR_RCHG_SHIFT		2
+#define NO_OF_SAMPLE_FOR_RCHG			GENMASK(3, 2)
+
+#define CHGR_ADC_TERM_CFG_REG			(CHGR_BASE + 0x6C)
+#define TERM_BASED_ON_SYNC_CONV_OR_SAMPLE_CNT	BIT(0)
+#define TERM_BASED_ON_SYNC_CONV			0
+#define TERM_BASED_ON_SAMPLE_CNT		1
+
+#define CHGR_FLOAT_VOLTAGE_CFG_REG		(CHGR_BASE + 0x70)
+
+#define CHARGE_INHIBIT_THRESHOLD_CFG_REG	(CHGR_BASE + 0x72)
+#define CHARGE_INHIBIT_THRESHOLD_MASK		GENMASK(1, 0)
+#define INHIBIT_ANALOG_VFLT_MINUS_50MV		0
+#define INHIBIT_ANALOG_VFLT_MINUS_100MV		1
+#define INHIBIT_ANALOG_VFLT_MINUS_200MV		2
+#define INHIBIT_ANALOG_VFLT_MINUS_300MV		3
+
+#define CHARGE_RCHG_SOC_THRESHOLD_CFG_REG	(CHGR_BASE + 0x7D)
+
+#define CHGR_ADC_RECHARGE_THRESHOLD_MSB_REG	(CHGR_BASE + 0x7E)
+
+#define CHGR_ADC_RECHARGE_THRESHOLD_LSB_REG	(CHGR_BASE + 0x7F)
+
+#define JEITA_EN_CFG_REG			(CHGR_BASE + 0x90)
+#define JEITA_EN_HOT_SL_FCV_BIT			BIT(3)
+#define JEITA_EN_COLD_SL_FCV_BIT		BIT(2)
+#define JEITA_EN_HOT_SL_CCC_BIT			BIT(1)
+#define JEITA_EN_COLD_SL_CCC_BIT		BIT(0)
+
+#define JEITA_CCCOMP_CFG_HOT_REG		(CHGR_BASE + 0x92)
+#define JEITA_CCCOMP_CFG_COLD_REG		(CHGR_BASE + 0x93)
+
+#define CHGR_JEITA_THRESHOLD_BASE_REG(i)	(CHGR_BASE + 0x94 + (i * 4))
+#define CHGR_JEITA_HOT_THRESHOLD_MSB_REG	CHGR_JEITA_THRESHOLD_BASE_REG(0)
+
+#define CHGR_FAST_CHARGE_SAFETY_TIMER_CFG_REG	(CHGR_BASE + 0xA2)
+#define FAST_CHARGE_SAFETY_TIMER_192_MIN	0x0
+#define FAST_CHARGE_SAFETY_TIMER_384_MIN	0x1
+#define FAST_CHARGE_SAFETY_TIMER_768_MIN	0x2
+#define FAST_CHARGE_SAFETY_TIMER_1536_MIN	0x3
+
+#define CHGR_ENG_CHARGING_CFG_REG		(CHGR_BASE + 0xC0)
+#define CHGR_ITERM_USE_ANALOG_BIT		BIT(3)
+
+/********************************
+ *  DCDC Peripheral Registers  *
+ ********************************/
+#define ICL_MAX_STATUS_REG			(DCDC_BASE + 0x06)
+#define ICL_STATUS_REG				(DCDC_BASE + 0x07)
+#define AICL_ICL_STATUS_REG			(DCDC_BASE + 0x08)
+
+#define AICL_STATUS_REG				(DCDC_BASE + 0x0A)
+#define SOFT_ILIMIT_BIT				BIT(6)
+#define AICL_DONE_BIT				BIT(0)
+
+#define POWER_PATH_STATUS_REG			(DCDC_BASE + 0x0B)
+#define USBIN_SUSPEND_STS_BIT			BIT(6)
+#define USE_USBIN_BIT				BIT(4)
+#define USE_DCIN_BIT				BIT(3)
+#define POWER_PATH_MASK				GENMASK(2, 1)
+#define VALID_INPUT_POWER_SOURCE_STS_BIT	BIT(0)
+
+#define DCDC_CMD_OTG_REG			(DCDC_BASE + 0x40)
+#define OTG_EN_BIT				BIT(0)
+
+#define DCDC_FSW_SEL_REG			(DCDC_BASE + 0x50)
+
+#define DCDC_OTG_CURRENT_LIMIT_CFG_REG		(DCDC_BASE + 0x52)
+
+#define DCDC_OTG_CFG_REG			(DCDC_BASE + 0x53)
+#define OTG_EN_SRC_CFG_BIT			BIT(1)
+
+#define OTG_FAULT_CONDITION_CFG_REG		(DCDC_BASE + 0x56)
+#define USBIN_MID_COMP_FAULT_EN_BIT		BIT(5)
+#define USBIN_COLLAPSE_FAULT_EN_BIT		BIT(4)
+
+#define DCDC_CFG_REF_MAX_PSNS_REG		(DCDC_BASE + 0x8C)
+
+#define DCDC_ENG_SDCDC_CFG5_REG			(DCDC_BASE + 0xC4)
+#define ENG_SDCDC_BAT_HPWR_MASK			GENMASK(7, 6)
+enum {
+	BOOST_MODE_THRESH_3P3_V,
+	BOOST_MODE_THRESH_3P4_V = 0x40,
+	BOOST_MODE_THRESH_3P5_V = 0x80,
+	BOOST_MODE_THRESH_3P6_V = 0xC0
+};
+
+/********************************
+ *  BATIF Peripheral Registers  *
+ ********************************/
+
+/* BATIF Interrupt Bits	 */
+#define VPH_OV_RT_STS_BIT			BIT(7)
+#define BUCK_OC_RT_STS_BIT			BIT(6)
+#define BAT_TERMINAL_MISSING_RT_STS_BIT		BIT(5)
+#define BAT_THERM_OR_ID_MISSING_RT_STS_BIT      BIT(4)
+#define BAT_LOW_RT_STS_BIT			BIT(3)
+#define BAT_OV_RT_STS_BIT			BIT(2)
+#define ALL_CHNL_CONV_DONE_RT_STS		BIT(1)
+#define BAT_TEMP_RT_STS_BIT			BIT(0)
+
+#define SHIP_MODE_REG				(BATIF_BASE + 0x40)
+#define SHIP_MODE_EN_BIT			BIT(0)
+
+#define BATIF_ADC_CHANNEL_EN_REG		(BATIF_BASE + 0x82)
+#define IBATT_CHANNEL_EN_BIT			BIT(6)
+#define CONN_THM_CHANNEL_EN_BIT			BIT(4)
+#define DIE_TEMP_CHANNEL_EN_BIT			BIT(2)
+#define MISC_THM_CHANNEL_EN_BIT			BIT(1)
+
+#define BATIF_ADC_INTERNAL_PULL_UP_REG		(BATIF_BASE + 0x86)
+#define INTERNAL_PULL_UP_CONN_THM_MASK		GENMASK(5, 4)
+#define CONN_THM_SHIFT				4
+#define INTERNAL_PULL_NO_PULL			0x00
+#define INTERNAL_PULL_30K_PULL			0x01
+#define INTERNAL_PULL_100K_PULL			0x02
+#define INTERNAL_PULL_400K_PULL			0x03
+
+/********************************
+ *  USBIN Peripheral Registers  *
+ ********************************/
+#define APSD_STATUS_REG				(USBIN_BASE + 0x07)
+#define APSD_STATUS_7_BIT			BIT(7)
+#define HVDCP_CHECK_TIMEOUT_BIT			BIT(6)
+#define SLOW_PLUGIN_TIMEOUT_BIT			BIT(5)
+#define ENUMERATION_DONE_BIT			BIT(4)
+#define VADP_CHANGE_DONE_AFTER_AUTH_BIT		BIT(3)
+#define QC_AUTH_DONE_STATUS_BIT			BIT(2)
+#define QC_CHARGER_BIT				BIT(1)
+#define APSD_DTC_STATUS_DONE_BIT		BIT(0)
+
+#define APSD_RESULT_STATUS_REG			(USBIN_BASE + 0x08)
+#define APSD_RESULT_STATUS_7_BIT		BIT(7)
+#define APSD_RESULT_STATUS_MASK			GENMASK(6, 0)
+#define QC_3P0_BIT				BIT(6)
+#define QC_2P0_BIT				BIT(5)
+#define FLOAT_CHARGER_BIT			BIT(4)
+#define DCP_CHARGER_BIT				BIT(3)
+#define CDP_CHARGER_BIT				BIT(2)
+#define OCP_CHARGER_BIT				BIT(1)
+#define SDP_CHARGER_BIT				BIT(0)
+
+#define QC_CHANGE_STATUS_REG			(USBIN_BASE + 0x09)
+#define QC_12V_BIT				BIT(2)
+#define QC_9V_BIT				BIT(1)
+#define QC_5V_BIT				BIT(0)
+#define QC_2P0_STATUS_MASK			GENMASK(2, 0)
+
+/* USBIN Interrupt Bits */
+#define USBIN_ICL_CHANGE_RT_STS_BIT		BIT(7)
+#define USBIN_SOURCE_CHANGE_RT_STS_BIT		BIT(6)
+#define USBIN_REVI_RT_STS_BIT			BIT(5)
+#define USBIN_PLUGIN_RT_STS_BIT			BIT(4)
+#define USBIN_OV_RT_STS_BIT			BIT(3)
+#define USBIN_UV_RT_STS_BIT			BIT(2)
+#define USBIN_VASHDN_RT_STS_BIT			BIT(1)
+#define USBIN_COLLAPSE_RT_STS_BIT		BIT(0)
+
+#define USBIN_CMD_IL_REG			(USBIN_BASE + 0x40)
+#define USBIN_SUSPEND_BIT			BIT(0)
+
+#define CMD_APSD_REG				(USBIN_BASE + 0x41)
+#define APSD_RERUN_BIT				BIT(0)
+
+#define CMD_ICL_OVERRIDE_REG			(USBIN_BASE + 0x42)
+#define ICL_OVERRIDE_BIT			BIT(0)
+
+#define CMD_HVDCP_2_REG				(USBIN_BASE + 0x43)
+#define FORCE_12V_BIT				BIT(5)
+#define FORCE_9V_BIT				BIT(4)
+#define FORCE_5V_BIT				BIT(3)
+#define IDLE_BIT				BIT(2)
+#define SINGLE_DECREMENT_BIT			BIT(1)
+#define SINGLE_INCREMENT_BIT			BIT(0)
+
+#define USBIN_ADAPTER_ALLOW_OVERRIDE_REG	(USBIN_BASE + 0x44)
+#define CONTINUOUS				BIT(3)
+#define FORCE_12V				BIT(2)
+#define FORCE_9V				BIT(1)
+#define FORCE_5V				BIT(0)
+#define FORCE_NULL				0
+
+#define USB_CMD_PULLDOWN_REG			(USBIN_BASE + 0x45)
+#define EN_PULLDOWN_USB_IN_BIT			BIT(0)
+
+#define TYPE_C_CFG_REG				(USBIN_BASE + 0x58)
+#define BC1P2_START_ON_CC_BIT			BIT(7)
+
+#define HVDCP_PULSE_COUNT_MAX_REG              (USBIN_BASE + 0x5B)
+#define HVDCP_PULSE_COUNT_MAX_QC2_MASK         GENMASK(7, 6)
+enum {
+	HVDCP_PULSE_COUNT_MAX_QC2_5V = 0,
+	HVDCP_PULSE_COUNT_MAX_QC2_9V = 0x40,
+	HVDCP_PULSE_COUNT_MAX_QC2_12V = 0x80,
+	HVDCP_PULSE_COUNT_MAX_QC2_INVALID = 0xC0
+};
+
+#define USBIN_ADAPTER_ALLOW_CFG_REG		(USBIN_BASE + 0x60)
+enum {
+	USBIN_ADAPTER_ALLOW_5V		= 0,
+	USBIN_ADAPTER_ALLOW_9V		= 2,
+	USBIN_ADAPTER_ALLOW_5V_OR_9V	= 3,
+	USBIN_ADAPTER_ALLOW_12V		= 4,
+	USBIN_ADAPTER_ALLOW_5V_OR_12V	= 5,
+	USBIN_ADAPTER_ALLOW_9V_TO_12V	= 6,
+	USBIN_ADAPTER_ALLOW_5V_OR_9V_TO_12V = 7,
+	USBIN_ADAPTER_ALLOW_5V_TO_9V	= 8,
+	USBIN_ADAPTER_ALLOW_5V_TO_12V	= 12,
+};
+
+#define USBIN_OPTIONS_1_CFG_REG			(USBIN_BASE + 0x62)
+#define HVDCP_AUTH_ALG_EN_CFG_BIT		BIT(6)
+#define HVDCP_AUTONOMOUS_MODE_EN_CFG_BIT	BIT(5)
+#define BC1P2_SRC_DETECT_BIT			BIT(3)
+#define HVDCP_EN_BIT				BIT(2)
+
+#define USBIN_OPTIONS_2_CFG_REG			(USBIN_BASE + 0x63)
+#define DCD_TIMEOUT_SEL_BIT			BIT(5)
+#define FLOAT_OPTIONS_MASK			GENMASK(2, 0)
+#define FLOAT_DIS_CHGING_CFG_BIT		BIT(2)
+#define SUSPEND_FLOAT_CFG_BIT			BIT(1)
+#define FORCE_FLOAT_SDP_CFG_BIT			BIT(0)
+
+#define USBIN_LOAD_CFG_REG			(USBIN_BASE + 0x65)
+#define ICL_OVERRIDE_AFTER_APSD_BIT		BIT(4)
+#define USBIN_AICL_STEP_TIMING_SEL_MASK		GENMASK(3, 2)
+#define USBIN_IN_COLLAPSE_GF_SEL_MASK		GENMASK(1, 0)
+
+#define USBIN_ICL_OPTIONS_REG			(USBIN_BASE + 0x66)
+#define CFG_USB3P0_SEL_BIT			BIT(2)
+#define	USB51_MODE_BIT				BIT(1)
+#define USBIN_MODE_CHG_BIT			BIT(0)
+
+#define USBIN_CURRENT_LIMIT_CFG_REG		(USBIN_BASE + 0x70)
+
+#define USBIN_AICL_OPTIONS_CFG_REG		(USBIN_BASE + 0x80)
+#define SUSPEND_ON_COLLAPSE_USBIN_BIT		BIT(7)
+#define USBIN_AICL_PERIODIC_RERUN_EN_BIT	BIT(4)
+#define USBIN_AICL_ADC_EN_BIT			BIT(3)
+#define USBIN_AICL_EN_BIT			BIT(2)
+
+#define USB_ENG_SSUPPLY_USB2_REG		(USBIN_BASE + 0xC0)
+#define ENG_SSUPPLY_12V_OV_OPT_BIT		BIT(1)
+
+#define USBIN_5V_AICL_THRESHOLD_REG		(USBIN_BASE + 0x81)
+#define USBIN_CONT_AICL_THRESHOLD_REG		(USBIN_BASE + 0x84)
+
+#define TYPE_C_CFG_REG                         (USBIN_BASE + 0x58)
+#define APSD_START_ON_CC_BIT                   BIT(7)
+
+/********************************
+ *  DCIN Peripheral Registers   *
+ ********************************/
+
+/* DCIN Interrupt Bits */
+#define DCIN_PLUGIN_RT_STS_BIT			BIT(4)
+
+#define DCIN_CMD_IL_REG				(DCIN_BASE + 0x40)
+#define DCIN_SUSPEND_BIT			BIT(0)
+#define DCIN_EN_OVERRIDE_BIT			BIT(1)
+#define DCIN_EN_BIT                                     BIT(2)
+#define DCIN_EN_MASK				GENMASK(2, 1)
+
+#define DCIN_CMD_PULLDOWN_REG		(DCIN_BASE + 0x45)
+#define DCIN_PULLDOWN_EN_BIT		BIT(0)
+#define DCIN_MID_PULLDOWN_BIT		BIT(1)
+
+#define DCIN_EN_MASK				GENMASK(2, 1)
+
+#define DCIN_CMD_PON_REG			(DCIN_BASE + 0x45)
+#define DCIN_PON_BIT				BIT(0)
+#define MID_CHG_BIT					BIT(1)
+
+#define DCIN_LOAD_CFG_REG			(DCIN_BASE + 0x65)
+#define INPUT_MISS_POLL_EN_BIT			BIT(5)
+
+/********************************
+ *  TYPEC Peripheral Registers  *
+ ********************************/
+#define TYPE_C_SNK_STATUS_REG			(TYPEC_BASE + 0x06)
+#define DETECTED_SRC_TYPE_MASK			GENMASK(6, 0)
+#define SNK_DAM_500MA_BIT			BIT(6)
+#define SNK_DAM_1500MA_BIT			BIT(5)
+#define SNK_DAM_3000MA_BIT			BIT(4)
+#define SNK_RP_STD_BIT				BIT(3)
+#define SNK_RP_1P5_BIT				BIT(2)
+#define SNK_RP_3P0_BIT				BIT(1)
+#define SNK_RP_SHORT_BIT			BIT(0)
+
+#define TYPE_C_SNK_DEBUG_ACC_STATUS_REG			(TYPEC_BASE + 0x07)
+#define SNK_DEBUG_ACC_RPSTD_PRSTD_BIT			BIT(0)
+
+#define TYPE_C_SRC_STATUS_REG			(TYPEC_BASE + 0x08)
+#define DETECTED_SNK_TYPE_MASK			GENMASK(4, 0)
+#define SRC_HIGH_BATT_BIT			BIT(5)
+#define SRC_DEBUG_ACCESS_BIT			BIT(4)
+#define SRC_RD_OPEN_BIT				BIT(3)
+#define SRC_RD_RA_VCONN_BIT			BIT(2)
+#define SRC_RA_OPEN_BIT				BIT(1)
+#define AUDIO_ACCESS_RA_RA_BIT			BIT(0)
+
+#define TYPE_C_STATE_MACHINE_STATUS_REG		(TYPEC_BASE + 0x09)
+#define TYPEC_ATTACH_DETACH_STATE_BIT		BIT(5)
+
+#define TYPE_C_MISC_STATUS_REG			(TYPEC_BASE + 0x0B)
+#define TYPEC_WATER_DETECTION_STATUS_BIT	BIT(7)
+#define SNK_SRC_MODE_BIT			BIT(6)
+#define TYPEC_VBUS_ERROR_STATUS_BIT		BIT(4)
+#define TYPEC_TCCDEBOUNCE_DONE_STATUS_BIT	BIT(3)
+#define CC_ORIENTATION_BIT			BIT(1)
+#define CC_ATTACHED_BIT				BIT(0)
+
+#define LEGACY_CABLE_STATUS_REG			(TYPEC_BASE + 0x0D)
+#define TYPEC_LEGACY_CABLE_STATUS_BIT		BIT(1)
+#define TYPEC_NONCOMP_LEGACY_CABLE_STATUS_BIT	BIT(0)
+
+#define TYPEC_U_USB_STATUS_REG			(TYPEC_BASE + 0x0F)
+#define U_USB_GROUND_NOVBUS_BIT			BIT(6)
+#define U_USB_GROUND_BIT			BIT(4)
+#define U_USB_FMB1_BIT				BIT(3)
+#define U_USB_FLOAT1_BIT			BIT(2)
+#define U_USB_FMB2_BIT				BIT(1)
+#define U_USB_FLOAT2_BIT			BIT(0)
+
+#define TYPE_C_MODE_CFG_REG			(TYPEC_BASE + 0x44)
+#define TYPEC_TRY_MODE_MASK			GENMASK(4, 3)
+#define EN_TRY_SNK_BIT				BIT(4)
+#define EN_TRY_SRC_BIT				BIT(3)
+#define TYPEC_POWER_ROLE_CMD_MASK		GENMASK(2, 0)
+#define EN_SRC_ONLY_BIT				BIT(2)
+#define EN_SNK_ONLY_BIT				BIT(1)
+#define TYPEC_DISABLE_CMD_BIT			BIT(0)
+
+#define TYPE_C_VCONN_CONTROL_REG		(TYPEC_BASE + 0x46)
+#define VCONN_EN_ORIENTATION_BIT		BIT(2)
+#define VCONN_EN_VALUE_BIT			BIT(1)
+#define VCONN_EN_SRC_BIT			BIT(0)
+
+#define TYPE_C_CCOUT_CONTROL_REG		(TYPEC_BASE + 0x48)
+#define TYPEC_CCOUT_BUFFER_EN_BIT		BIT(2)
+#define TYPEC_CCOUT_VALUE_BIT			BIT(1)
+#define TYPEC_CCOUT_SRC_BIT			BIT(0)
+
+#define TYPE_C_DEBUG_ACC_SNK_CFG		(TYPEC_BASE + 0x4A)
+#define TYPEC_DEBUG_ACC_SNK_SEL_ICL		BIT(2)
+#define TYPEC_DEBUG_ACC_SNK_DIS_AICL		BIT(3)
+
+#define DEBUG_ACCESS_SRC_CFG_REG		(TYPEC_BASE + 0x4C)
+#define EN_UNORIENTED_DEBUG_ACCESS_SRC_BIT	BIT(0)
+
+#define TYPE_C_CRUDE_SENSOR_CFG_REG		(TYPEC_BASE + 0x4e)
+#define EN_SRC_CRUDE_SENSOR_BIT			BIT(1)
+#define EN_SNK_CRUDE_SENSOR_BIT			BIT(0)
+
+#define TYPE_C_EXIT_STATE_CFG_REG		(TYPEC_BASE + 0x50)
+#define BYPASS_VSAFE0V_DURING_ROLE_SWAP_BIT	BIT(3)
+#define SEL_SRC_UPPER_REF_BIT			BIT(2)
+#define EXIT_SNK_BASED_ON_CC_BIT		BIT(0)
+
+#define TYPE_C_CURRSRC_CFG_REG			(TYPEC_BASE + 0x52)
+#define TYPEC_SRC_RP_SEL_MASK			GENMASK(1, 0)
+enum {
+	TYPEC_SRC_RP_STD,
+	TYPEC_SRC_RP_1P5A,
+	TYPEC_SRC_RP_3A,
+	TYPEC_SRC_RP_3A_DUPLICATE,
+	TYPEC_SRC_RP_MAX_ELEMENTS
+};
+
+#define TYPE_C_INTERRUPT_EN_CFG_1_REG			(TYPEC_BASE + 0x5E)
+#define TYPEC_LEGACY_CABLE_INT_EN_BIT			BIT(7)
+#define TYPEC_NONCOMPLIANT_LEGACY_CABLE_INT_EN_BIT	BIT(6)
+#define TYPEC_TRYSOURCE_DETECT_INT_EN_BIT		BIT(5)
+#define TYPEC_TRYSINK_DETECT_INT_EN_BIT			BIT(4)
+#define TYPEC_CCOUT_DETACH_INT_EN_BIT			BIT(3)
+#define TYPEC_CCOUT_ATTACH_INT_EN_BIT			BIT(2)
+#define TYPEC_VBUS_DEASSERT_INT_EN_BIT			BIT(1)
+#define TYPEC_VBUS_ASSERT_INT_EN_BIT			BIT(0)
+
+#define TYPE_C_INTERRUPT_EN_CFG_2_REG		(TYPEC_BASE + 0x60)
+#define TYPEC_SRC_BATT_HPWR_INT_EN_BIT		BIT(6)
+#define MICRO_USB_STATE_CHANGE_INT_EN_BIT	BIT(5)
+#define TYPEC_STATE_MACHINE_CHANGE_INT_EN_BIT	BIT(4)
+#define TYPEC_DEBUG_ACCESS_DETECT_INT_EN_BIT	BIT(3)
+#define TYPEC_WATER_DETECTION_INT_EN_BIT	BIT(2)
+#define TYPEC_VBUS_ERROR_INT_EN_BIT		BIT(1)
+#define TYPEC_DEBOUNCE_DONE_INT_EN_BIT		BIT(0)
+
+#define TYPE_C_DEBOUNCE_OPTION_REG		(TYPEC_BASE + 0x62)
+#define REDUCE_TCCDEBOUNCE_TO_2MS_BIT		BIT(2)
+
+#define TYPE_C_SBU_CFG_REG			(TYPEC_BASE + 0x6A)
+#define SEL_SBU1_ISRC_VAL			0x04
+#define SEL_SBU2_ISRC_VAL			0x01
+
+#define TYPEC_U_USB_CFG_REG			(TYPEC_BASE + 0x70)
+#define EN_MICRO_USB_FACTORY_MODE_BIT		BIT(1)
+#define EN_MICRO_USB_MODE_BIT			BIT(0)
+
+#define PMI632_TYPEC_U_USB_WATER_PROTECTION_CFG_REG	(TYPEC_BASE + 0x72)
+#define TYPEC_U_USB_WATER_PROTECTION_CFG_REG		(TYPEC_BASE + 0x73)
+#define EN_MICRO_USB_WATER_PROTECTION_BIT		BIT(4)
+#define MICRO_USB_DETECTION_ON_TIME_CFG_MASK		GENMASK(3, 2)
+#define MICRO_USB_DETECTION_PERIOD_CFG_MASK		GENMASK(1, 0)
+#define TYPEC_MICRO_USB_MODE_REG		(TYPEC_BASE + 0x73)
+#define PMI632_TYPEC_MICRO_USB_MODE_REG		(TYPEC_BASE + 0x73)
+#define MICRO_USB_MODE_ONLY_BIT			BIT(0)
+/********************************
+ *  MISC Peripheral Registers  *
+ ********************************/
+#define TEMP_RANGE_STATUS_REG			(MISC_BASE + 0x06)
+#define THERM_REG_ACTIVE_BIT			BIT(6)
+#define TLIM_BIT				BIT(5)
+#define TEMP_RANGE_MASK				GENMASK(4, 1)
+#define ALERT_LEVEL_BIT				BIT(4)
+#define TEMP_ABOVE_RANGE_BIT			BIT(3)
+#define TEMP_WITHIN_RANGE_BIT			BIT(2)
+#define TEMP_BELOW_RANGE_BIT			BIT(1)
+#define THERMREG_DISABLED_BIT			BIT(0)
+
+#define DIE_TEMP_STATUS_REG			(MISC_BASE + 0x07)
+#define DIE_TEMP_SHDN_BIT			BIT(3)
+#define DIE_TEMP_RST_BIT			BIT(2)
+#define DIE_TEMP_UB_BIT				BIT(1)
+#define DIE_TEMP_LB_BIT				BIT(0)
+
+#define SKIN_TEMP_STATUS_REG			(MISC_BASE + 0x08)
+#define SKIN_TEMP_SHDN_BIT			BIT(3)
+#define SKIN_TEMP_RST_BIT			BIT(2)
+#define SKIN_TEMP_UB_BIT			BIT(1)
+#define SKIN_TEMP_LB_BIT			BIT(0)
+
+#define CONNECTOR_TEMP_STATUS_REG		(MISC_BASE + 0x09)
+#define CONNECTOR_TEMP_SHDN_BIT			BIT(3)
+#define CONNECTOR_TEMP_RST_BIT			BIT(2)
+#define CONNECTOR_TEMP_UB_BIT			BIT(1)
+#define CONNECTOR_TEMP_LB_BIT			BIT(0)
+
+#define SMB_TEMP_STATUS_REG			(MISC_BASE + 0x0A)
+#define SMB_TEMP_SHDN_BIT			BIT(3)
+#define SMB_TEMP_RST_BIT			BIT(2)
+#define SMB_TEMP_UB_BIT				BIT(1)
+#define SMB_TEMP_LB_BIT				BIT(0)
+
+#define BARK_BITE_WDOG_PET_REG			(MISC_BASE + 0x43)
+#define BARK_BITE_WDOG_PET_BIT			BIT(0)
+
+#define AICL_CMD_REG				(MISC_BASE + 0x44)
+#define RESTART_AICL_BIT			BIT(1)
+#define RERUN_AICL_BIT				BIT(0)
+
+#define MISC_SMB_EN_CMD_REG			(MISC_BASE + 0x48)
+#define SMB_EN_OVERRIDE_VALUE_BIT		BIT(4)
+#define SMB_EN_OVERRIDE_BIT			BIT(3)
+#define EN_STAT_CMD_BIT				BIT(2)
+#define EN_CP_FPF_CMD_BIT			BIT(1)
+#define EN_CP_CMD_BIT				BIT(0)
+
+#define WD_CFG_REG				(MISC_BASE + 0x51)
+#define WATCHDOG_TRIGGER_AFP_EN_BIT		BIT(7)
+#define BARK_WDOG_INT_EN_BIT			BIT(6)
+#define WDOG_TIMER_EN_ON_PLUGIN_BIT		BIT(1)
+#define WDOG_TIMER_EN_BIT			BIT(0)
+
+#define SNARL_BARK_BITE_WD_CFG_REG		(MISC_BASE + 0x53)
+#define BITE_WDOG_DISABLE_CHARGING_CFG_BIT	BIT(7)
+#define SNARL_WDOG_TIMEOUT_MASK                 GENMASK(6, 4)
+#define SNARL_WDOG_TIMEOUT_SHIFT		4
+#define SNARL_WDOG_TMOUT_62P5MS			0x00
+#define SNARL_WDOG_TMOUT_1S			0x40
+#define SNARL_WDOG_TMOUT_8S			0x70
+#define BARK_WDOG_TIMEOUT_MASK			GENMASK(3, 2)
+#define BARK_WDOG_TIMEOUT_SHIFT			2
+#define BITE_WDOG_TIMEOUT_MASK			GENMASK(1, 0)
+#define BITE_WDOG_TIMEOUT_8S			0x3
+#define MIN_WD_BARK_TIME			16
+
+#define AICL_RERUN_TIME_CFG_REG			(MISC_BASE + 0x61)
+#define AICL_RERUN_TIME_12S_VAL			0x01
+
+#define MISC_THERMREG_SRC_CFG_REG		(MISC_BASE + 0x70)
+#define THERMREG_SW_ICL_ADJUST_BIT		BIT(7)
+#define DIE_ADC_SEL_BIT				BIT(6)
+#define THERMREG_SMB_ADC_SRC_EN_BIT		BIT(5)
+#define THERMREG_CONNECTOR_ADC_SRC_EN_BIT	BIT(4)
+#define SKIN_ADC_CFG_BIT			BIT(3)
+#define THERMREG_SKIN_ADC_SRC_EN_BIT		BIT(2)
+#define THERMREG_DIE_ADC_SRC_EN_BIT		BIT(1)
+#define THERMREG_DIE_CMP_SRC_EN_BIT		BIT(0)
+
+#define MISC_SMB_CFG_REG			(MISC_BASE + 0x90)
+#define SMB_EN_SEL_BIT				BIT(4)
+#define CP_EN_POLARITY_CFG_BIT			BIT(3)
+#define STAT_POLARITY_CFG_BIT			BIT(2)
+#define STAT_FUNCTION_CFG_BIT			BIT(1)
+#define STAT_IRQ_PULSING_EN_BIT			BIT(0)
+
+#define DIE_REG_H_THRESHOLD_MSB_REG		(MISC_BASE + 0xA0)
+
+#define SMB_REG_H_THRESHOLD_MSB_REG		(MISC_BASE + 0XBC)
+
+/* SDAM regs */
+#define MISC_PBS_RT_STS_REG			(MISC_PBS_BASE + 0x10)
+#define PULSE_SKIP_IRQ_BIT			BIT(4)
+#endif /* __SMB5_CHARGER_REG_H */
diff --git a/drivers/power/supply/qcom/step-chg-jeita.h b/drivers/power/supply/qcom/step-chg-jeita.h
new file mode 100644
index 000000000..640d69fd7
--- /dev/null
+++ b/drivers/power/supply/qcom/step-chg-jeita.h
@@ -0,0 +1,59 @@
+/* Copyright (c) 2017-2019 The Linux Foundation. All rights reserved.
+ * Copyright (C) 2021 XiaoMi, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __STEP_CHG_H__
+#define __STEP_CHG_H__
+
+#ifdef CONFIG_QPNP_SMB5_NABU
+#define MAX_STEP_CHG_ENTRIES	6
+#else
+#define MAX_STEP_CHG_ENTRIES    5
+#endif
+
+#define BATT_CP_COOL_THRESHOLD		100
+#define BATT_CP_WARM_THRESHOLD		450
+
+#define BATT_COOL_THRESHOLD		150
+#define BATT_WARM_THRESHOLD		450
+#define FFC_CHG_TERM_TEMP_THRESHOLD	350
+enum hvdcp3_class_type {
+	HVDCP3_CLASS_NONE = 0,
+	HVDCP3_CLASS_A_18W,
+	HVDCP3_CLASS_B_27W,
+#ifdef CONFIG_QPNP_SMB5_NABU
+	HVDCP3P5_CLASS_A_18W,
+	HVDCP3P5_CLASS_B_27W,
+#endif
+};
+
+struct step_chg_jeita_param {
+	u32			psy_prop;
+	char			*prop_name;
+	int			hysteresis;
+	bool			use_bms;
+};
+
+struct range_data {
+	int low_threshold;
+	int high_threshold;
+	u32 value;
+};
+
+int qcom_step_chg_init(struct device *dev,
+		bool step_chg_enable, bool sw_jeita_enable, bool jeita_arb_en);
+void qcom_step_chg_deinit(void);
+int read_range_data_from_node(struct device_node *node,
+                const char *prop_str, struct range_data *ranges,
+                int max_threshold, u32 max_value);
+int qcom_step_chg_get_step_index(void);
+#endif /* __STEP_CHG_H__ */
diff --git a/drivers/soc/qcom/Kconfig b/drivers/soc/qcom/Kconfig
index ae504c43d..79f724531 100644
--- a/drivers/soc/qcom/Kconfig
+++ b/drivers/soc/qcom/Kconfig
@@ -248,4 +248,13 @@ config QCOM_ICC_BWMON
 	  the fixed bandwidth votes from cpufreq (CPU nodes) thus achieve high
 	  memory throughput even with lower CPU frequencies.
 
+config QCOM_PBS
+	tristate "PBS trigger support for QPNP PMIC"
+	depends on SPMI
+	help
+	  This driver supports configuring software PBS trigger event through PBS
+	  RAM on Qualcomm Technologies, Inc. QPNP PMICs. This module provides
+	  the APIs to the client drivers that wants to send the PBS trigger
+	  event to the PBS RAM.
+
 endmenu
diff --git a/drivers/soc/qcom/Makefile b/drivers/soc/qcom/Makefile
index d66604aff..a4eae59bb 100644
--- a/drivers/soc/qcom/Makefile
+++ b/drivers/soc/qcom/Makefile
@@ -29,3 +29,4 @@ obj-$(CONFIG_QCOM_RPMHPD) += rpmhpd.o
 obj-$(CONFIG_QCOM_RPMPD) += rpmpd.o
 obj-$(CONFIG_QCOM_KRYO_L2_ACCESSORS) +=	kryo-l2-accessors.o
 obj-$(CONFIG_QCOM_ICC_BWMON)	+= icc-bwmon.o
+obj-$(CONFIG_QCOM_PBS) += qpnp-pbs.o
diff --git a/drivers/soc/qcom/qpnp-pbs.c b/drivers/soc/qcom/qpnp-pbs.c
new file mode 100644
index 000000000..3f1176710
--- /dev/null
+++ b/drivers/soc/qcom/qpnp-pbs.c
@@ -0,0 +1,364 @@
+/* Copyright (c) 2017-2018, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt)	"PBS: %s: " fmt, __func__
+
+#include <linux/delay.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/spmi.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+#include <linux/err.h>
+#include <linux/of.h>
+#include <linux/qpnp-pbs.h>
+
+#define QPNP_PBS_DEV_NAME "qcom,qpnp-pbs"
+
+#define PBS_CLIENT_TRIG_CTL		0x42
+#define PBS_CLIENT_SW_TRIG_BIT		BIT(7)
+#define PBS_CLIENT_SCRATCH1		0x50
+#define PBS_CLIENT_SCRATCH2		0x51
+
+static LIST_HEAD(pbs_dev_list);
+static DEFINE_MUTEX(pbs_list_lock);
+
+struct qpnp_pbs {
+	struct platform_device	*pdev;
+	struct device		*dev;
+	struct device_node	*dev_node;
+	struct regmap		*regmap;
+	struct mutex		pbs_lock;
+	struct list_head	link;
+
+	u32			base;
+};
+
+static int qpnp_pbs_read(struct qpnp_pbs *pbs, u32 address,
+					u8 *val, int count)
+{
+	int rc = 0;
+	struct platform_device *pdev = pbs->pdev;
+
+	rc = regmap_bulk_read(pbs->regmap, address, val, count);
+	if (rc)
+		pr_err("Failed to read address=0x%02x sid=0x%02x rc=%d\n",
+			address, to_spmi_device(pdev->dev.parent)->usid, rc);
+
+	return rc;
+}
+
+static int qpnp_pbs_write(struct qpnp_pbs *pbs, u16 address,
+					u8 *val, int count)
+{
+	int rc = 0;
+	struct platform_device *pdev = pbs->pdev;
+
+	rc = regmap_bulk_write(pbs->regmap, address, val, count);
+	if (rc < 0)
+		pr_err("Failed to write address =0x%02x sid=0x%02x rc=%d\n",
+			  address, to_spmi_device(pdev->dev.parent)->usid, rc);
+	else
+		pr_debug("Wrote 0x%02X to addr 0x%04x\n", *val, address);
+
+	return rc;
+}
+
+static int qpnp_pbs_masked_write(struct qpnp_pbs *pbs, u16 address,
+						   u8 mask, u8 val)
+{
+	int rc;
+
+	rc = regmap_update_bits(pbs->regmap, address, mask, val);
+	if (rc < 0)
+		pr_err("Failed to write address 0x%04X, rc = %d\n",
+					address, rc);
+	else
+		pr_debug("Wrote 0x%02X to addr 0x%04X\n",
+			val, address);
+
+	return rc;
+}
+
+static struct qpnp_pbs *get_pbs_client_node(struct device_node *dev_node)
+{
+	struct qpnp_pbs *pbs;
+
+	mutex_lock(&pbs_list_lock);
+	list_for_each_entry(pbs, &pbs_dev_list, link) {
+		if (dev_node == pbs->dev_node) {
+			mutex_unlock(&pbs_list_lock);
+			return pbs;
+		}
+	}
+
+	mutex_unlock(&pbs_list_lock);
+	return ERR_PTR(-EINVAL);
+}
+
+static int qpnp_pbs_wait_for_ack(struct qpnp_pbs *pbs, u8 bit_pos)
+{
+	int rc = 0;
+	u16 retries = 2000, dly = 1000;
+	u8 val;
+
+	while (retries--) {
+		rc = qpnp_pbs_read(pbs, pbs->base +
+					PBS_CLIENT_SCRATCH2, &val, 1);
+		if (rc < 0) {
+			pr_err("Failed to read register %x rc = %d\n",
+						PBS_CLIENT_SCRATCH2, rc);
+			return rc;
+		}
+
+		if (val == 0xFF) {
+			val = 0;
+			/* PBS error - clear SCRATCH2 register */
+			rc = qpnp_pbs_write(pbs, pbs->base +
+					PBS_CLIENT_SCRATCH2, &val, 1);
+			if (rc < 0) {
+				pr_err("Failed to clear register %x rc=%d\n",
+						PBS_CLIENT_SCRATCH2, rc);
+				return rc;
+			}
+
+			pr_err("NACK from PBS for bit %d\n", bit_pos);
+			return -EINVAL;
+		}
+
+		if (val & BIT(bit_pos)) {
+			pr_debug("PBS sequence for bit %d executed!\n",
+						 bit_pos);
+			break;
+		}
+
+		usleep_range(dly, dly + 100);
+	}
+
+	if (!retries) {
+		pr_err("Timeout for PBS ACK/NACK for bit %d\n", bit_pos);
+		return -ETIMEDOUT;
+	}
+
+	return 0;
+}
+
+/**
+ * qpnp_pbs_trigger_event - Trigger the PBS RAM sequence
+ *
+ * Returns = 0 If the PBS RAM sequence executed successfully.
+ *
+ * Returns < 0 for errors.
+ *
+ * This function is used to trigger the PBS RAM sequence to be
+ * executed by the client driver.
+ *
+ * The PBS trigger sequence involves
+ * 1. setting the PBS sequence bit in PBS_CLIENT_SCRATCH1
+ * 2. Initiating the SW PBS trigger
+ * 3. Checking the equivalent bit in PBS_CLIENT_SCRATCH2 for the
+ *    completion of the sequence.
+ * 4. If PBS_CLIENT_SCRATCH2 == 0xFF, the PBS sequence failed to execute
+ */
+int qpnp_pbs_trigger_event(struct device_node *dev_node, u8 bitmap)
+{
+	struct qpnp_pbs *pbs;
+	int rc = 0;
+	u16 bit_pos = 0;
+	u8 val, mask  = 0;
+
+	if (!dev_node)
+		return -EINVAL;
+
+	if (!bitmap) {
+		pr_err("Invalid bitmap passed by client\n");
+		return -EINVAL;
+	}
+
+	pbs = get_pbs_client_node(dev_node);
+	if (IS_ERR_OR_NULL(pbs)) {
+		pr_err("Unable to find the PBS dev_node\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&pbs->pbs_lock);
+	rc = qpnp_pbs_read(pbs, pbs->base + PBS_CLIENT_SCRATCH2, &val, 1);
+	if (rc < 0) {
+		pr_err("read register %x failed rc = %d\n",
+					PBS_CLIENT_SCRATCH2, rc);
+		goto out;
+	}
+
+	if (val == 0xFF) {
+		val = 0;
+		/* PBS error - clear SCRATCH2 register */
+		rc = qpnp_pbs_write(pbs, pbs->base + PBS_CLIENT_SCRATCH2, &val,
+				    1);
+		if (rc < 0) {
+			pr_err("Failed to clear register %x rc=%d\n",
+						PBS_CLIENT_SCRATCH2, rc);
+			goto out;
+		}
+	}
+
+	for (bit_pos = 0; bit_pos < 8; bit_pos++) {
+		if (bitmap & BIT(bit_pos)) {
+			/*
+			 * Clear the PBS sequence bit position in
+			 * PBS_CLIENT_SCRATCH2 mask register.
+			 */
+			rc = qpnp_pbs_masked_write(pbs, pbs->base +
+					 PBS_CLIENT_SCRATCH2, BIT(bit_pos), 0);
+			if (rc < 0) {
+				pr_err("Failed to clear %x reg bit rc=%d\n",
+						PBS_CLIENT_SCRATCH2, rc);
+				goto error;
+			}
+
+			/*
+			 * Set the PBS sequence bit position in
+			 * PBS_CLIENT_SCRATCH1 register.
+			 */
+			val = mask = BIT(bit_pos);
+			rc = qpnp_pbs_masked_write(pbs, pbs->base +
+						PBS_CLIENT_SCRATCH1, mask, val);
+			if (rc < 0) {
+				pr_err("Failed to set %x reg bit rc=%d\n",
+						PBS_CLIENT_SCRATCH1, rc);
+				goto error;
+			}
+
+			/* Initiate the SW trigger */
+			val = mask = PBS_CLIENT_SW_TRIG_BIT;
+			rc = qpnp_pbs_masked_write(pbs, pbs->base +
+						PBS_CLIENT_TRIG_CTL, mask, val);
+			if (rc < 0) {
+				pr_err("Failed to write register %x rc=%d\n",
+						PBS_CLIENT_TRIG_CTL, rc);
+				goto error;
+			}
+
+			rc = qpnp_pbs_wait_for_ack(pbs, bit_pos);
+			if (rc < 0) {
+				pr_err("Error during wait_for_ack\n");
+				goto error;
+			}
+
+			/*
+			 * Clear the PBS sequence bit position in
+			 * PBS_CLIENT_SCRATCH1 register.
+			 */
+			rc = qpnp_pbs_masked_write(pbs, pbs->base +
+					PBS_CLIENT_SCRATCH1, BIT(bit_pos), 0);
+			if (rc < 0) {
+				pr_err("Failed to clear %x reg bit rc=%d\n",
+						PBS_CLIENT_SCRATCH1, rc);
+				goto error;
+			}
+
+			/*
+			 * Clear the PBS sequence bit position in
+			 * PBS_CLIENT_SCRATCH2 mask register.
+			 */
+			rc = qpnp_pbs_masked_write(pbs, pbs->base +
+					PBS_CLIENT_SCRATCH2, BIT(bit_pos), 0);
+			if (rc < 0) {
+				pr_err("Failed to clear %x reg bit rc=%d\n",
+						PBS_CLIENT_SCRATCH2, rc);
+				goto error;
+			}
+
+		}
+	}
+
+error:
+	/* Clear all the requested bitmap */
+	rc = qpnp_pbs_masked_write(pbs, pbs->base + PBS_CLIENT_SCRATCH1,
+						bitmap, 0);
+	if (rc < 0)
+		pr_err("Failed to clear %x reg bit rc=%d\n",
+					PBS_CLIENT_SCRATCH1, rc);
+out:
+	mutex_unlock(&pbs->pbs_lock);
+
+	return rc;
+}
+EXPORT_SYMBOL(qpnp_pbs_trigger_event);
+
+static int qpnp_pbs_probe(struct platform_device *pdev)
+{
+	int rc = 0;
+	u32 val = 0;
+	struct qpnp_pbs *pbs;
+
+	pbs = devm_kzalloc(&pdev->dev, sizeof(*pbs), GFP_KERNEL);
+	if (!pbs)
+		return -ENOMEM;
+
+	pbs->pdev = pdev;
+	pbs->dev = &pdev->dev;
+	pbs->dev_node = pdev->dev.of_node;
+	pbs->regmap = dev_get_regmap(pdev->dev.parent, NULL);
+	if (!pbs->regmap) {
+		dev_err(&pdev->dev, "Couldn't get parent's regmap\n");
+		return -EINVAL;
+	}
+
+	rc = of_property_read_u32(pdev->dev.of_node, "reg", &val);
+	if (rc < 0) {
+		dev_err(&pdev->dev,
+			"Couldn't find reg in node = %s rc = %d\n",
+			pdev->dev.of_node->full_name, rc);
+		return rc;
+	}
+
+	pbs->base = val;
+	mutex_init(&pbs->pbs_lock);
+
+	dev_set_drvdata(&pdev->dev, pbs);
+
+	mutex_lock(&pbs_list_lock);
+	list_add(&pbs->link, &pbs_dev_list);
+	mutex_unlock(&pbs_list_lock);
+
+	return 0;
+}
+
+static const struct of_device_id qpnp_pbs_match_table[] = {
+	{ .compatible = QPNP_PBS_DEV_NAME },
+	{}
+};
+
+static struct platform_driver qpnp_pbs_driver = {
+	.driver	= {
+		.name		= QPNP_PBS_DEV_NAME,
+		.owner		= THIS_MODULE,
+		.of_match_table	= qpnp_pbs_match_table,
+	},
+	.probe	= qpnp_pbs_probe,
+};
+
+static int __init qpnp_pbs_init(void)
+{
+	return platform_driver_register(&qpnp_pbs_driver);
+}
+arch_initcall(qpnp_pbs_init);
+
+static void __exit qpnp_pbs_exit(void)
+{
+	return platform_driver_unregister(&qpnp_pbs_driver);
+}
+module_exit(qpnp_pbs_exit);
+
+MODULE_DESCRIPTION("QPNP PBS DRIVER");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:" QPNP_PBS_DEV_NAME);
diff --git a/include/linux/qpnp-pbs.h b/include/linux/qpnp-pbs.h
new file mode 100644
index 000000000..5613ee213
--- /dev/null
+++ b/include/linux/qpnp-pbs.h
@@ -0,0 +1,25 @@
+/* Copyright (c) 2017, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _QPNP_PBS_H
+#define _QPNP_PBS_H
+
+#ifdef CONFIG_QCOM_PBS
+int qpnp_pbs_trigger_event(struct device_node *dev_node, u8 bitmap);
+#else
+static inline int qpnp_pbs_trigger_event(struct device_node *dev_node,
+						 u8 bitmap) {
+	return -ENODEV;
+}
+#endif
+
+#endif
-- 
2.46.1

